{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "673fc1c8",
   "metadata": {},
   "source": [
    "# 2. Déploiement et quantization avec onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da76f02e",
   "metadata": {},
   "source": [
    "## Partie 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0de5a10",
   "metadata": {},
   "source": [
    "### 1. Entraîner un réseau de neurone convolutionnel de petite taille"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 993,
   "id": "2986dee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "train_dataset = datasets.MNIST(root='data/', train=True, download=True, transform=transform)\n",
    "test_dataset  = datasets.MNIST(root='data/', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader  = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader   = DataLoader(test_dataset, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 994,
   "id": "7a032fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 60000\n",
      "Number of test samples: 10000\n",
      "Size images: 5\n",
      "Number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training samples: {len(train_dataset)}\")\n",
    "print(f\"Number of test samples: {len(test_dataset)}\")\n",
    "print(f\"Size images: {train_dataset[0][1]}\")\n",
    "print(f\"Number of classes: {len(train_dataset.classes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1020,
   "id": "59080527",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "    def compile(self, optimizer, criterion):\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "    \n",
    "    def fit(self, train_loader, epochs=1):\n",
    "        self.train()\n",
    "        for epoch in range(epochs):\n",
    "            running_loss = 0.0\n",
    "            for batch_idx, (data, target) in enumerate(train_loader):\n",
    "                self.optimizer.zero_grad()\n",
    "                output = self(data)\n",
    "                loss = self.criterion(output, target)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "            avg_loss = running_loss / len(train_loader)\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    def evaluate(self, test_loader):\n",
    "        self.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                output = self(data)\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                correct += (predicted == target).sum().item()\n",
    "        return correct / len(test_loader.dataset)\n",
    "    \n",
    "    def export_onnx(self, file_name):\n",
    "        self.eval()\n",
    "        dummy_input = torch.randn(1, 1, 28, 28)\n",
    "\n",
    "        torch.onnx.export(\n",
    "            model,\n",
    "            dummy_input,\n",
    "            file_name,\n",
    "            input_names=[\"input\"],\n",
    "            output_names=[\"output\"],\n",
    "            opset_version=18,\n",
    "            dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}},\n",
    "        )\n",
    "\n",
    "model = MLP()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model.compile(optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 996,
   "id": "6bfe5814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2, Loss: 0.3400\n",
      "Epoch 2/2, Loss: 0.1397\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_loader, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 997,
   "id": "6cb497b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9661\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(test_loader)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a560a17",
   "metadata": {},
   "source": [
    "### 2. Faire en sorte d'exporter le modèle au format ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "id": "3a3a2671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `SimpleMLP([...]` with `torch.export.export(..., strict=False)`...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12252/1215903376.py:50: UserWarning: # 'dynamic_axes' is not recommended when dynamo=True, and may lead to 'torch._dynamo.exc.UserError: Constraints violated.' Supply the 'dynamic_shapes' argument instead if export is unsuccessful.\n",
      "  torch.onnx.export(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `SimpleMLP([...]` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n",
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n",
      "Applied 1 of general pattern rewrite rules.\n"
     ]
    }
   ],
   "source": [
    "model.export_onnx(\"model/simple_mlp.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8c68a1",
   "metadata": {},
   "source": [
    "### 3. Faire un benchmark de votre modèle. il faudra mesurer le temps moyen de prédiction du modèle origianl et le modèle onnx CPU pour différente taille de batch.\n",
    "Modèle\tbatch-size = 1\tBatch size = 8\tBatch size = 32\tBatch size 128\n",
    "vitesse - modèle original\t \t \t \t \n",
    "vitesse onnx runtime\n",
    "\n",
    "### 4. Mesurer la test accuracy de votre modèle avec ONNX runtime et comparer les softpredictions sur plusieurs exemples. y-t-il des différences ?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "id": "b4d20ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import onnx\n",
    "import onnxruntime as ort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "id": "48aafd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_torch(mod, data_loader: DataLoader):\n",
    "    mod.eval()  \n",
    "    all_preds = []\n",
    "    correct = 0\n",
    "    times = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            start = time.time()\n",
    "            outputs = mod(data)\n",
    "            end = time.time()\n",
    "\n",
    "            times.append(end - start)\n",
    "            preds = outputs.argmax(dim=1).cpu().numpy()\n",
    "            all_preds.append(preds)\n",
    "            correct += (preds == target.numpy()).sum()\n",
    "\n",
    "    avg_time_per_batch = np.mean(times)\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    return avg_time_per_batch, all_preds, correct / len(data_loader.dataset)\n",
    "\n",
    "\n",
    "def benchmark_onnx(ort_session, data_loader):\n",
    "    import numpy as np\n",
    "    all_preds = []\n",
    "    correct = 0\n",
    "    times = []\n",
    "\n",
    "\n",
    "    input_name = ort_session.get_inputs()[0].name\n",
    "\n",
    "    for data, target in data_loader:\n",
    "        data_np = data.numpy()\n",
    "        start = time.time()\n",
    "        outputs = ort_session.run(None, {input_name: data_np})\n",
    "        end = time.time()\n",
    "\n",
    "        times.append(end - start)\n",
    "        preds = np.argmax(outputs[0], axis=1)\n",
    "        all_preds.append(preds)\n",
    "        correct += (preds == target.numpy()).sum()\n",
    "\n",
    "    avg_time_per_batch = np.mean(times)\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    return avg_time_per_batch, all_preds, correct / len(data_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1001,
   "id": "9523d4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     model   batch=1   batch=8  batch=32  batch=128  accuracy\n",
      "0  pytorch  0.000135  0.000178  0.000490   0.001830    0.9661\n",
      "1     onnx  0.000025  0.000051  0.000243   0.000159    0.9661\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ort_session = ort.InferenceSession(\"model/simple_mlp.onnx\")\n",
    "batch_sizes = [1, 8, 32, 128]\n",
    "\n",
    "def benchmark_models(models_bm, dataset):\n",
    "    results = {\"model\": [], \"batch=1\": [], \"batch=8\": [], \"batch=32\": [], \"batch=128\": [], \"accuracy\": []}\n",
    "    for model_name, m, bm_func in models_bm:\n",
    "        results[\"model\"].append(model_name)\n",
    "        times_per_batch = []\n",
    "        for batch_size in batch_sizes:\n",
    "            loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "            avg_time_per_batch, all_preds, acc = zip(*[bm_func(m, loader) for _ in range(2)])\n",
    "            t = np.mean(avg_time_per_batch)\n",
    "            times_per_batch.append(t)\n",
    "        results[\"batch=1\"].append(times_per_batch[0])\n",
    "        results[\"batch=8\"].append(times_per_batch[1])\n",
    "        results[\"batch=32\"].append(times_per_batch[2])\n",
    "        results[\"batch=128\"].append(times_per_batch[3])\n",
    "        results[\"accuracy\"].append(np.mean(acc))\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n",
    "\n",
    "models_bm = [\n",
    "    (\"pytorch\", model, benchmark_torch), \n",
    "    (\"onnx\", ort_session, benchmark_onnx)\n",
    "]\n",
    "df = benchmark_models(models_bm, test_dataset)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2a6712",
   "metadata": {},
   "source": [
    "Onnx est plus rapide sans perte de performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1002,
   "id": "2c0ae508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "data, target = next(iter(DataLoader(test_dataset, batch_size=100, shuffle=False))) # take first 100 samples\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits_torch = model(data)\n",
    "    soft_torch = F.softmax(logits_torch, dim=1).numpy()\n",
    "\n",
    "input_name = ort_session.get_inputs()[0].name\n",
    "logits_onnx = ort_session.run(None, {input_name: data.numpy()})[0]\n",
    "soft_onnx = np.exp(logits_onnx) / np.sum(np.exp(logits_onnx), axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "id": "f5c9722a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean difference per element: 8.189887e-09\n",
      "Max difference per element: 2.3841858e-07\n"
     ]
    }
   ],
   "source": [
    "diff = np.abs(soft_torch - soft_onnx)\n",
    "print(\"Mean difference per element:\", np.mean(diff))\n",
    "print(\"Max difference per element:\", np.max(diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaef11a",
   "metadata": {},
   "source": [
    "C'est tres proche donc onnx runtime est une bonne alternative pour deployer des modeles entraines avec pytorch. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8eb313",
   "metadata": {},
   "source": [
    "## Partie 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389895bb",
   "metadata": {},
   "source": [
    "### 1. Quantifier le modèle et reprendre l'analyse de la partie 1. Comparer également la taille du modèle original et quantifié. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1057,
   "id": "51b1f51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnx import numpy_helper, shape_inference\n",
    "\n",
    "\n",
    "def _set_dynamic_batch_dim(model, dim_name=\"batch_size\"):\n",
    "    for tensor in list(model.graph.input) + list(model.graph.output):\n",
    "        tensor_shape = tensor.type.tensor_type.shape\n",
    "        if tensor_shape.dim:\n",
    "            tensor_shape.dim[0].dim_value = 0\n",
    "            tensor_shape.dim[0].dim_param = dim_name\n",
    "\n",
    "\n",
    "def correct_onnx(src, dst):\n",
    "    model = onnx.load(src)\n",
    "    for node in model.graph.node:\n",
    "        if node.op_type != \"Gemm\":\n",
    "            continue\n",
    "\n",
    "        transB_attr = next((attr for attr in node.attribute if attr.name == \"transB\"), None)\n",
    "        weight_name = node.input[1]\n",
    "\n",
    "        if transB_attr and transB_attr.i == 1:\n",
    "            weight_init = next((init for init in model.graph.initializer if init.name == weight_name), None)\n",
    "            if weight_init is None:\n",
    "                continue\n",
    "            weight_array = numpy_helper.to_array(weight_init)\n",
    "            weight_T = weight_array.T\n",
    "            new_weight_init = numpy_helper.from_array(weight_T, name=weight_name)\n",
    "\n",
    "            for idx, init in enumerate(model.graph.initializer):\n",
    "                if init.name == weight_name:\n",
    "                    model.graph.initializer[idx].CopyFrom(new_weight_init)\n",
    "                    break\n",
    "\n",
    "            transB_attr.i = 0\n",
    "\n",
    "    model.graph.value_info.clear()\n",
    "\n",
    "    model = shape_inference.infer_shapes(model, strict_mode=True)\n",
    "    _set_dynamic_batch_dim(model)\n",
    "    onnx.checker.check_model(model)\n",
    "    onnx.save(model, dst)\n",
    "\n",
    "\n",
    "src = \"model/simple_mlp.onnx\"\n",
    "dst = \"model/simple_mlp.cleaned.onnx\"\n",
    "correct_onnx(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1058,
   "id": "5e36e3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
     ]
    }
   ],
   "source": [
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "quantize_dynamic(\n",
    "    model_input=\"model/simple_mlp.cleaned.onnx\",\n",
    "    model_output=\"model/simple_mlp.quant.onnx\",\n",
    "    weight_type=QuantType.QInt8,\n",
    "    per_channel=False,\n",
    "    reduce_range=False,\n",
    "    op_types_to_quantize=[\"MatMul\", \"Gemm\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1059,
   "id": "0701e64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model size: 433.65 KB\n",
      "Quantized model size: 113.65 KB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "original_size = os.path.getsize(\"model/simple_mlp.cleaned.onnx\")\n",
    "quantized_size = os.path.getsize(\"model/simple_mlp.quant.onnx\")\n",
    "print(f\"Original model size: {original_size / 1024:.2f} KB\")\n",
    "print(f\"Quantized model size: {quantized_size / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1060,
   "id": "7df5666b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        model   batch=1   batch=8  batch=32  batch=128  accuracy\n",
      "0     pytorch  0.000135  0.000178  0.000490   0.001830    0.9661\n",
      "1        onnx  0.000025  0.000051  0.000243   0.000159    0.9661\n",
      "2  onnx_quant  0.000029  0.000038  0.000097   0.000160    0.9661\n"
     ]
    }
   ],
   "source": [
    "# Refaire le benchmark avec le modèle quantifié\n",
    "ort_session_quant = ort.InferenceSession(\"model/simple_mlp.quant.onnx\")\n",
    "\n",
    "models_bm = [(\"onnx_quant\", ort_session_quant, benchmark_onnx)]\n",
    "df_quant = benchmark_models(models_bm, test_dataset)\n",
    "df_quant = pd.concat([df, df_quant], ignore_index=True)\n",
    "print(df_quant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ec5ff9",
   "metadata": {},
   "source": [
    "### 2. Refaire la même analyse avec un dataset un peu plus complexe (cifar 10, cifar100, etc.) et / ou un modèle plus gros (par exemple issu d'un modèle pré-entraîné)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896bafab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "# FIXME: calcul mean and std\n",
    "mean = (0.49139968, 0.48215827, 0.44653124)\n",
    "std = (0.24703233, 0.24348505, 0.26158768)\n",
    "cifar_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean, std)])\n",
    "\n",
    "cifar10_train = datasets.CIFAR10(root=\"data/\", train=True, download=True, transform=cifar_transform)\n",
    "cifar10_test = datasets.CIFAR10(root=\"data/\", train=False, download=True, transform=cifar_transform)\n",
    "\n",
    "train_cifar = torch.utils.data.DataLoader(cifar10_train, batch_size=64, shuffle=True)\n",
    "test_cifar = torch.utils.data.DataLoader(cifar10_test, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1062,
   "id": "242fe42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/lois/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    }
   ],
   "source": [
    "# use pretrained model\n",
    "import torch\n",
    "model_cifar = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_resnet20\", pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1063,
   "id": "a5579f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_cifar = optim.Adam(model_cifar.parameters())\n",
    "criterion_cifar = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1064,
   "id": "eb7e23a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12252/2266756794.py:5: UserWarning: # 'dynamic_axes' is not recommended when dynamo=True, and may lead to 'torch._dynamo.exc.UserError: Constraints violated.' Supply the 'dynamic_shapes' argument instead if export is unsuccessful.\n",
      "  torch.onnx.export(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `CifarResNet([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `CifarResNet([...]` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n",
      "[torch.onnx] Obtain model graph for `CifarResNet([...]` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n",
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n",
      "Applied 1 of general pattern rewrite rules.\n",
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n",
      "Applied 1 of general pattern rewrite rules.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ONNXProgram(\n",
       "    model=\n",
       "        <\n",
       "            ir_version=10,\n",
       "            opset_imports={'': 18},\n",
       "            producer_name='pytorch',\n",
       "            producer_version='2.9.0+cu128',\n",
       "            domain=None,\n",
       "            model_version=None,\n",
       "        >\n",
       "        graph(\n",
       "            name=main_graph,\n",
       "            inputs=(\n",
       "                %\"input\"<FLOAT,[s77,3,32,32]>\n",
       "            ),\n",
       "            outputs=(\n",
       "                %\"output\"<FLOAT,[1,10]>\n",
       "            ),\n",
       "            initializers=(\n",
       "                %\"conv1.weight\"<FLOAT,[16,3,3,3]>{TorchTensor(...)},\n",
       "                %\"bn1.weight\"<FLOAT,[16]>{TorchTensor(...)},\n",
       "                %\"bn1.bias\"<FLOAT,[16]>{TorchTensor(...)},\n",
       "                %\"layer1.0.conv1.weight\"<FLOAT,[16,16,3,3]>{TorchTensor(...)},\n",
       "                %\"layer1.0.bn1.weight\"<FLOAT,[16]>{TorchTensor(...)},\n",
       "                %\"layer1.0.bn1.bias\"<FLOAT,[16]>{TorchTensor(...)},\n",
       "                %\"layer1.0.conv2.weight\"<FLOAT,[16,16,3,3]>{TorchTensor(...)},\n",
       "                %\"layer1.0.bn2.weight\"<FLOAT,[16]>{TorchTensor(...)},\n",
       "                %\"layer1.0.bn2.bias\"<FLOAT,[16]>{TorchTensor(...)},\n",
       "                %\"layer1.1.conv1.weight\"<FLOAT,[16,16,3,3]>{TorchTensor(...)},\n",
       "                %\"layer1.1.bn1.weight\"<FLOAT,[16]>{TorchTensor(...)},\n",
       "                %\"layer1.1.bn1.bias\"<FLOAT,[16]>{TorchTensor(...)},\n",
       "                %\"layer1.1.conv2.weight\"<FLOAT,[16,16,3,3]>{TorchTensor(...)},\n",
       "                %\"layer1.1.bn2.weight\"<FLOAT,[16]>{TorchTensor(...)},\n",
       "                %\"layer1.1.bn2.bias\"<FLOAT,[16]>{TorchTensor(...)},\n",
       "                %\"layer1.2.conv1.weight\"<FLOAT,[16,16,3,3]>{TorchTensor(...)},\n",
       "                %\"layer1.2.bn1.weight\"<FLOAT,[16]>{TorchTensor(...)},\n",
       "                %\"layer1.2.bn1.bias\"<FLOAT,[16]>{TorchTensor(...)},\n",
       "                %\"layer1.2.conv2.weight\"<FLOAT,[16,16,3,3]>{TorchTensor(...)},\n",
       "                %\"layer1.2.bn2.weight\"<FLOAT,[16]>{TorchTensor(...)},\n",
       "                %\"layer1.2.bn2.bias\"<FLOAT,[16]>{TorchTensor(...)},\n",
       "                %\"layer2.0.conv1.weight\"<FLOAT,[32,16,3,3]>{TorchTensor(...)},\n",
       "                %\"layer2.0.bn1.weight\"<FLOAT,[32]>{TorchTensor(...)},\n",
       "                %\"layer2.0.bn1.bias\"<FLOAT,[32]>{TorchTensor(...)},\n",
       "                %\"layer2.0.conv2.weight\"<FLOAT,[32,32,3,3]>{TorchTensor(...)},\n",
       "                %\"layer2.0.bn2.weight\"<FLOAT,[32]>{TorchTensor(...)},\n",
       "                %\"layer2.0.bn2.bias\"<FLOAT,[32]>{TorchTensor(...)},\n",
       "                %\"layer2.0.downsample.0.weight\"<FLOAT,[32,16,1,1]>{TorchTensor(...)},\n",
       "                %\"layer2.0.downsample.1.weight\"<FLOAT,[32]>{TorchTensor(...)},\n",
       "                %\"layer2.1.conv1.weight\"<FLOAT,[32,32,3,3]>{TorchTensor(...)},\n",
       "                %\"layer2.1.bn1.weight\"<FLOAT,[32]>{TorchTensor(...)},\n",
       "                %\"layer2.1.bn1.bias\"<FLOAT,[32]>{TorchTensor(...)},\n",
       "                %\"layer2.1.conv2.weight\"<FLOAT,[32,32,3,3]>{TorchTensor(...)},\n",
       "                %\"layer2.1.bn2.weight\"<FLOAT,[32]>{TorchTensor(...)},\n",
       "                %\"layer2.1.bn2.bias\"<FLOAT,[32]>{TorchTensor(...)},\n",
       "                %\"layer2.2.conv1.weight\"<FLOAT,[32,32,3,3]>{TorchTensor(...)},\n",
       "                %\"layer2.2.bn1.weight\"<FLOAT,[32]>{TorchTensor(...)},\n",
       "                %\"layer2.2.bn1.bias\"<FLOAT,[32]>{TorchTensor(...)},\n",
       "                %\"layer2.2.conv2.weight\"<FLOAT,[32,32,3,3]>{TorchTensor(...)},\n",
       "                %\"layer2.2.bn2.weight\"<FLOAT,[32]>{TorchTensor(...)},\n",
       "                %\"layer2.2.bn2.bias\"<FLOAT,[32]>{TorchTensor(...)},\n",
       "                %\"layer3.0.conv1.weight\"<FLOAT,[64,32,3,3]>{TorchTensor(...)},\n",
       "                %\"layer3.0.bn1.weight\"<FLOAT,[64]>{TorchTensor(...)},\n",
       "                %\"layer3.0.bn1.bias\"<FLOAT,[64]>{TorchTensor(...)},\n",
       "                %\"layer3.0.conv2.weight\"<FLOAT,[64,64,3,3]>{TorchTensor(...)},\n",
       "                %\"layer3.0.bn2.weight\"<FLOAT,[64]>{TorchTensor(...)},\n",
       "                %\"layer3.0.bn2.bias\"<FLOAT,[64]>{TorchTensor(...)},\n",
       "                %\"layer3.0.downsample.0.weight\"<FLOAT,[64,32,1,1]>{TorchTensor(...)},\n",
       "                %\"layer3.0.downsample.1.weight\"<FLOAT,[64]>{TorchTensor(...)},\n",
       "                %\"layer3.1.conv1.weight\"<FLOAT,[64,64,3,3]>{TorchTensor(...)},\n",
       "                %\"layer3.1.bn1.weight\"<FLOAT,[64]>{TorchTensor(...)},\n",
       "                %\"layer3.1.bn1.bias\"<FLOAT,[64]>{TorchTensor(...)},\n",
       "                %\"layer3.1.conv2.weight\"<FLOAT,[64,64,3,3]>{TorchTensor(...)},\n",
       "                %\"layer3.1.bn2.weight\"<FLOAT,[64]>{TorchTensor(...)},\n",
       "                %\"layer3.1.bn2.bias\"<FLOAT,[64]>{TorchTensor(...)},\n",
       "                %\"layer3.2.conv1.weight\"<FLOAT,[64,64,3,3]>{TorchTensor(...)},\n",
       "                %\"layer3.2.bn1.weight\"<FLOAT,[64]>{TorchTensor(...)},\n",
       "                %\"layer3.2.bn1.bias\"<FLOAT,[64]>{TorchTensor(...)},\n",
       "                %\"layer3.2.conv2.weight\"<FLOAT,[64,64,3,3]>{TorchTensor(...)},\n",
       "                %\"layer3.2.bn2.weight\"<FLOAT,[64]>{TorchTensor(...)},\n",
       "                %\"layer3.2.bn2.bias\"<FLOAT,[64]>{TorchTensor(...)},\n",
       "                %\"fc.weight\"<FLOAT,[10,64]>{TorchTensor(...)},\n",
       "                %\"fc.bias\"<FLOAT,[10]>{TorchTensor<FLOAT,[10]>(Parameter containing: tensor([-0.0084, -0.0081,  0.0402,  0.0166,  0.0054, -0.0219,  0.0162, -0.0199, 0.0115, -0.0315], requires_grad=True), name='fc.bias')},\n",
       "                %\"bn1.running_mean\"<FLOAT,[16]>{TorchTensor(...)},\n",
       "                %\"bn1.running_var\"<FLOAT,[16]>{TorchTensor(...)},\n",
       "                %\"layer1.0.bn1.running_mean\"<FLOAT,[16]>{TorchTensor(...)},\n",
       "                %\"layer1.0.bn1.running_var\"<FLOAT,[16]>{TorchTensor(...)},\n",
       "                %\"layer1.0.bn2.running_mean\"<FLOAT,[16]>{TorchTensor(...)},\n",
       "                %\"layer1.0.bn2.running_var\"<FLOAT,[16]>{TorchTensor(...)},\n",
       "                %\"layer1.1.bn1.running_mean\"<FLOAT,[16]>{TorchTensor(...)},\n",
       "                %\"layer1.1.bn1.running_var\"<FLOAT,[16]>{TorchTensor(...)},\n",
       "                %\"layer1.1.bn2.running_mean\"<FLOAT,[16]>{TorchTensor(...)},\n",
       "                %\"layer1.1.bn2.running_var\"<FLOAT,[16]>{TorchTensor(...)},\n",
       "                %\"layer1.2.bn1.running_mean\"<FLOAT,[16]>{TorchTensor(...)},\n",
       "                %\"layer1.2.bn1.running_var\"<FLOAT,[16]>{TorchTensor(...)},\n",
       "                %\"layer1.2.bn2.running_mean\"<FLOAT,[16]>{TorchTensor(...)},\n",
       "                %\"layer1.2.bn2.running_var\"<FLOAT,[16]>{TorchTensor(...)},\n",
       "                %\"layer2.0.bn1.running_mean\"<FLOAT,[32]>{TorchTensor(...)},\n",
       "                %\"layer2.0.bn1.running_var\"<FLOAT,[32]>{TorchTensor(...)},\n",
       "                %\"layer2.0.bn2.running_mean\"<FLOAT,[32]>{TorchTensor(...)},\n",
       "                %\"layer2.0.bn2.running_var\"<FLOAT,[32]>{TorchTensor(...)},\n",
       "                %\"layer2.0.downsample.1.running_mean\"<FLOAT,[32]>{TorchTensor(...)},\n",
       "                %\"layer2.0.downsample.1.running_var\"<FLOAT,[32]>{TorchTensor(...)},\n",
       "                %\"layer2.1.bn1.running_mean\"<FLOAT,[32]>{TorchTensor(...)},\n",
       "                %\"layer2.1.bn1.running_var\"<FLOAT,[32]>{TorchTensor(...)},\n",
       "                %\"layer2.1.bn2.running_mean\"<FLOAT,[32]>{TorchTensor(...)},\n",
       "                %\"layer2.1.bn2.running_var\"<FLOAT,[32]>{TorchTensor(...)},\n",
       "                %\"layer2.2.bn1.running_mean\"<FLOAT,[32]>{TorchTensor(...)},\n",
       "                %\"layer2.2.bn1.running_var\"<FLOAT,[32]>{TorchTensor(...)},\n",
       "                %\"layer2.2.bn2.running_mean\"<FLOAT,[32]>{TorchTensor(...)},\n",
       "                %\"layer2.2.bn2.running_var\"<FLOAT,[32]>{TorchTensor(...)},\n",
       "                %\"layer3.0.bn1.running_mean\"<FLOAT,[64]>{TorchTensor(...)},\n",
       "                %\"layer3.0.bn1.running_var\"<FLOAT,[64]>{TorchTensor(...)},\n",
       "                %\"layer3.0.bn2.running_mean\"<FLOAT,[64]>{TorchTensor(...)},\n",
       "                %\"layer3.0.bn2.running_var\"<FLOAT,[64]>{TorchTensor(...)},\n",
       "                %\"layer3.0.downsample.1.running_mean\"<FLOAT,[64]>{TorchTensor(...)},\n",
       "                %\"layer3.0.downsample.1.running_var\"<FLOAT,[64]>{TorchTensor(...)},\n",
       "                %\"layer3.1.bn1.running_mean\"<FLOAT,[64]>{TorchTensor(...)},\n",
       "                %\"layer3.1.bn1.running_var\"<FLOAT,[64]>{TorchTensor(...)},\n",
       "                %\"layer3.1.bn2.running_mean\"<FLOAT,[64]>{TorchTensor(...)},\n",
       "                %\"layer3.1.bn2.running_var\"<FLOAT,[64]>{TorchTensor(...)},\n",
       "                %\"layer3.2.bn1.running_mean\"<FLOAT,[64]>{TorchTensor(...)},\n",
       "                %\"layer3.2.bn1.running_var\"<FLOAT,[64]>{TorchTensor(...)},\n",
       "                %\"layer3.2.bn2.running_mean\"<FLOAT,[64]>{TorchTensor(...)},\n",
       "                %\"layer3.2.bn2.running_var\"<FLOAT,[64]>{TorchTensor(...)},\n",
       "                %\"val_6\"<FLOAT,[16]>{Tensor(...)},\n",
       "                %\"val_71\"<FLOAT,[32]>{Tensor(...)},\n",
       "                %\"val_134\"<FLOAT,[64]>{Tensor(...)},\n",
       "                %\"val_195\"<INT64,[2]>{Tensor<INT64,[2]>(array([-1, -2]), name='val_195')},\n",
       "                %\"val_198\"<INT64,[1]>{Tensor<INT64,[1]>(array([-1]), name='val_198')}\n",
       "            ),\n",
       "        ) {\n",
       "             0 |  # node_Shape_0\n",
       "                  %\"val_0\"<INT64,[1]> ⬅️ ::Shape(%\"input\") {end=1, start=0}\n",
       "             1 |  # node_conv2d\n",
       "                  %\"conv2d\"<FLOAT,[s77,16,32,32]> ⬅️ ::Conv(%\"input\", %\"conv1.weight\"{...}, %\"val_6\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "             2 |  # node__native_batch_norm_legit_no_training__0\n",
       "                  %\"getitem\"<FLOAT,[1,16,32,32]> ⬅️ ::BatchNormalization(%\"conv2d\", %\"bn1.weight\"{...}, %\"bn1.bias\"{...}, %\"bn1.running_mean\"{...}, %\"bn1.running_var\"{...}) {momentum=0.9, epsilon=1e-05}\n",
       "             3 |  # node_relu\n",
       "                  %\"relu\"<FLOAT,[1,16,32,32]> ⬅️ ::Relu(%\"getitem\")\n",
       "             4 |  # node_conv2d_1\n",
       "                  %\"conv2d_1\"<FLOAT,[1,16,32,32]> ⬅️ ::Conv(%\"relu\", %\"layer1.0.conv1.weight\"{...}, %\"val_6\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "             5 |  # node__native_batch_norm_legit_no_training_1__0\n",
       "                  %\"getitem_3\"<FLOAT,[1,16,32,32]> ⬅️ ::BatchNormalization(%\"conv2d_1\", %\"layer1.0.bn1.weight\"{...}, %\"layer1.0.bn1.bias\"{...}, %\"layer1.0.bn1.running_mean\"{...}, %\"layer1.0.bn1.running_var\"{...}) {momentum=0.9, epsilon=1e-05}\n",
       "             6 |  # node_relu_1\n",
       "                  %\"relu_1\"<FLOAT,[1,16,32,32]> ⬅️ ::Relu(%\"getitem_3\")\n",
       "             7 |  # node_conv2d_2\n",
       "                  %\"conv2d_2\"<FLOAT,[1,16,32,32]> ⬅️ ::Conv(%\"relu_1\", %\"layer1.0.conv2.weight\"{...}, %\"val_6\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "             8 |  # node__native_batch_norm_legit_no_training_2__0\n",
       "                  %\"getitem_6\"<FLOAT,[1,16,32,32]> ⬅️ ::BatchNormalization(%\"conv2d_2\", %\"layer1.0.bn2.weight\"{...}, %\"layer1.0.bn2.bias\"{...}, %\"layer1.0.bn2.running_mean\"{...}, %\"layer1.0.bn2.running_var\"{...}) {momentum=0.9, epsilon=1e-05}\n",
       "             9 |  # node_add_5\n",
       "                  %\"add_5\"<FLOAT,[1,16,32,32]> ⬅️ ::Add(%\"getitem_6\", %\"relu\")\n",
       "            10 |  # node_relu_2\n",
       "                  %\"relu_2\"<FLOAT,[1,16,32,32]> ⬅️ ::Relu(%\"add_5\")\n",
       "            11 |  # node_conv2d_3\n",
       "                  %\"conv2d_3\"<FLOAT,[1,16,32,32]> ⬅️ ::Conv(%\"relu_2\", %\"layer1.1.conv1.weight\"{...}, %\"val_6\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            12 |  # node__native_batch_norm_legit_no_training_3__0\n",
       "                  %\"getitem_9\"<FLOAT,[1,16,32,32]> ⬅️ ::BatchNormalization(%\"conv2d_3\", %\"layer1.1.bn1.weight\"{...}, %\"layer1.1.bn1.bias\"{...}, %\"layer1.1.bn1.running_mean\"{...}, %\"layer1.1.bn1.running_var\"{...}) {momentum=0.9, epsilon=1e-05}\n",
       "            13 |  # node_relu_3\n",
       "                  %\"relu_3\"<FLOAT,[1,16,32,32]> ⬅️ ::Relu(%\"getitem_9\")\n",
       "            14 |  # node_conv2d_4\n",
       "                  %\"conv2d_4\"<FLOAT,[1,16,32,32]> ⬅️ ::Conv(%\"relu_3\", %\"layer1.1.conv2.weight\"{...}, %\"val_6\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            15 |  # node__native_batch_norm_legit_no_training_4__0\n",
       "                  %\"getitem_12\"<FLOAT,[1,16,32,32]> ⬅️ ::BatchNormalization(%\"conv2d_4\", %\"layer1.1.bn2.weight\"{...}, %\"layer1.1.bn2.bias\"{...}, %\"layer1.1.bn2.running_mean\"{...}, %\"layer1.1.bn2.running_var\"{...}) {momentum=0.9, epsilon=1e-05}\n",
       "            16 |  # node_add_6\n",
       "                  %\"add_6\"<FLOAT,[1,16,32,32]> ⬅️ ::Add(%\"getitem_12\", %\"relu_2\")\n",
       "            17 |  # node_relu_4\n",
       "                  %\"relu_4\"<FLOAT,[1,16,32,32]> ⬅️ ::Relu(%\"add_6\")\n",
       "            18 |  # node_conv2d_5\n",
       "                  %\"conv2d_5\"<FLOAT,[1,16,32,32]> ⬅️ ::Conv(%\"relu_4\", %\"layer1.2.conv1.weight\"{...}, %\"val_6\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            19 |  # node__native_batch_norm_legit_no_training_5__0\n",
       "                  %\"getitem_15\"<FLOAT,[1,16,32,32]> ⬅️ ::BatchNormalization(%\"conv2d_5\", %\"layer1.2.bn1.weight\"{...}, %\"layer1.2.bn1.bias\"{...}, %\"layer1.2.bn1.running_mean\"{...}, %\"layer1.2.bn1.running_var\"{...}) {momentum=0.9, epsilon=1e-05}\n",
       "            20 |  # node_relu_5\n",
       "                  %\"relu_5\"<FLOAT,[1,16,32,32]> ⬅️ ::Relu(%\"getitem_15\")\n",
       "            21 |  # node_conv2d_6\n",
       "                  %\"conv2d_6\"<FLOAT,[1,16,32,32]> ⬅️ ::Conv(%\"relu_5\", %\"layer1.2.conv2.weight\"{...}, %\"val_6\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            22 |  # node__native_batch_norm_legit_no_training_6__0\n",
       "                  %\"getitem_18\"<FLOAT,[1,16,32,32]> ⬅️ ::BatchNormalization(%\"conv2d_6\", %\"layer1.2.bn2.weight\"{...}, %\"layer1.2.bn2.bias\"{...}, %\"layer1.2.bn2.running_mean\"{...}, %\"layer1.2.bn2.running_var\"{...}) {momentum=0.9, epsilon=1e-05}\n",
       "            23 |  # node_add_7\n",
       "                  %\"add_7\"<FLOAT,[1,16,32,32]> ⬅️ ::Add(%\"getitem_18\", %\"relu_4\")\n",
       "            24 |  # node_relu_6\n",
       "                  %\"relu_6\"<FLOAT,[1,16,32,32]> ⬅️ ::Relu(%\"add_7\")\n",
       "            25 |  # node_conv2d_7\n",
       "                  %\"conv2d_7\"<FLOAT,[1,32,16,16]> ⬅️ ::Conv(%\"relu_6\", %\"layer2.0.conv1.weight\"{...}, %\"val_71\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(2, 2), dilations=(1, 1)}\n",
       "            26 |  # node__native_batch_norm_legit_no_training_7__0\n",
       "                  %\"getitem_21\"<FLOAT,[1,32,16,16]> ⬅️ ::BatchNormalization(%\"conv2d_7\", %\"layer2.0.bn1.weight\"{...}, %\"layer2.0.bn1.bias\"{...}, %\"layer2.0.bn1.running_mean\"{...}, %\"layer2.0.bn1.running_var\"{...}) {momentum=0.9, epsilon=1e-05}\n",
       "            27 |  # node_relu_7\n",
       "                  %\"relu_7\"<FLOAT,[1,32,16,16]> ⬅️ ::Relu(%\"getitem_21\")\n",
       "            28 |  # node_conv2d_8\n",
       "                  %\"conv2d_8\"<FLOAT,[1,32,16,16]> ⬅️ ::Conv(%\"relu_7\", %\"layer2.0.conv2.weight\"{...}, %\"val_71\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            29 |  # node__native_batch_norm_legit_no_training_8__0\n",
       "                  %\"getitem_24\"<FLOAT,[1,32,16,16]> ⬅️ ::BatchNormalization(%\"conv2d_8\", %\"layer2.0.bn2.weight\"{...}, %\"layer2.0.bn2.bias\"{...}, %\"layer2.0.bn2.running_mean\"{...}, %\"layer2.0.bn2.running_var\"{...}) {momentum=0.9, epsilon=1e-05}\n",
       "            30 |  # node_conv2d_9\n",
       "                  %\"conv2d_9\"<FLOAT,[1,32,16,16]> ⬅️ ::Conv(%\"relu_6\", %\"layer2.0.downsample.0.weight\"{...}, %\"val_71\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(2, 2), dilations=(1, 1)}\n",
       "            31 |  # node__native_batch_norm_legit_no_training_9__0\n",
       "                  %\"getitem_27\"<FLOAT,[1,32,16,16]> ⬅️ ::BatchNormalization(%\"conv2d_9\", %\"layer2.0.downsample.1.weight\"{...}, %\"layer2.0.bn2.bias\"{...}, %\"layer2.0.downsample.1.running_mean\"{...}, %\"layer2.0.downsample.1.running_var\"{...}) {momentum=0.9, epsilon=1e-05}\n",
       "            32 |  # node_add_8\n",
       "                  %\"add_8\"<FLOAT,[1,32,16,16]> ⬅️ ::Add(%\"getitem_24\", %\"getitem_27\")\n",
       "            33 |  # node_relu_8\n",
       "                  %\"relu_8\"<FLOAT,[1,32,16,16]> ⬅️ ::Relu(%\"add_8\")\n",
       "            34 |  # node_conv2d_10\n",
       "                  %\"conv2d_10\"<FLOAT,[1,32,16,16]> ⬅️ ::Conv(%\"relu_8\", %\"layer2.1.conv1.weight\"{...}, %\"val_71\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            35 |  # node__native_batch_norm_legit_no_training_10__0\n",
       "                  %\"getitem_30\"<FLOAT,[1,32,16,16]> ⬅️ ::BatchNormalization(%\"conv2d_10\", %\"layer2.1.bn1.weight\"{...}, %\"layer2.1.bn1.bias\"{...}, %\"layer2.1.bn1.running_mean\"{...}, %\"layer2.1.bn1.running_var\"{...}) {momentum=0.9, epsilon=1e-05}\n",
       "            36 |  # node_relu_9\n",
       "                  %\"relu_9\"<FLOAT,[1,32,16,16]> ⬅️ ::Relu(%\"getitem_30\")\n",
       "            37 |  # node_conv2d_11\n",
       "                  %\"conv2d_11\"<FLOAT,[1,32,16,16]> ⬅️ ::Conv(%\"relu_9\", %\"layer2.1.conv2.weight\"{...}, %\"val_71\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            38 |  # node__native_batch_norm_legit_no_training_11__0\n",
       "                  %\"getitem_33\"<FLOAT,[1,32,16,16]> ⬅️ ::BatchNormalization(%\"conv2d_11\", %\"layer2.1.bn2.weight\"{...}, %\"layer2.1.bn2.bias\"{...}, %\"layer2.1.bn2.running_mean\"{...}, %\"layer2.1.bn2.running_var\"{...}) {momentum=0.9, epsilon=1e-05}\n",
       "            39 |  # node_add_9\n",
       "                  %\"add_9\"<FLOAT,[1,32,16,16]> ⬅️ ::Add(%\"getitem_33\", %\"relu_8\")\n",
       "            40 |  # node_relu_10\n",
       "                  %\"relu_10\"<FLOAT,[1,32,16,16]> ⬅️ ::Relu(%\"add_9\")\n",
       "            41 |  # node_conv2d_12\n",
       "                  %\"conv2d_12\"<FLOAT,[1,32,16,16]> ⬅️ ::Conv(%\"relu_10\", %\"layer2.2.conv1.weight\"{...}, %\"val_71\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            42 |  # node__native_batch_norm_legit_no_training_12__0\n",
       "                  %\"getitem_36\"<FLOAT,[1,32,16,16]> ⬅️ ::BatchNormalization(%\"conv2d_12\", %\"layer2.2.bn1.weight\"{...}, %\"layer2.2.bn1.bias\"{...}, %\"layer2.2.bn1.running_mean\"{...}, %\"layer2.2.bn1.running_var\"{...}) {momentum=0.9, epsilon=1e-05}\n",
       "            43 |  # node_relu_11\n",
       "                  %\"relu_11\"<FLOAT,[1,32,16,16]> ⬅️ ::Relu(%\"getitem_36\")\n",
       "            44 |  # node_conv2d_13\n",
       "                  %\"conv2d_13\"<FLOAT,[1,32,16,16]> ⬅️ ::Conv(%\"relu_11\", %\"layer2.2.conv2.weight\"{...}, %\"val_71\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            45 |  # node__native_batch_norm_legit_no_training_13__0\n",
       "                  %\"getitem_39\"<FLOAT,[1,32,16,16]> ⬅️ ::BatchNormalization(%\"conv2d_13\", %\"layer2.2.bn2.weight\"{...}, %\"layer2.2.bn2.bias\"{...}, %\"layer2.2.bn2.running_mean\"{...}, %\"layer2.2.bn2.running_var\"{...}) {momentum=0.9, epsilon=1e-05}\n",
       "            46 |  # node_add_10\n",
       "                  %\"add_10\"<FLOAT,[1,32,16,16]> ⬅️ ::Add(%\"getitem_39\", %\"relu_10\")\n",
       "            47 |  # node_relu_12\n",
       "                  %\"relu_12\"<FLOAT,[1,32,16,16]> ⬅️ ::Relu(%\"add_10\")\n",
       "            48 |  # node_conv2d_14\n",
       "                  %\"conv2d_14\"<FLOAT,[1,64,8,8]> ⬅️ ::Conv(%\"relu_12\", %\"layer3.0.conv1.weight\"{...}, %\"val_134\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(2, 2), dilations=(1, 1)}\n",
       "            49 |  # node__native_batch_norm_legit_no_training_14__0\n",
       "                  %\"getitem_42\"<FLOAT,[1,64,8,8]> ⬅️ ::BatchNormalization(%\"conv2d_14\", %\"layer3.0.bn1.weight\"{...}, %\"layer3.0.bn1.bias\"{...}, %\"layer3.0.bn1.running_mean\"{...}, %\"layer3.0.bn1.running_var\"{...}) {momentum=0.9, epsilon=1e-05}\n",
       "            50 |  # node_relu_13\n",
       "                  %\"relu_13\"<FLOAT,[1,64,8,8]> ⬅️ ::Relu(%\"getitem_42\")\n",
       "            51 |  # node_conv2d_15\n",
       "                  %\"conv2d_15\"<FLOAT,[1,64,8,8]> ⬅️ ::Conv(%\"relu_13\", %\"layer3.0.conv2.weight\"{...}, %\"val_134\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            52 |  # node__native_batch_norm_legit_no_training_15__0\n",
       "                  %\"getitem_45\"<FLOAT,[1,64,8,8]> ⬅️ ::BatchNormalization(%\"conv2d_15\", %\"layer3.0.bn2.weight\"{...}, %\"layer3.0.bn2.bias\"{...}, %\"layer3.0.bn2.running_mean\"{...}, %\"layer3.0.bn2.running_var\"{...}) {momentum=0.9, epsilon=1e-05}\n",
       "            53 |  # node_conv2d_16\n",
       "                  %\"conv2d_16\"<FLOAT,[1,64,8,8]> ⬅️ ::Conv(%\"relu_12\", %\"layer3.0.downsample.0.weight\"{...}, %\"val_134\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(2, 2), dilations=(1, 1)}\n",
       "            54 |  # node__native_batch_norm_legit_no_training_16__0\n",
       "                  %\"getitem_48\"<FLOAT,[1,64,8,8]> ⬅️ ::BatchNormalization(%\"conv2d_16\", %\"layer3.0.downsample.1.weight\"{...}, %\"layer3.0.bn2.bias\"{...}, %\"layer3.0.downsample.1.running_mean\"{...}, %\"layer3.0.downsample.1.running_var\"{...}) {momentum=0.9, epsilon=1e-05}\n",
       "            55 |  # node_add_11\n",
       "                  %\"add_11\"<FLOAT,[1,64,8,8]> ⬅️ ::Add(%\"getitem_45\", %\"getitem_48\")\n",
       "            56 |  # node_relu_14\n",
       "                  %\"relu_14\"<FLOAT,[1,64,8,8]> ⬅️ ::Relu(%\"add_11\")\n",
       "            57 |  # node_conv2d_17\n",
       "                  %\"conv2d_17\"<FLOAT,[1,64,8,8]> ⬅️ ::Conv(%\"relu_14\", %\"layer3.1.conv1.weight\"{...}, %\"val_134\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            58 |  # node__native_batch_norm_legit_no_training_17__0\n",
       "                  %\"getitem_51\"<FLOAT,[1,64,8,8]> ⬅️ ::BatchNormalization(%\"conv2d_17\", %\"layer3.1.bn1.weight\"{...}, %\"layer3.1.bn1.bias\"{...}, %\"layer3.1.bn1.running_mean\"{...}, %\"layer3.1.bn1.running_var\"{...}) {momentum=0.9, epsilon=1e-05}\n",
       "            59 |  # node_relu_15\n",
       "                  %\"relu_15\"<FLOAT,[1,64,8,8]> ⬅️ ::Relu(%\"getitem_51\")\n",
       "            60 |  # node_conv2d_18\n",
       "                  %\"conv2d_18\"<FLOAT,[1,64,8,8]> ⬅️ ::Conv(%\"relu_15\", %\"layer3.1.conv2.weight\"{...}, %\"val_134\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            61 |  # node__native_batch_norm_legit_no_training_18__0\n",
       "                  %\"getitem_54\"<FLOAT,[1,64,8,8]> ⬅️ ::BatchNormalization(%\"conv2d_18\", %\"layer3.1.bn2.weight\"{...}, %\"layer3.1.bn2.bias\"{...}, %\"layer3.1.bn2.running_mean\"{...}, %\"layer3.1.bn2.running_var\"{...}) {momentum=0.9, epsilon=1e-05}\n",
       "            62 |  # node_add_12\n",
       "                  %\"add_12\"<FLOAT,[1,64,8,8]> ⬅️ ::Add(%\"getitem_54\", %\"relu_14\")\n",
       "            63 |  # node_relu_16\n",
       "                  %\"relu_16\"<FLOAT,[1,64,8,8]> ⬅️ ::Relu(%\"add_12\")\n",
       "            64 |  # node_conv2d_19\n",
       "                  %\"conv2d_19\"<FLOAT,[1,64,8,8]> ⬅️ ::Conv(%\"relu_16\", %\"layer3.2.conv1.weight\"{...}, %\"val_134\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            65 |  # node__native_batch_norm_legit_no_training_19__0\n",
       "                  %\"getitem_57\"<FLOAT,[1,64,8,8]> ⬅️ ::BatchNormalization(%\"conv2d_19\", %\"layer3.2.bn1.weight\"{...}, %\"layer3.2.bn1.bias\"{...}, %\"layer3.2.bn1.running_mean\"{...}, %\"layer3.2.bn1.running_var\"{...}) {momentum=0.9, epsilon=1e-05}\n",
       "            66 |  # node_relu_17\n",
       "                  %\"relu_17\"<FLOAT,[1,64,8,8]> ⬅️ ::Relu(%\"getitem_57\")\n",
       "            67 |  # node_conv2d_20\n",
       "                  %\"conv2d_20\"<FLOAT,[1,64,8,8]> ⬅️ ::Conv(%\"relu_17\", %\"layer3.2.conv2.weight\"{...}, %\"val_134\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            68 |  # node__native_batch_norm_legit_no_training_20__0\n",
       "                  %\"getitem_60\"<FLOAT,[1,64,8,8]> ⬅️ ::BatchNormalization(%\"conv2d_20\", %\"layer3.2.bn2.weight\"{...}, %\"layer3.2.bn2.bias\"{...}, %\"layer3.2.bn2.running_mean\"{...}, %\"layer3.2.bn2.running_var\"{...}) {momentum=0.9, epsilon=1e-05}\n",
       "            69 |  # node_add_13\n",
       "                  %\"add_13\"<FLOAT,[1,64,8,8]> ⬅️ ::Add(%\"getitem_60\", %\"relu_16\")\n",
       "            70 |  # node_relu_18\n",
       "                  %\"relu_18\"<FLOAT,[1,64,8,8]> ⬅️ ::Relu(%\"add_13\")\n",
       "            71 |  # node_mean\n",
       "                  %\"mean\"<FLOAT,[1,64,1,1]> ⬅️ ::ReduceMean(%\"relu_18\", %\"val_195\"{[-1, -2]}) {noop_with_empty_axes=0, keepdims=1}\n",
       "            72 |  # node_Concat_199\n",
       "                  %\"val_199\"<INT64,[2]> ⬅️ ::Concat(%\"val_0\", %\"val_198\"{[-1]}) {axis=0}\n",
       "            73 |  # node_view\n",
       "                  %\"view\"<FLOAT,[1,64]> ⬅️ ::Reshape(%\"mean\", %\"val_199\") {allowzero=1}\n",
       "            74 |  # node_linear\n",
       "                  %\"output\"<FLOAT,[1,10]> ⬅️ ::Gemm(%\"view\", %\"fc.weight\"{...}, %\"fc.bias\"{[-0.008414060808718204, -0.008147068321704865, 0.040229786187410355, 0.0165706854313612, 0.005398356355726719, -0.021945152431726456, 0.01621832512319088, -0.019912585616111755, 0.011514868587255478, -0.03153958544135094]}) {beta=1.0, transB=1, alpha=1.0, transA=0}\n",
       "            return %\"output\"<FLOAT,[1,10]>\n",
       "        }\n",
       "\n",
       "\n",
       "    ,\n",
       "    exported_program=\n",
       "        ExportedProgram:\n",
       "            class GraphModule(torch.nn.Module):\n",
       "                def forward(self, p_conv1_weight: \"f32[16, 3, 3, 3]\", p_bn1_weight: \"f32[16]\", p_bn1_bias: \"f32[16]\", p_layer1_0_conv1_weight: \"f32[16, 16, 3, 3]\", p_layer1_0_bn1_weight: \"f32[16]\", p_layer1_0_bn1_bias: \"f32[16]\", p_layer1_0_conv2_weight: \"f32[16, 16, 3, 3]\", p_layer1_0_bn2_weight: \"f32[16]\", p_layer1_0_bn2_bias: \"f32[16]\", p_layer1_1_conv1_weight: \"f32[16, 16, 3, 3]\", p_layer1_1_bn1_weight: \"f32[16]\", p_layer1_1_bn1_bias: \"f32[16]\", p_layer1_1_conv2_weight: \"f32[16, 16, 3, 3]\", p_layer1_1_bn2_weight: \"f32[16]\", p_layer1_1_bn2_bias: \"f32[16]\", p_layer1_2_conv1_weight: \"f32[16, 16, 3, 3]\", p_layer1_2_bn1_weight: \"f32[16]\", p_layer1_2_bn1_bias: \"f32[16]\", p_layer1_2_conv2_weight: \"f32[16, 16, 3, 3]\", p_layer1_2_bn2_weight: \"f32[16]\", p_layer1_2_bn2_bias: \"f32[16]\", p_layer2_0_conv1_weight: \"f32[32, 16, 3, 3]\", p_layer2_0_bn1_weight: \"f32[32]\", p_layer2_0_bn1_bias: \"f32[32]\", p_layer2_0_conv2_weight: \"f32[32, 32, 3, 3]\", p_layer2_0_bn2_weight: \"f32[32]\", p_layer2_0_bn2_bias: \"f32[32]\", p_layer2_0_downsample_0_weight: \"f32[32, 16, 1, 1]\", p_layer2_0_downsample_1_weight: \"f32[32]\", p_layer2_0_downsample_1_bias: \"f32[32]\", p_layer2_1_conv1_weight: \"f32[32, 32, 3, 3]\", p_layer2_1_bn1_weight: \"f32[32]\", p_layer2_1_bn1_bias: \"f32[32]\", p_layer2_1_conv2_weight: \"f32[32, 32, 3, 3]\", p_layer2_1_bn2_weight: \"f32[32]\", p_layer2_1_bn2_bias: \"f32[32]\", p_layer2_2_conv1_weight: \"f32[32, 32, 3, 3]\", p_layer2_2_bn1_weight: \"f32[32]\", p_layer2_2_bn1_bias: \"f32[32]\", p_layer2_2_conv2_weight: \"f32[32, 32, 3, 3]\", p_layer2_2_bn2_weight: \"f32[32]\", p_layer2_2_bn2_bias: \"f32[32]\", p_layer3_0_conv1_weight: \"f32[64, 32, 3, 3]\", p_layer3_0_bn1_weight: \"f32[64]\", p_layer3_0_bn1_bias: \"f32[64]\", p_layer3_0_conv2_weight: \"f32[64, 64, 3, 3]\", p_layer3_0_bn2_weight: \"f32[64]\", p_layer3_0_bn2_bias: \"f32[64]\", p_layer3_0_downsample_0_weight: \"f32[64, 32, 1, 1]\", p_layer3_0_downsample_1_weight: \"f32[64]\", p_layer3_0_downsample_1_bias: \"f32[64]\", p_layer3_1_conv1_weight: \"f32[64, 64, 3, 3]\", p_layer3_1_bn1_weight: \"f32[64]\", p_layer3_1_bn1_bias: \"f32[64]\", p_layer3_1_conv2_weight: \"f32[64, 64, 3, 3]\", p_layer3_1_bn2_weight: \"f32[64]\", p_layer3_1_bn2_bias: \"f32[64]\", p_layer3_2_conv1_weight: \"f32[64, 64, 3, 3]\", p_layer3_2_bn1_weight: \"f32[64]\", p_layer3_2_bn1_bias: \"f32[64]\", p_layer3_2_conv2_weight: \"f32[64, 64, 3, 3]\", p_layer3_2_bn2_weight: \"f32[64]\", p_layer3_2_bn2_bias: \"f32[64]\", p_fc_weight: \"f32[10, 64]\", p_fc_bias: \"f32[10]\", b_bn1_running_mean: \"f32[16]\", b_bn1_running_var: \"f32[16]\", b_bn1_num_batches_tracked: \"i64[]\", b_layer1_0_bn1_running_mean: \"f32[16]\", b_layer1_0_bn1_running_var: \"f32[16]\", b_layer1_0_bn1_num_batches_tracked: \"i64[]\", b_layer1_0_bn2_running_mean: \"f32[16]\", b_layer1_0_bn2_running_var: \"f32[16]\", b_layer1_0_bn2_num_batches_tracked: \"i64[]\", b_layer1_1_bn1_running_mean: \"f32[16]\", b_layer1_1_bn1_running_var: \"f32[16]\", b_layer1_1_bn1_num_batches_tracked: \"i64[]\", b_layer1_1_bn2_running_mean: \"f32[16]\", b_layer1_1_bn2_running_var: \"f32[16]\", b_layer1_1_bn2_num_batches_tracked: \"i64[]\", b_layer1_2_bn1_running_mean: \"f32[16]\", b_layer1_2_bn1_running_var: \"f32[16]\", b_layer1_2_bn1_num_batches_tracked: \"i64[]\", b_layer1_2_bn2_running_mean: \"f32[16]\", b_layer1_2_bn2_running_var: \"f32[16]\", b_layer1_2_bn2_num_batches_tracked: \"i64[]\", b_layer2_0_bn1_running_mean: \"f32[32]\", b_layer2_0_bn1_running_var: \"f32[32]\", b_layer2_0_bn1_num_batches_tracked: \"i64[]\", b_layer2_0_bn2_running_mean: \"f32[32]\", b_layer2_0_bn2_running_var: \"f32[32]\", b_layer2_0_bn2_num_batches_tracked: \"i64[]\", b_layer2_0_downsample_1_running_mean: \"f32[32]\", b_layer2_0_downsample_1_running_var: \"f32[32]\", b_layer2_0_downsample_1_num_batches_tracked: \"i64[]\", b_layer2_1_bn1_running_mean: \"f32[32]\", b_layer2_1_bn1_running_var: \"f32[32]\", b_layer2_1_bn1_num_batches_tracked: \"i64[]\", b_layer2_1_bn2_running_mean: \"f32[32]\", b_layer2_1_bn2_running_var: \"f32[32]\", b_layer2_1_bn2_num_batches_tracked: \"i64[]\", b_layer2_2_bn1_running_mean: \"f32[32]\", b_layer2_2_bn1_running_var: \"f32[32]\", b_layer2_2_bn1_num_batches_tracked: \"i64[]\", b_layer2_2_bn2_running_mean: \"f32[32]\", b_layer2_2_bn2_running_var: \"f32[32]\", b_layer2_2_bn2_num_batches_tracked: \"i64[]\", b_layer3_0_bn1_running_mean: \"f32[64]\", b_layer3_0_bn1_running_var: \"f32[64]\", b_layer3_0_bn1_num_batches_tracked: \"i64[]\", b_layer3_0_bn2_running_mean: \"f32[64]\", b_layer3_0_bn2_running_var: \"f32[64]\", b_layer3_0_bn2_num_batches_tracked: \"i64[]\", b_layer3_0_downsample_1_running_mean: \"f32[64]\", b_layer3_0_downsample_1_running_var: \"f32[64]\", b_layer3_0_downsample_1_num_batches_tracked: \"i64[]\", b_layer3_1_bn1_running_mean: \"f32[64]\", b_layer3_1_bn1_running_var: \"f32[64]\", b_layer3_1_bn1_num_batches_tracked: \"i64[]\", b_layer3_1_bn2_running_mean: \"f32[64]\", b_layer3_1_bn2_running_var: \"f32[64]\", b_layer3_1_bn2_num_batches_tracked: \"i64[]\", b_layer3_2_bn1_running_mean: \"f32[64]\", b_layer3_2_bn1_running_var: \"f32[64]\", b_layer3_2_bn1_num_batches_tracked: \"i64[]\", b_layer3_2_bn2_running_mean: \"f32[64]\", b_layer3_2_bn2_running_var: \"f32[64]\", b_layer3_2_bn2_num_batches_tracked: \"i64[]\", x: \"f32[s77, 3, 32, 32]\"):\n",
       "                     # \n",
       "                    sym_size_int_1: \"Sym(s77)\" = torch.ops.aten.sym_size.int(x, 0)\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d: \"f32[s77, 16, 32, 32]\" = torch.ops.aten.conv2d.default(x, p_conv1_weight, None, [1, 1], [1, 1]);  x = p_conv1_weight = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d, p_bn1_weight, p_bn1_bias, b_bn1_running_mean, b_bn1_running_var, 0.1, 1e-05);  conv2d = p_bn1_weight = p_bn1_bias = b_bn1_running_mean = b_bn1_running_var = None\n",
       "                    getitem: \"f32[1, 16, 32, 32]\" = _native_batch_norm_legit_no_training[0];  _native_batch_norm_legit_no_training = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu: \"f32[1, 16, 32, 32]\" = torch.ops.aten.relu.default(getitem);  getitem = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_1: \"f32[1, 16, 32, 32]\" = torch.ops.aten.conv2d.default(relu, p_layer1_0_conv1_weight, None, [1, 1], [1, 1]);  p_layer1_0_conv1_weight = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_1 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_1, p_layer1_0_bn1_weight, p_layer1_0_bn1_bias, b_layer1_0_bn1_running_mean, b_layer1_0_bn1_running_var, 0.1, 1e-05);  conv2d_1 = p_layer1_0_bn1_weight = p_layer1_0_bn1_bias = b_layer1_0_bn1_running_mean = b_layer1_0_bn1_running_var = None\n",
       "                    getitem_3: \"f32[1, 16, 32, 32]\" = _native_batch_norm_legit_no_training_1[0];  _native_batch_norm_legit_no_training_1 = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_1: \"f32[1, 16, 32, 32]\" = torch.ops.aten.relu.default(getitem_3);  getitem_3 = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_2: \"f32[1, 16, 32, 32]\" = torch.ops.aten.conv2d.default(relu_1, p_layer1_0_conv2_weight, None, [1, 1], [1, 1]);  relu_1 = p_layer1_0_conv2_weight = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_2 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_2, p_layer1_0_bn2_weight, p_layer1_0_bn2_bias, b_layer1_0_bn2_running_mean, b_layer1_0_bn2_running_var, 0.1, 1e-05);  conv2d_2 = p_layer1_0_bn2_weight = p_layer1_0_bn2_bias = b_layer1_0_bn2_running_mean = b_layer1_0_bn2_running_var = None\n",
       "                    getitem_6: \"f32[1, 16, 32, 32]\" = _native_batch_norm_legit_no_training_2[0];  _native_batch_norm_legit_no_training_2 = None\n",
       "            \n",
       "                     # File: /home/lois/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master/pytorch_cifar_models/resnet.py:96 in forward, code: out += identity\n",
       "                    add_5: \"f32[1, 16, 32, 32]\" = torch.ops.aten.add.Tensor(getitem_6, relu);  getitem_6 = relu = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_2: \"f32[1, 16, 32, 32]\" = torch.ops.aten.relu.default(add_5);  add_5 = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_3: \"f32[1, 16, 32, 32]\" = torch.ops.aten.conv2d.default(relu_2, p_layer1_1_conv1_weight, None, [1, 1], [1, 1]);  p_layer1_1_conv1_weight = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_3 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_3, p_layer1_1_bn1_weight, p_layer1_1_bn1_bias, b_layer1_1_bn1_running_mean, b_layer1_1_bn1_running_var, 0.1, 1e-05);  conv2d_3 = p_layer1_1_bn1_weight = p_layer1_1_bn1_bias = b_layer1_1_bn1_running_mean = b_layer1_1_bn1_running_var = None\n",
       "                    getitem_9: \"f32[1, 16, 32, 32]\" = _native_batch_norm_legit_no_training_3[0];  _native_batch_norm_legit_no_training_3 = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_3: \"f32[1, 16, 32, 32]\" = torch.ops.aten.relu.default(getitem_9);  getitem_9 = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_4: \"f32[1, 16, 32, 32]\" = torch.ops.aten.conv2d.default(relu_3, p_layer1_1_conv2_weight, None, [1, 1], [1, 1]);  relu_3 = p_layer1_1_conv2_weight = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_4 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_4, p_layer1_1_bn2_weight, p_layer1_1_bn2_bias, b_layer1_1_bn2_running_mean, b_layer1_1_bn2_running_var, 0.1, 1e-05);  conv2d_4 = p_layer1_1_bn2_weight = p_layer1_1_bn2_bias = b_layer1_1_bn2_running_mean = b_layer1_1_bn2_running_var = None\n",
       "                    getitem_12: \"f32[1, 16, 32, 32]\" = _native_batch_norm_legit_no_training_4[0];  _native_batch_norm_legit_no_training_4 = None\n",
       "            \n",
       "                     # File: /home/lois/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master/pytorch_cifar_models/resnet.py:96 in forward, code: out += identity\n",
       "                    add_6: \"f32[1, 16, 32, 32]\" = torch.ops.aten.add.Tensor(getitem_12, relu_2);  getitem_12 = relu_2 = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_4: \"f32[1, 16, 32, 32]\" = torch.ops.aten.relu.default(add_6);  add_6 = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_5: \"f32[1, 16, 32, 32]\" = torch.ops.aten.conv2d.default(relu_4, p_layer1_2_conv1_weight, None, [1, 1], [1, 1]);  p_layer1_2_conv1_weight = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_5 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_5, p_layer1_2_bn1_weight, p_layer1_2_bn1_bias, b_layer1_2_bn1_running_mean, b_layer1_2_bn1_running_var, 0.1, 1e-05);  conv2d_5 = p_layer1_2_bn1_weight = p_layer1_2_bn1_bias = b_layer1_2_bn1_running_mean = b_layer1_2_bn1_running_var = None\n",
       "                    getitem_15: \"f32[1, 16, 32, 32]\" = _native_batch_norm_legit_no_training_5[0];  _native_batch_norm_legit_no_training_5 = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_5: \"f32[1, 16, 32, 32]\" = torch.ops.aten.relu.default(getitem_15);  getitem_15 = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_6: \"f32[1, 16, 32, 32]\" = torch.ops.aten.conv2d.default(relu_5, p_layer1_2_conv2_weight, None, [1, 1], [1, 1]);  relu_5 = p_layer1_2_conv2_weight = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_6 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_6, p_layer1_2_bn2_weight, p_layer1_2_bn2_bias, b_layer1_2_bn2_running_mean, b_layer1_2_bn2_running_var, 0.1, 1e-05);  conv2d_6 = p_layer1_2_bn2_weight = p_layer1_2_bn2_bias = b_layer1_2_bn2_running_mean = b_layer1_2_bn2_running_var = None\n",
       "                    getitem_18: \"f32[1, 16, 32, 32]\" = _native_batch_norm_legit_no_training_6[0];  _native_batch_norm_legit_no_training_6 = None\n",
       "            \n",
       "                     # File: /home/lois/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master/pytorch_cifar_models/resnet.py:96 in forward, code: out += identity\n",
       "                    add_7: \"f32[1, 16, 32, 32]\" = torch.ops.aten.add.Tensor(getitem_18, relu_4);  getitem_18 = relu_4 = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_6: \"f32[1, 16, 32, 32]\" = torch.ops.aten.relu.default(add_7);  add_7 = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_7: \"f32[1, 32, 16, 16]\" = torch.ops.aten.conv2d.default(relu_6, p_layer2_0_conv1_weight, None, [2, 2], [1, 1]);  p_layer2_0_conv1_weight = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_7 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_7, p_layer2_0_bn1_weight, p_layer2_0_bn1_bias, b_layer2_0_bn1_running_mean, b_layer2_0_bn1_running_var, 0.1, 1e-05);  conv2d_7 = p_layer2_0_bn1_weight = p_layer2_0_bn1_bias = b_layer2_0_bn1_running_mean = b_layer2_0_bn1_running_var = None\n",
       "                    getitem_21: \"f32[1, 32, 16, 16]\" = _native_batch_norm_legit_no_training_7[0];  _native_batch_norm_legit_no_training_7 = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_7: \"f32[1, 32, 16, 16]\" = torch.ops.aten.relu.default(getitem_21);  getitem_21 = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_8: \"f32[1, 32, 16, 16]\" = torch.ops.aten.conv2d.default(relu_7, p_layer2_0_conv2_weight, None, [1, 1], [1, 1]);  relu_7 = p_layer2_0_conv2_weight = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_8 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_8, p_layer2_0_bn2_weight, p_layer2_0_bn2_bias, b_layer2_0_bn2_running_mean, b_layer2_0_bn2_running_var, 0.1, 1e-05);  conv2d_8 = p_layer2_0_bn2_weight = p_layer2_0_bn2_bias = b_layer2_0_bn2_running_mean = b_layer2_0_bn2_running_var = None\n",
       "                    getitem_24: \"f32[1, 32, 16, 16]\" = _native_batch_norm_legit_no_training_8[0];  _native_batch_norm_legit_no_training_8 = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_9: \"f32[1, 32, 16, 16]\" = torch.ops.aten.conv2d.default(relu_6, p_layer2_0_downsample_0_weight, None, [2, 2]);  relu_6 = p_layer2_0_downsample_0_weight = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_9 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_9, p_layer2_0_downsample_1_weight, p_layer2_0_downsample_1_bias, b_layer2_0_downsample_1_running_mean, b_layer2_0_downsample_1_running_var, 0.1, 1e-05);  conv2d_9 = p_layer2_0_downsample_1_weight = p_layer2_0_downsample_1_bias = b_layer2_0_downsample_1_running_mean = b_layer2_0_downsample_1_running_var = None\n",
       "                    getitem_27: \"f32[1, 32, 16, 16]\" = _native_batch_norm_legit_no_training_9[0];  _native_batch_norm_legit_no_training_9 = None\n",
       "            \n",
       "                     # File: /home/lois/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master/pytorch_cifar_models/resnet.py:96 in forward, code: out += identity\n",
       "                    add_8: \"f32[1, 32, 16, 16]\" = torch.ops.aten.add.Tensor(getitem_24, getitem_27);  getitem_24 = getitem_27 = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_8: \"f32[1, 32, 16, 16]\" = torch.ops.aten.relu.default(add_8);  add_8 = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_10: \"f32[1, 32, 16, 16]\" = torch.ops.aten.conv2d.default(relu_8, p_layer2_1_conv1_weight, None, [1, 1], [1, 1]);  p_layer2_1_conv1_weight = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_10 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_10, p_layer2_1_bn1_weight, p_layer2_1_bn1_bias, b_layer2_1_bn1_running_mean, b_layer2_1_bn1_running_var, 0.1, 1e-05);  conv2d_10 = p_layer2_1_bn1_weight = p_layer2_1_bn1_bias = b_layer2_1_bn1_running_mean = b_layer2_1_bn1_running_var = None\n",
       "                    getitem_30: \"f32[1, 32, 16, 16]\" = _native_batch_norm_legit_no_training_10[0];  _native_batch_norm_legit_no_training_10 = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_9: \"f32[1, 32, 16, 16]\" = torch.ops.aten.relu.default(getitem_30);  getitem_30 = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_11: \"f32[1, 32, 16, 16]\" = torch.ops.aten.conv2d.default(relu_9, p_layer2_1_conv2_weight, None, [1, 1], [1, 1]);  relu_9 = p_layer2_1_conv2_weight = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_11 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_11, p_layer2_1_bn2_weight, p_layer2_1_bn2_bias, b_layer2_1_bn2_running_mean, b_layer2_1_bn2_running_var, 0.1, 1e-05);  conv2d_11 = p_layer2_1_bn2_weight = p_layer2_1_bn2_bias = b_layer2_1_bn2_running_mean = b_layer2_1_bn2_running_var = None\n",
       "                    getitem_33: \"f32[1, 32, 16, 16]\" = _native_batch_norm_legit_no_training_11[0];  _native_batch_norm_legit_no_training_11 = None\n",
       "            \n",
       "                     # File: /home/lois/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master/pytorch_cifar_models/resnet.py:96 in forward, code: out += identity\n",
       "                    add_9: \"f32[1, 32, 16, 16]\" = torch.ops.aten.add.Tensor(getitem_33, relu_8);  getitem_33 = relu_8 = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_10: \"f32[1, 32, 16, 16]\" = torch.ops.aten.relu.default(add_9);  add_9 = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_12: \"f32[1, 32, 16, 16]\" = torch.ops.aten.conv2d.default(relu_10, p_layer2_2_conv1_weight, None, [1, 1], [1, 1]);  p_layer2_2_conv1_weight = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_12 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_12, p_layer2_2_bn1_weight, p_layer2_2_bn1_bias, b_layer2_2_bn1_running_mean, b_layer2_2_bn1_running_var, 0.1, 1e-05);  conv2d_12 = p_layer2_2_bn1_weight = p_layer2_2_bn1_bias = b_layer2_2_bn1_running_mean = b_layer2_2_bn1_running_var = None\n",
       "                    getitem_36: \"f32[1, 32, 16, 16]\" = _native_batch_norm_legit_no_training_12[0];  _native_batch_norm_legit_no_training_12 = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_11: \"f32[1, 32, 16, 16]\" = torch.ops.aten.relu.default(getitem_36);  getitem_36 = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_13: \"f32[1, 32, 16, 16]\" = torch.ops.aten.conv2d.default(relu_11, p_layer2_2_conv2_weight, None, [1, 1], [1, 1]);  relu_11 = p_layer2_2_conv2_weight = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_13 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_13, p_layer2_2_bn2_weight, p_layer2_2_bn2_bias, b_layer2_2_bn2_running_mean, b_layer2_2_bn2_running_var, 0.1, 1e-05);  conv2d_13 = p_layer2_2_bn2_weight = p_layer2_2_bn2_bias = b_layer2_2_bn2_running_mean = b_layer2_2_bn2_running_var = None\n",
       "                    getitem_39: \"f32[1, 32, 16, 16]\" = _native_batch_norm_legit_no_training_13[0];  _native_batch_norm_legit_no_training_13 = None\n",
       "            \n",
       "                     # File: /home/lois/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master/pytorch_cifar_models/resnet.py:96 in forward, code: out += identity\n",
       "                    add_10: \"f32[1, 32, 16, 16]\" = torch.ops.aten.add.Tensor(getitem_39, relu_10);  getitem_39 = relu_10 = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_12: \"f32[1, 32, 16, 16]\" = torch.ops.aten.relu.default(add_10);  add_10 = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_14: \"f32[1, 64, 8, 8]\" = torch.ops.aten.conv2d.default(relu_12, p_layer3_0_conv1_weight, None, [2, 2], [1, 1]);  p_layer3_0_conv1_weight = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_14 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_14, p_layer3_0_bn1_weight, p_layer3_0_bn1_bias, b_layer3_0_bn1_running_mean, b_layer3_0_bn1_running_var, 0.1, 1e-05);  conv2d_14 = p_layer3_0_bn1_weight = p_layer3_0_bn1_bias = b_layer3_0_bn1_running_mean = b_layer3_0_bn1_running_var = None\n",
       "                    getitem_42: \"f32[1, 64, 8, 8]\" = _native_batch_norm_legit_no_training_14[0];  _native_batch_norm_legit_no_training_14 = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_13: \"f32[1, 64, 8, 8]\" = torch.ops.aten.relu.default(getitem_42);  getitem_42 = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_15: \"f32[1, 64, 8, 8]\" = torch.ops.aten.conv2d.default(relu_13, p_layer3_0_conv2_weight, None, [1, 1], [1, 1]);  relu_13 = p_layer3_0_conv2_weight = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_15 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_15, p_layer3_0_bn2_weight, p_layer3_0_bn2_bias, b_layer3_0_bn2_running_mean, b_layer3_0_bn2_running_var, 0.1, 1e-05);  conv2d_15 = p_layer3_0_bn2_weight = p_layer3_0_bn2_bias = b_layer3_0_bn2_running_mean = b_layer3_0_bn2_running_var = None\n",
       "                    getitem_45: \"f32[1, 64, 8, 8]\" = _native_batch_norm_legit_no_training_15[0];  _native_batch_norm_legit_no_training_15 = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_16: \"f32[1, 64, 8, 8]\" = torch.ops.aten.conv2d.default(relu_12, p_layer3_0_downsample_0_weight, None, [2, 2]);  relu_12 = p_layer3_0_downsample_0_weight = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_16 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_16, p_layer3_0_downsample_1_weight, p_layer3_0_downsample_1_bias, b_layer3_0_downsample_1_running_mean, b_layer3_0_downsample_1_running_var, 0.1, 1e-05);  conv2d_16 = p_layer3_0_downsample_1_weight = p_layer3_0_downsample_1_bias = b_layer3_0_downsample_1_running_mean = b_layer3_0_downsample_1_running_var = None\n",
       "                    getitem_48: \"f32[1, 64, 8, 8]\" = _native_batch_norm_legit_no_training_16[0];  _native_batch_norm_legit_no_training_16 = None\n",
       "            \n",
       "                     # File: /home/lois/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master/pytorch_cifar_models/resnet.py:96 in forward, code: out += identity\n",
       "                    add_11: \"f32[1, 64, 8, 8]\" = torch.ops.aten.add.Tensor(getitem_45, getitem_48);  getitem_45 = getitem_48 = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_14: \"f32[1, 64, 8, 8]\" = torch.ops.aten.relu.default(add_11);  add_11 = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_17: \"f32[1, 64, 8, 8]\" = torch.ops.aten.conv2d.default(relu_14, p_layer3_1_conv1_weight, None, [1, 1], [1, 1]);  p_layer3_1_conv1_weight = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_17 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_17, p_layer3_1_bn1_weight, p_layer3_1_bn1_bias, b_layer3_1_bn1_running_mean, b_layer3_1_bn1_running_var, 0.1, 1e-05);  conv2d_17 = p_layer3_1_bn1_weight = p_layer3_1_bn1_bias = b_layer3_1_bn1_running_mean = b_layer3_1_bn1_running_var = None\n",
       "                    getitem_51: \"f32[1, 64, 8, 8]\" = _native_batch_norm_legit_no_training_17[0];  _native_batch_norm_legit_no_training_17 = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_15: \"f32[1, 64, 8, 8]\" = torch.ops.aten.relu.default(getitem_51);  getitem_51 = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_18: \"f32[1, 64, 8, 8]\" = torch.ops.aten.conv2d.default(relu_15, p_layer3_1_conv2_weight, None, [1, 1], [1, 1]);  relu_15 = p_layer3_1_conv2_weight = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_18 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_18, p_layer3_1_bn2_weight, p_layer3_1_bn2_bias, b_layer3_1_bn2_running_mean, b_layer3_1_bn2_running_var, 0.1, 1e-05);  conv2d_18 = p_layer3_1_bn2_weight = p_layer3_1_bn2_bias = b_layer3_1_bn2_running_mean = b_layer3_1_bn2_running_var = None\n",
       "                    getitem_54: \"f32[1, 64, 8, 8]\" = _native_batch_norm_legit_no_training_18[0];  _native_batch_norm_legit_no_training_18 = None\n",
       "            \n",
       "                     # File: /home/lois/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master/pytorch_cifar_models/resnet.py:96 in forward, code: out += identity\n",
       "                    add_12: \"f32[1, 64, 8, 8]\" = torch.ops.aten.add.Tensor(getitem_54, relu_14);  getitem_54 = relu_14 = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_16: \"f32[1, 64, 8, 8]\" = torch.ops.aten.relu.default(add_12);  add_12 = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_19: \"f32[1, 64, 8, 8]\" = torch.ops.aten.conv2d.default(relu_16, p_layer3_2_conv1_weight, None, [1, 1], [1, 1]);  p_layer3_2_conv1_weight = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_19 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_19, p_layer3_2_bn1_weight, p_layer3_2_bn1_bias, b_layer3_2_bn1_running_mean, b_layer3_2_bn1_running_var, 0.1, 1e-05);  conv2d_19 = p_layer3_2_bn1_weight = p_layer3_2_bn1_bias = b_layer3_2_bn1_running_mean = b_layer3_2_bn1_running_var = None\n",
       "                    getitem_57: \"f32[1, 64, 8, 8]\" = _native_batch_norm_legit_no_training_19[0];  _native_batch_norm_legit_no_training_19 = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_17: \"f32[1, 64, 8, 8]\" = torch.ops.aten.relu.default(getitem_57);  getitem_57 = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_20: \"f32[1, 64, 8, 8]\" = torch.ops.aten.conv2d.default(relu_17, p_layer3_2_conv2_weight, None, [1, 1], [1, 1]);  relu_17 = p_layer3_2_conv2_weight = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_20 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_20, p_layer3_2_bn2_weight, p_layer3_2_bn2_bias, b_layer3_2_bn2_running_mean, b_layer3_2_bn2_running_var, 0.1, 1e-05);  conv2d_20 = p_layer3_2_bn2_weight = p_layer3_2_bn2_bias = b_layer3_2_bn2_running_mean = b_layer3_2_bn2_running_var = None\n",
       "                    getitem_60: \"f32[1, 64, 8, 8]\" = _native_batch_norm_legit_no_training_20[0];  _native_batch_norm_legit_no_training_20 = None\n",
       "            \n",
       "                     # File: /home/lois/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master/pytorch_cifar_models/resnet.py:96 in forward, code: out += identity\n",
       "                    add_13: \"f32[1, 64, 8, 8]\" = torch.ops.aten.add.Tensor(getitem_60, relu_16);  getitem_60 = relu_16 = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_18: \"f32[1, 64, 8, 8]\" = torch.ops.aten.relu.default(add_13);  add_13 = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/pooling.py:1500 in forward, code: return F.adaptive_avg_pool2d(input, self.output_size)\n",
       "                    mean: \"f32[1, 64, 1, 1]\" = torch.ops.aten.mean.dim(relu_18, [-1, -2], True);  relu_18 = None\n",
       "            \n",
       "                     # File: /home/lois/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master/pytorch_cifar_models/resnet.py:151 in forward, code: x = x.view(x.size(0), -1)\n",
       "                    view: \"f32[1, 64]\" = torch.ops.aten.view.default(mean, [sym_size_int_1, -1]);  mean = sym_size_int_1 = None\n",
       "            \n",
       "                     # File: /home/lois/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear: \"f32[1, 10]\" = torch.ops.aten.linear.default(view, p_fc_weight, p_fc_bias);  view = p_fc_weight = p_fc_bias = None\n",
       "                    return (linear,)\n",
       "            \n",
       "        Graph signature: \n",
       "            # inputs\n",
       "            p_conv1_weight: PARAMETER target='conv1.weight'\n",
       "            p_bn1_weight: PARAMETER target='bn1.weight'\n",
       "            p_bn1_bias: PARAMETER target='bn1.bias'\n",
       "            p_layer1_0_conv1_weight: PARAMETER target='layer1.0.conv1.weight'\n",
       "            p_layer1_0_bn1_weight: PARAMETER target='layer1.0.bn1.weight'\n",
       "            p_layer1_0_bn1_bias: PARAMETER target='layer1.0.bn1.bias'\n",
       "            p_layer1_0_conv2_weight: PARAMETER target='layer1.0.conv2.weight'\n",
       "            p_layer1_0_bn2_weight: PARAMETER target='layer1.0.bn2.weight'\n",
       "            p_layer1_0_bn2_bias: PARAMETER target='layer1.0.bn2.bias'\n",
       "            p_layer1_1_conv1_weight: PARAMETER target='layer1.1.conv1.weight'\n",
       "            p_layer1_1_bn1_weight: PARAMETER target='layer1.1.bn1.weight'\n",
       "            p_layer1_1_bn1_bias: PARAMETER target='layer1.1.bn1.bias'\n",
       "            p_layer1_1_conv2_weight: PARAMETER target='layer1.1.conv2.weight'\n",
       "            p_layer1_1_bn2_weight: PARAMETER target='layer1.1.bn2.weight'\n",
       "            p_layer1_1_bn2_bias: PARAMETER target='layer1.1.bn2.bias'\n",
       "            p_layer1_2_conv1_weight: PARAMETER target='layer1.2.conv1.weight'\n",
       "            p_layer1_2_bn1_weight: PARAMETER target='layer1.2.bn1.weight'\n",
       "            p_layer1_2_bn1_bias: PARAMETER target='layer1.2.bn1.bias'\n",
       "            p_layer1_2_conv2_weight: PARAMETER target='layer1.2.conv2.weight'\n",
       "            p_layer1_2_bn2_weight: PARAMETER target='layer1.2.bn2.weight'\n",
       "            p_layer1_2_bn2_bias: PARAMETER target='layer1.2.bn2.bias'\n",
       "            p_layer2_0_conv1_weight: PARAMETER target='layer2.0.conv1.weight'\n",
       "            p_layer2_0_bn1_weight: PARAMETER target='layer2.0.bn1.weight'\n",
       "            p_layer2_0_bn1_bias: PARAMETER target='layer2.0.bn1.bias'\n",
       "            p_layer2_0_conv2_weight: PARAMETER target='layer2.0.conv2.weight'\n",
       "            p_layer2_0_bn2_weight: PARAMETER target='layer2.0.bn2.weight'\n",
       "            p_layer2_0_bn2_bias: PARAMETER target='layer2.0.bn2.bias'\n",
       "            p_layer2_0_downsample_0_weight: PARAMETER target='layer2.0.downsample.0.weight'\n",
       "            p_layer2_0_downsample_1_weight: PARAMETER target='layer2.0.downsample.1.weight'\n",
       "            p_layer2_0_downsample_1_bias: PARAMETER target='layer2.0.downsample.1.bias'\n",
       "            p_layer2_1_conv1_weight: PARAMETER target='layer2.1.conv1.weight'\n",
       "            p_layer2_1_bn1_weight: PARAMETER target='layer2.1.bn1.weight'\n",
       "            p_layer2_1_bn1_bias: PARAMETER target='layer2.1.bn1.bias'\n",
       "            p_layer2_1_conv2_weight: PARAMETER target='layer2.1.conv2.weight'\n",
       "            p_layer2_1_bn2_weight: PARAMETER target='layer2.1.bn2.weight'\n",
       "            p_layer2_1_bn2_bias: PARAMETER target='layer2.1.bn2.bias'\n",
       "            p_layer2_2_conv1_weight: PARAMETER target='layer2.2.conv1.weight'\n",
       "            p_layer2_2_bn1_weight: PARAMETER target='layer2.2.bn1.weight'\n",
       "            p_layer2_2_bn1_bias: PARAMETER target='layer2.2.bn1.bias'\n",
       "            p_layer2_2_conv2_weight: PARAMETER target='layer2.2.conv2.weight'\n",
       "            p_layer2_2_bn2_weight: PARAMETER target='layer2.2.bn2.weight'\n",
       "            p_layer2_2_bn2_bias: PARAMETER target='layer2.2.bn2.bias'\n",
       "            p_layer3_0_conv1_weight: PARAMETER target='layer3.0.conv1.weight'\n",
       "            p_layer3_0_bn1_weight: PARAMETER target='layer3.0.bn1.weight'\n",
       "            p_layer3_0_bn1_bias: PARAMETER target='layer3.0.bn1.bias'\n",
       "            p_layer3_0_conv2_weight: PARAMETER target='layer3.0.conv2.weight'\n",
       "            p_layer3_0_bn2_weight: PARAMETER target='layer3.0.bn2.weight'\n",
       "            p_layer3_0_bn2_bias: PARAMETER target='layer3.0.bn2.bias'\n",
       "            p_layer3_0_downsample_0_weight: PARAMETER target='layer3.0.downsample.0.weight'\n",
       "            p_layer3_0_downsample_1_weight: PARAMETER target='layer3.0.downsample.1.weight'\n",
       "            p_layer3_0_downsample_1_bias: PARAMETER target='layer3.0.downsample.1.bias'\n",
       "            p_layer3_1_conv1_weight: PARAMETER target='layer3.1.conv1.weight'\n",
       "            p_layer3_1_bn1_weight: PARAMETER target='layer3.1.bn1.weight'\n",
       "            p_layer3_1_bn1_bias: PARAMETER target='layer3.1.bn1.bias'\n",
       "            p_layer3_1_conv2_weight: PARAMETER target='layer3.1.conv2.weight'\n",
       "            p_layer3_1_bn2_weight: PARAMETER target='layer3.1.bn2.weight'\n",
       "            p_layer3_1_bn2_bias: PARAMETER target='layer3.1.bn2.bias'\n",
       "            p_layer3_2_conv1_weight: PARAMETER target='layer3.2.conv1.weight'\n",
       "            p_layer3_2_bn1_weight: PARAMETER target='layer3.2.bn1.weight'\n",
       "            p_layer3_2_bn1_bias: PARAMETER target='layer3.2.bn1.bias'\n",
       "            p_layer3_2_conv2_weight: PARAMETER target='layer3.2.conv2.weight'\n",
       "            p_layer3_2_bn2_weight: PARAMETER target='layer3.2.bn2.weight'\n",
       "            p_layer3_2_bn2_bias: PARAMETER target='layer3.2.bn2.bias'\n",
       "            p_fc_weight: PARAMETER target='fc.weight'\n",
       "            p_fc_bias: PARAMETER target='fc.bias'\n",
       "            b_bn1_running_mean: BUFFER target='bn1.running_mean' persistent=True\n",
       "            b_bn1_running_var: BUFFER target='bn1.running_var' persistent=True\n",
       "            b_bn1_num_batches_tracked: BUFFER target='bn1.num_batches_tracked' persistent=True\n",
       "            b_layer1_0_bn1_running_mean: BUFFER target='layer1.0.bn1.running_mean' persistent=True\n",
       "            b_layer1_0_bn1_running_var: BUFFER target='layer1.0.bn1.running_var' persistent=True\n",
       "            b_layer1_0_bn1_num_batches_tracked: BUFFER target='layer1.0.bn1.num_batches_tracked' persistent=True\n",
       "            b_layer1_0_bn2_running_mean: BUFFER target='layer1.0.bn2.running_mean' persistent=True\n",
       "            b_layer1_0_bn2_running_var: BUFFER target='layer1.0.bn2.running_var' persistent=True\n",
       "            b_layer1_0_bn2_num_batches_tracked: BUFFER target='layer1.0.bn2.num_batches_tracked' persistent=True\n",
       "            b_layer1_1_bn1_running_mean: BUFFER target='layer1.1.bn1.running_mean' persistent=True\n",
       "            b_layer1_1_bn1_running_var: BUFFER target='layer1.1.bn1.running_var' persistent=True\n",
       "            b_layer1_1_bn1_num_batches_tracked: BUFFER target='layer1.1.bn1.num_batches_tracked' persistent=True\n",
       "            b_layer1_1_bn2_running_mean: BUFFER target='layer1.1.bn2.running_mean' persistent=True\n",
       "            b_layer1_1_bn2_running_var: BUFFER target='layer1.1.bn2.running_var' persistent=True\n",
       "            b_layer1_1_bn2_num_batches_tracked: BUFFER target='layer1.1.bn2.num_batches_tracked' persistent=True\n",
       "            b_layer1_2_bn1_running_mean: BUFFER target='layer1.2.bn1.running_mean' persistent=True\n",
       "            b_layer1_2_bn1_running_var: BUFFER target='layer1.2.bn1.running_var' persistent=True\n",
       "            b_layer1_2_bn1_num_batches_tracked: BUFFER target='layer1.2.bn1.num_batches_tracked' persistent=True\n",
       "            b_layer1_2_bn2_running_mean: BUFFER target='layer1.2.bn2.running_mean' persistent=True\n",
       "            b_layer1_2_bn2_running_var: BUFFER target='layer1.2.bn2.running_var' persistent=True\n",
       "            b_layer1_2_bn2_num_batches_tracked: BUFFER target='layer1.2.bn2.num_batches_tracked' persistent=True\n",
       "            b_layer2_0_bn1_running_mean: BUFFER target='layer2.0.bn1.running_mean' persistent=True\n",
       "            b_layer2_0_bn1_running_var: BUFFER target='layer2.0.bn1.running_var' persistent=True\n",
       "            b_layer2_0_bn1_num_batches_tracked: BUFFER target='layer2.0.bn1.num_batches_tracked' persistent=True\n",
       "            b_layer2_0_bn2_running_mean: BUFFER target='layer2.0.bn2.running_mean' persistent=True\n",
       "            b_layer2_0_bn2_running_var: BUFFER target='layer2.0.bn2.running_var' persistent=True\n",
       "            b_layer2_0_bn2_num_batches_tracked: BUFFER target='layer2.0.bn2.num_batches_tracked' persistent=True\n",
       "            b_layer2_0_downsample_1_running_mean: BUFFER target='layer2.0.downsample.1.running_mean' persistent=True\n",
       "            b_layer2_0_downsample_1_running_var: BUFFER target='layer2.0.downsample.1.running_var' persistent=True\n",
       "            b_layer2_0_downsample_1_num_batches_tracked: BUFFER target='layer2.0.downsample.1.num_batches_tracked' persistent=True\n",
       "            b_layer2_1_bn1_running_mean: BUFFER target='layer2.1.bn1.running_mean' persistent=True\n",
       "            b_layer2_1_bn1_running_var: BUFFER target='layer2.1.bn1.running_var' persistent=True\n",
       "            b_layer2_1_bn1_num_batches_tracked: BUFFER target='layer2.1.bn1.num_batches_tracked' persistent=True\n",
       "            b_layer2_1_bn2_running_mean: BUFFER target='layer2.1.bn2.running_mean' persistent=True\n",
       "            b_layer2_1_bn2_running_var: BUFFER target='layer2.1.bn2.running_var' persistent=True\n",
       "            b_layer2_1_bn2_num_batches_tracked: BUFFER target='layer2.1.bn2.num_batches_tracked' persistent=True\n",
       "            b_layer2_2_bn1_running_mean: BUFFER target='layer2.2.bn1.running_mean' persistent=True\n",
       "            b_layer2_2_bn1_running_var: BUFFER target='layer2.2.bn1.running_var' persistent=True\n",
       "            b_layer2_2_bn1_num_batches_tracked: BUFFER target='layer2.2.bn1.num_batches_tracked' persistent=True\n",
       "            b_layer2_2_bn2_running_mean: BUFFER target='layer2.2.bn2.running_mean' persistent=True\n",
       "            b_layer2_2_bn2_running_var: BUFFER target='layer2.2.bn2.running_var' persistent=True\n",
       "            b_layer2_2_bn2_num_batches_tracked: BUFFER target='layer2.2.bn2.num_batches_tracked' persistent=True\n",
       "            b_layer3_0_bn1_running_mean: BUFFER target='layer3.0.bn1.running_mean' persistent=True\n",
       "            b_layer3_0_bn1_running_var: BUFFER target='layer3.0.bn1.running_var' persistent=True\n",
       "            b_layer3_0_bn1_num_batches_tracked: BUFFER target='layer3.0.bn1.num_batches_tracked' persistent=True\n",
       "            b_layer3_0_bn2_running_mean: BUFFER target='layer3.0.bn2.running_mean' persistent=True\n",
       "            b_layer3_0_bn2_running_var: BUFFER target='layer3.0.bn2.running_var' persistent=True\n",
       "            b_layer3_0_bn2_num_batches_tracked: BUFFER target='layer3.0.bn2.num_batches_tracked' persistent=True\n",
       "            b_layer3_0_downsample_1_running_mean: BUFFER target='layer3.0.downsample.1.running_mean' persistent=True\n",
       "            b_layer3_0_downsample_1_running_var: BUFFER target='layer3.0.downsample.1.running_var' persistent=True\n",
       "            b_layer3_0_downsample_1_num_batches_tracked: BUFFER target='layer3.0.downsample.1.num_batches_tracked' persistent=True\n",
       "            b_layer3_1_bn1_running_mean: BUFFER target='layer3.1.bn1.running_mean' persistent=True\n",
       "            b_layer3_1_bn1_running_var: BUFFER target='layer3.1.bn1.running_var' persistent=True\n",
       "            b_layer3_1_bn1_num_batches_tracked: BUFFER target='layer3.1.bn1.num_batches_tracked' persistent=True\n",
       "            b_layer3_1_bn2_running_mean: BUFFER target='layer3.1.bn2.running_mean' persistent=True\n",
       "            b_layer3_1_bn2_running_var: BUFFER target='layer3.1.bn2.running_var' persistent=True\n",
       "            b_layer3_1_bn2_num_batches_tracked: BUFFER target='layer3.1.bn2.num_batches_tracked' persistent=True\n",
       "            b_layer3_2_bn1_running_mean: BUFFER target='layer3.2.bn1.running_mean' persistent=True\n",
       "            b_layer3_2_bn1_running_var: BUFFER target='layer3.2.bn1.running_var' persistent=True\n",
       "            b_layer3_2_bn1_num_batches_tracked: BUFFER target='layer3.2.bn1.num_batches_tracked' persistent=True\n",
       "            b_layer3_2_bn2_running_mean: BUFFER target='layer3.2.bn2.running_mean' persistent=True\n",
       "            b_layer3_2_bn2_running_var: BUFFER target='layer3.2.bn2.running_var' persistent=True\n",
       "            b_layer3_2_bn2_num_batches_tracked: BUFFER target='layer3.2.bn2.num_batches_tracked' persistent=True\n",
       "            x: USER_INPUT\n",
       "    \n",
       "            # outputs\n",
       "            linear: USER_OUTPUT\n",
       "    \n",
       "        Range constraints: {s77: VR[0, int_oo]}\n",
       "\n",
       ")"
      ]
     },
     "execution_count": 1064,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = \"model/cifar.onnx\"\n",
    "\n",
    "model_cifar.eval()\n",
    "dummy_input = torch.randn(1, 3, 32, 32)\n",
    "torch.onnx.export(\n",
    "    model_cifar,\n",
    "    dummy_input,\n",
    "    file_name,\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"output\"],\n",
    "    opset_version=18,\n",
    "    dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1065,
   "id": "181e7b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
     ]
    }
   ],
   "source": [
    "correct_onnx(\"model/cifar.onnx\", \"model/cifar.cleaned.onnx\")\n",
    "quantize_dynamic(\n",
    "    model_input=\"model/cifar.cleaned.onnx\",\n",
    "    model_output=\"model/cifar.quant.onnx\",\n",
    "    weight_type=QuantType.QInt8,\n",
    "    per_channel=False,\n",
    "    reduce_range=False,\n",
    "    op_types_to_quantize=[\"MatMul\", \"Gemm\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1067,
   "id": "266367df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        model   batch=1   batch=8  batch=32  batch=128  accuracy\n",
      "0     pytorch  0.002717  0.007248  0.016593   0.059894    0.9260\n",
      "1        onnx  0.000380  0.001936  0.007319   0.026405    0.9260\n",
      "2  onnx_quant  0.000417  0.001880  0.006753   0.026463    0.9257\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "ort_session_cifar = ort.InferenceSession(\"model/cifar.cleaned.onnx\")\n",
    "ort_session_cifar_quant = ort.InferenceSession(\"model/cifar.quant.onnx\")\n",
    "\n",
    "model_cifar.eval()\n",
    "\n",
    "batch_sizes = [1, 8, 32, 128]\n",
    "\n",
    "models_bm = [\n",
    "    (\"pytorch\", model_cifar, benchmark_torch),\n",
    "    (\"onnx\", ort_session_cifar, benchmark_onnx),\n",
    "    (\"onnx_quant\", ort_session_cifar_quant, benchmark_onnx),\n",
    "]\n",
    "\n",
    "df_cifar = benchmark_models(models_bm, cifar10_test)\n",
    "print(df_cifar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3649d63",
   "metadata": {},
   "source": [
    "Expliquer le principe du quantization aware training et la méthode Straight Through Estimator. \n",
    "\n",
    "Pour cela vous pouvez vous appuyer sur la lecture de la section G.1 (à partir de la fin de la page 8) de l'article suivante : https://arxiv.org/pdf/2103.13630.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906b693b",
   "metadata": {},
   "source": [
    "Le Quantization Aware Training consiste à entraîner un réseau en simulant la quantization pour qu’il s’y adapte, et la méthode du Straight Through Estimator permet de propager les gradients à travers la quantization en approximant la dérivée de l’opération de round par l’identité.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "f18c7528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "id": "1e77886b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize(float_value, min_range, max_range,  zero = 0):\n",
    "    bits = 8\n",
    "    qmin = - (1 << (bits - 1))\n",
    "    qmax = (1 << (bits - 1)) - 1\n",
    "\n",
    "    S = (max_range - min_range) / (qmax - qmin)\n",
    "    zero_point = np.round(qmin - min_range / S).astype(np.int8)\n",
    "\n",
    "    Q = np.round(float_value / S + zero_point).astype(np.int8)\n",
    "    return Q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "id": "39f6338a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S: -127.5\n",
      "Zero point: 0\n",
      "[-1.  0.  2.  3.  4.  5.]\n",
      "[-26   0  51  76 102 127]\n"
     ]
    }
   ],
   "source": [
    "float_value = np.array([-1.0, 0, 2.0, 3.0, 4.0, 5.0], dtype=np.float32)\n",
    "min_range = -5.0\n",
    "max_range = 5.0\n",
    "quantized_values = quantize(float_value, min_range, max_range, zero = 0)\n",
    "print(float_value)\n",
    "print(quantized_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "id": "eb5108c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_float(uint_values, min_range, max_range):\n",
    "    bits = 8\n",
    "    qmin = - (1 << (bits - 1))\n",
    "    qmax = (1 << (bits - 1)) - 1\n",
    "\n",
    "    S = (max_range - min_range) / (qmax - qmin)\n",
    "    zero_point = np.round(qmin - min_range / S).astype(np.int8)\n",
    "\n",
    "    F = S * (uint_values.astype(np.float32) - zero_point)\n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "id": "1ee311a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.0196079  0.         2.         2.9803922  4.         4.9803925]\n"
     ]
    }
   ],
   "source": [
    "restored_float_values = to_float(quantized_values, min_range, max_range)\n",
    "print(restored_float_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "id": "974a2389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_error_histogram(values, min, max):\n",
    "    quantized_values = quantize(values, min, max, zero = 0)\n",
    "    restored_values = to_float(quantized_values, min, max)\n",
    "    errors = values - restored_values\n",
    "    plt.hist(errors, bins=100, edgecolor='black')\n",
    "    plt.title(\"Quantization Error Histogram\")\n",
    "    plt.xlabel(\"Error\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "id": "f1556cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantization_error_stats(values, min, max):\n",
    "    quantized_values = quantize(values, min, max, zero = 0)\n",
    "    restored_values = to_float(quantized_values, min, max)\n",
    "    errors = values - restored_values\n",
    "    print(f\"Mean error: {np.mean(errors)}\")\n",
    "    print(f\"Standard deviation : {np.std(errors)}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "id": "3a09aff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean error: -1.5031545785859635e-08\n",
      "Standard deviation : 0.001132344827055931\n"
     ]
    }
   ],
   "source": [
    "# Situation 1\n",
    "array = np.linspace(0, 0.5, 1000, dtype=np.float32)\n",
    "min_range = 0\n",
    "max_range = 1\n",
    "display_error_histogram(array, min_range, max_range)\n",
    "quantization_error_stats(array, min_range, max_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "id": "4d717070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean error: -3.8479993236251175e-06\n",
      "Standard deviation : 0.0011439853115007281\n"
     ]
    }
   ],
   "source": [
    "# Situation 1bis\n",
    "array = np.random.uniform(0, 1, 1000).astype(np.float32)\n",
    "min_range = 0\n",
    "max_range = 1\n",
    "display_error_histogram(array, min_range, max_range)\n",
    "quantization_error_stats(array, min_range, max_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "id": "676c2d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHHCAYAAABZbpmkAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAOUlJREFUeJzt3XlclOX+//H3sA3K6gZoIu4SLvnIyqbcMpLUY5aeNjfseFoUK6U6ZXlcK81KLUPtdBTyWx7LskXzmEtqpZhGWqZmmQuagLmxuLDevz/6MacRVBgGBm5fz8djHjnXfd33/bmvGeLNfV/3jMUwDEMAAAAm5eHuAgAAACoTYQcAAJgaYQcAAJgaYQcAAJgaYQcAAJgaYQcAAJgaYQcAAJgaYQcAAJgaYQcAAJgaYQcwkR49eqhHjx5XzH6vJBaLRZMmTXJ3GUCNRNgB/r9du3ZpyJAhuuqqq2S1WtWoUSMNGTJEu3fvdndpDnbv3q1Jkybp4MGDV8R+L2XDhg2yWCwXfSxZssTdJZZq0qRJslgsOn78eKnLmzZtqr/85S8V3s/ixYs1e/bsCm8HqOm83F0AUB0sW7ZM999/v+rWrasRI0aoWbNmOnjwoBYsWKAPPvhA7733nvr37+/uMiX9ETomT56sHj16qGnTpg7LVq9ebbr9lsVjjz2m66+/vkS7zWZzQzWV49y5c/LyKt//shcvXqwff/xRY8aMqZyigBqCsIMr3q+//qqhQ4eqefPm+vLLL9WgQQP7sscff1xdu3bVkCFD9MMPP6hZs2ZurPTyfHx8rqj9Fuvatav++te/lmudoqIi5eXlydfXt8SyM2fOyM/Pr0I1nT17VrVr167QNv6stDqrO1eMI+AKXMbCFe/ll1/W2bNn9a9//csh6EhS/fr19eabbyonJ0cvv/yyvX348OElzm5I/7s88WeJiYnq2bOnQkJCZLVaFRUVpXnz5pVYt/jSxddff60bbrhBvr6+at68uRYtWmTvk5SUpLvvvluSdMstt9gv12zYsEFSybkzTZs2veglnuJ1Dh06pFGjRqlNmzaqVauW6tWrp7vvvtvhclV59ytJx44d04gRIxQaGipfX19dc801evvttx36HDx4UBaLRa+88or+9a9/qUWLFrJarbr++uu1bdu2EmNUERaLRaNHj9a7776rtm3bymq1atWqVUpKSpLFYtHGjRs1atQohYSEqHHjxvb15s6da+/fqFEjxcXF6fTp0w7b7tGjh9q1a6eUlBR169ZNtWvX1rPPPuvy+v88Zyc7O1tjxoxR06ZNZbVaFRISottuu03fffedvabPPvtMhw4dsr9ef37PluX1kaQTJ05o6NChCgwMVHBwsGJjY/X999/LYrEoKSnJ3m/48OHy9/fXr7/+qj59+iggIECDBw+WJH311Ve6++671aRJE1mtVoWHh2vs2LE6d+6cw76Kt5Gamqq//OUv8vf311VXXaWEhARJ0s6dO9WzZ0/5+fkpIiJCixcvdtHowuw4s4Mr3vLly9W0aVN17dq11OXdunVT06ZNtXz5cs2dO7fc2583b57atm2rO+64Q15eXlq+fLlGjRqloqIixcXFOfTdt2+f/vrXv2rEiBGKjY3VwoULNXz4cHXq1Elt27ZVt27d9Nhjj+n111/Xs88+q6uvvlqS7P+90OzZs5WTk+PQNmvWLO3YsUP16tWTJG3btk2bN2/Wfffdp8aNG+vgwYOaN2+eevTood27d6t27drl3u+5c+fUo0cP7du3T6NHj1azZs20dOlSDR8+XKdPn9bjjz/u0H/x4sXKzs7Www8/LIvFohkzZmjAgAHav3+/vL29LzvG2dnZpc5/qVevnkP4/OKLL/T+++9r9OjRql+/vpo2baodO3ZIkkaNGqUGDRpowoQJOnPmjKQ/wuvkyZMVHR2tkSNHau/evZo3b562bdumTZs2OdR24sQJ9e7dW/fdd5+GDBmi0NDQy9Z98uTJUtuLioouu+4jjzyiDz74QKNHj1ZUVJROnDihr7/+Wnv27NG1116r5557TpmZmTpy5IhmzZolSfL395dU9tenqKhI/fr109atWzVy5EhFRkbqk08+UWxsbKk1FRQUKCYmRl26dNErr7xiP7O1dOlSnT17ViNHjlS9evW0detWzZkzR0eOHNHSpUsdtlFYWKjevXurW7dumjFjht59912NHj1afn5+eu655zR48GANGDBA8+fP17Bhw2Sz2ar9GVdUAwZwBTt9+rQhyejfv/8l+91xxx2GJCMrK8swDMOIjY01IiIiSvSbOHGiceGP1dmzZ0v0i4mJMZo3b+7QFhERYUgyvvzyS3vbsWPHDKvVajzxxBP2tqVLlxqSjPXr15fYbvfu3Y3u3btf9Djef/99Q5IxZcqUS9aXnJxsSDIWLVrk1H5nz55tSDLeeecde1teXp5hs9kMf39/+zgeOHDAkGTUq1fPOHnypL3vJ598Ykgyli9fftFjMQzDWL9+vSHpoo+0tDR7X0mGh4eHsWvXLodtJCYmGpKMLl26GAUFBfb2Y8eOGT4+PkavXr2MwsJCe/sbb7xhSDIWLlzocPySjPnz51+y3mLF75NLPfr27euwjiRj4sSJ9udBQUFGXFzcJffTt2/fUt+nZX19PvzwQ0OSMXv2bHu/wsJCo2fPnoYkIzEx0d4eGxtrSDKeeeaZEvsr7T02bdo0w2KxGIcOHSqxjRdffNHedurUKaNWrVqGxWIxlixZYm//6aefSowJcDFcxsIVLTs7W5IUEBBwyX7Fy4v7l0etWrXs/87MzNTx48fVvXt37d+/X5mZmQ59o6KiHM4wNWjQQG3atNH+/fvLvd8L7d69W3/729/Uv39/jR8/vtT68vPzdeLECbVs2VLBwcH2SyLltXLlSoWFhen++++3t3l7e+uxxx5TTk6ONm7c6ND/3nvvVZ06dezPi8egrMc9YcIErVmzpsSjbt26Dv26d++uqKioUrfx4IMPytPT0/587dq1ysvL05gxY+Th4eHQLzAwUJ999pnD+larVQ888ECZ6i324Ycfllp3Wc4KBQcH65tvvtHRo0fLtU+p7K/PqlWr5O3trQcffNDez8PDo8QZyT8bOXJkibY/v8fOnDmj48eP66abbpJhGNq+fXuJ/n//+9/t/w4ODlabNm3k5+ene+65x97epk0bBQcHu+RnA+bHZSxc0coaYrKzs2WxWFS/fv1y72PTpk2aOHGikpOTdfbsWYdlmZmZCgoKsj9v0qRJifXr1KmjU6dOlXu/f5aVlaUBAwboqquu0qJFixwu7Zw7d07Tpk1TYmKifvvtNxmG4VCfMw4dOqRWrVo5hATpf5e9Dh065NB+4XEXB5+yHnf79u0VHR192X6Xutxx4bLiGtu0aePQ7uPjo+bNm5c4hquuuqrcE7W7detW6nuqLJORZ8yYodjYWIWHh6tTp07q06ePhg0bpubNm1923bK+PocOHVLDhg1LTLRu2bJlqdv18vJymO9ULDU1VRMmTNCnn35a4jW98D3m6+tbYu5cUFCQGjduXGI+XFBQUIV/NnBlIOzgihYUFKRGjRrphx9+uGS/H374QY0bN7b/Mrvwf7rFCgsLHZ7/+uuvuvXWWxUZGamZM2cqPDxcPj4+WrlypWbNmlVibsafzyz82Z8DiDOGDx+uo0ePauvWrQoMDHRY9uijjyoxMVFjxoyRzWZTUFCQLBaL7rvvvjLNHXGFyjruC/35DEN5llV025XhnnvuUdeuXfXRRx9p9erVevnll/XSSy9p2bJl6t27d5XWUsxqtZYIUIWFhbrtttt08uRJPf3004qMjJSfn59+++03DR8+vMw/A1X1HoE5EXZwxevXr5/efPNNff311+rSpUuJ5V999ZUOHjyo+Ph4e1udOnVK3JEjlTxjsXz5cuXm5urTTz91OHuxfv16p+u9WNC6mOnTp+vjjz/WsmXLFBkZWWL5Bx98oNjYWL366qv2tvPnz5c4vvLsNyIiQj/88IOKioocfvn99NNP9uXVXXGNe/fudThbkpeXpwMHDpTpTFJla9iwoUaNGqVRo0bp2LFjuvbaa/XCCy/Yw87FXrOyvj4RERFav359idvo9+3bV+Yad+7cqZ9//llvv/22hg0bZm9fs2ZN2Q8UqCDm7OCK9+STT6p27dp6+OGHdeLECYdlJ0+e1COPPKLAwECNHj3a3t6iRQtlZmY6nBFKS0vTRx995LB+8V+jF14aSkxMdLre4s8tKS1sXWjt2rUaP368nnvuOd15552l9vH09Czx1/GcOXNKnKUqz3779Omj9PR0vffee/a2goICzZkzR/7+/urevftlt+Fu0dHR8vHx0euvv+4wPgsWLFBmZqb69u3rttoKCwtLXP4JCQlRo0aNlJuba2/z8/Mr9VJkWV+fmJgY5efn66233rL3Kyoqst8KXhal/QwYhqHXXnutzNsAKoozO7jitWzZUosWLdL999+v9u3bl/gE5VOnTmnJkiUOczruu+8+Pf3007rrrrv02GOP6ezZs5o3b55at27tMKm3V69e8vHxUb9+/fTwww8rJydHb731lkJCQpSWluZUvR07dpSnp6deeuklZWZmymq12j/H50L333+/GjRooFatWumdd95xWHbbbbcpNDRUf/nLX/R///d/CgoKUlRUlJKTk7V27Vr7renO7Pehhx7Sm2++qeHDhyslJUVNmzbVBx98oE2bNmn27NmXnRBeXl999ZXOnz9for1Dhw7q0KGDU9ts0KCBxo0bp8mTJ+v222/XHXfcob1792ru3Lm6/vrrNWTIkIqW7bTs7Gw1btxYf/3rX3XNNdfI399fa9eu1bZt2xzO0HXq1Envvfee4uPjdf3118vf31/9+vUr8+tz55136oYbbtATTzyhffv2KTIyUp9++qn9lvmynO2LjIxUixYt9OSTT+q3335TYGCgPvzwQ+baoGq56zYwoLrZuXOnMWjQICMsLMzw8PAwJBm+vr4lblUutnr1aqNdu3aGj4+P0aZNG+Odd94p9dbzTz/91OjQoYPh6+trNG3a1HjppZeMhQsXGpKMAwcO2PtFRESUuN3YMEq/nfytt94ymjdvbnh6ejrcDn5hX13i1ubidU6dOmU88MADRv369Q1/f38jJibG+Omnn4yIiAgjNjbWqf0ahmFkZGTYt+vj42O0b9/e4VZlw/jfrecvv/xyieNWGW4rvtyt539eX1Kpt2oX33q+bdu2UvfxxhtvGJGRkYa3t7cRGhpqjBw50jh16pRDn+7duxtt27a9ZK1/Vvw++f3330tdXtp74c/Hk5ubazz11FPGNddcYwQEBBh+fn7GNddcY8ydO9dhnZycHGPQoEFGcHCwIcnhNvSyvD6GYRi///67MWjQICMgIMAICgoyhg8fbmzatMmQ5HAreGxsrOHn51fq8ezevduIjo42/P39jfr16xsPPvig8f3335d6+3pp27jY+F7sZwa4kMUwmN0FlGbRokUaPny4hgwZ4vApxsCV7uOPP9Zdd92lr7/+WjfffLO7ywEui8tYwEUMGzZMaWlpeuaZZ9S4cWO9+OKL7i4JqHLnzp1zuNOssLBQc+bMUWBgoK699lo3VgaUHWd2AAAX9fe//13nzp2TzWZTbm6uli1bps2bN+vFF1/UuHHj3F0eUCaEHQDARS1evFivvvqq9u3bp/Pnz6tly5YaOXKkw92JQHVH2AEAAKbG5+wAAABTI+wAAABT424s/fGJoEePHlVAQEC5P4ofAAC4h2EYys7OVqNGjUp8L9ufEXYkHT16VOHh4e4uAwAAOOHw4cNq3LjxRZcTdiT7R6MfPny4xDdCAwCA6ikrK0vh4eGX/Qoawo7+9/0ugYGBhB0AAGqYy01BYYIyAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNbeGnUmTJslisTg8IiMj7cvPnz+vuLg41atXT/7+/ho4cKAyMjIctpGamqq+ffuqdu3aCgkJ0VNPPaWCgoKqPhQAAFBNuf2LQNu2bau1a9fan3t5/a+ksWPH6rPPPtPSpUsVFBSk0aNHa8CAAdq0aZMkqbCwUH379lVYWJg2b96stLQ0DRs2TN7e3nrxxRer/FgAAED14/aw4+XlpbCwsBLtmZmZWrBggRYvXqyePXtKkhITE3X11Vdry5YtuvHGG7V69Wrt3r1ba9euVWhoqDp27KipU6fq6aef1qRJk+Tj41PVhwMAAKoZt8/Z+eWXX9SoUSM1b95cgwcPVmpqqiQpJSVF+fn5io6OtveNjIxUkyZNlJycLElKTk5W+/btFRoaau8TExOjrKws7dq166L7zM3NVVZWlsOjsqSmpuq7775zeBQfIwAAqHxuPbPTuXNnJSUlqU2bNkpLS9PkyZPVtWtX/fjjj0pPT5ePj4+Cg4Md1gkNDVV6erokKT093SHoFC8vXnYx06ZN0+TJk117MKVITU1Vm8irdf7cWYd231q1tfenPWrSpEml1wAAQFVLTU3V8ePH7c/r16/v1t95bg07vXv3tv+7Q4cO6ty5syIiIvT++++rVq1albbfcePGKT4+3v48KytL4eHhLt/P8ePHdf7cWdX7yxPyrvfH9vNPHNaJFa/q+PHjhB0AgOmU9oe+u//Id/ucnT8LDg5W69attW/fPt12223Ky8vT6dOnHc7uZGRk2Of4hIWFaevWrQ7bKL5bq7R5QMWsVqusVqvrD+AivOuFyxrWssr2BwCAu1z4h351+CPf7XN2/iwnJ0e//vqrGjZsqE6dOsnb21vr1q2zL9+7d69SU1Nls9kkSTabTTt37tSxY8fsfdasWaPAwEBFRUVVef0AAOAPxX/oF1/ZcCe3ntl58skn1a9fP0VEROjo0aOaOHGiPD09df/99ysoKEgjRoxQfHy86tatq8DAQD366KOy2Wy68cYbJUm9evVSVFSUhg4dqhkzZig9PV3jx49XXFxclZ65AQAA1Zdbw86RI0d0//3368SJE2rQoIG6dOmiLVu2qEGDBpKkWbNmycPDQwMHDlRubq5iYmI0d+5c+/qenp5asWKFRo4cKZvNJj8/P8XGxmrKlCnuOiQAAFDNuDXsLFmy5JLLfX19lZCQoISEhIv2iYiI0MqVK11dGgAAMIlqNWcHAADA1Qg7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1KpN2Jk+fbosFovGjBljbzt//rzi4uJUr149+fv7a+DAgcrIyHBYLzU1VX379lXt2rUVEhKip556SgUFBVVcPQAAqK6qRdjZtm2b3nzzTXXo0MGhfezYsVq+fLmWLl2qjRs36ujRoxowYIB9eWFhofr27au8vDxt3rxZb7/9tpKSkjRhwoSqPgQAAFBNuT3s5OTkaPDgwXrrrbdUp04de3tmZqYWLFigmTNnqmfPnurUqZMSExO1efNmbdmyRZK0evVq7d69W++88446duyo3r17a+rUqUpISFBeXp67DgkAAFQjbg87cXFx6tu3r6Kjox3aU1JSlJ+f79AeGRmpJk2aKDk5WZKUnJys9u3bKzQ01N4nJiZGWVlZ2rVrV9UcAAAAqNa83LnzJUuW6LvvvtO2bdtKLEtPT5ePj4+Cg4Md2kNDQ5Wenm7v8+egU7y8eNnF5ObmKjc31/48KyvL2UMAAADVnNvO7Bw+fFiPP/643n33Xfn6+lbpvqdNm6agoCD7Izw8vEr3DwAAqo7bwk5KSoqOHTuma6+9Vl5eXvLy8tLGjRv1+uuvy8vLS6GhocrLy9Pp06cd1svIyFBYWJgkKSwsrMTdWcXPi/uUZty4ccrMzLQ/Dh8+7NqDAwAA1Ybbws6tt96qnTt3aseOHfbHddddp8GDB9v/7e3trXXr1tnX2bt3r1JTU2Wz2SRJNptNO3fu1LFjx+x91qxZo8DAQEVFRV1031arVYGBgQ4PAABgTm6bsxMQEKB27do5tPn5+alevXr29hEjRig+Pl5169ZVYGCgHn30UdlsNt14442SpF69eikqKkpDhw7VjBkzlJ6ervHjxysuLk5Wq7XKjwkAAFQ/bp2gfDmzZs2Sh4eHBg4cqNzcXMXExGju3Ln25Z6enlqxYoVGjhwpm80mPz8/xcbGasqUKW6sGgAAVCfVKuxs2LDB4bmvr68SEhKUkJBw0XUiIiK0cuXKSq4MAADUVG7/nB0AAIDKRNgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACm5lTY2b9/v6vrAAAAqBROhZ2WLVvqlltu0TvvvKPz58+7uiYAAACXcSrsfPfdd+rQoYPi4+MVFhamhx9+WFu3bnV1bQAAABXmVNjp2LGjXnvtNR09elQLFy5UWlqaunTponbt2mnmzJn6/fffy7SdefPmqUOHDgoMDFRgYKBsNpv++9//2pefP39ecXFxqlevnvz9/TVw4EBlZGQ4bCM1NVV9+/ZV7dq1FRISoqeeekoFBQXOHBYAADChCk1Q9vLy0oABA7R06VK99NJL2rdvn5588kmFh4dr2LBhSktLu+T6jRs31vTp05WSkqJvv/1WPXv2VP/+/bVr1y5J0tixY7V8+XItXbpUGzdu1NGjRzVgwAD7+oWFherbt6/y8vK0efNmvf3220pKStKECRMqclgAAMBEKhR2vv32W40aNUoNGzbUzJkz9eSTT+rXX3/VmjVrdPToUfXv3/+S6/fr1099+vRRq1at1Lp1a73wwgvy9/fXli1blJmZqQULFmjmzJnq2bOnOnXqpMTERG3evFlbtmyRJK1evVq7d+/WO++8o44dO6p3796aOnWqEhISlJeXV5FDAwAAJuFU2Jk5c6bat2+vm266SUePHtWiRYt06NAhPf/882rWrJm6du2qpKQkfffdd2XeZmFhoZYsWaIzZ87IZrMpJSVF+fn5io6OtveJjIxUkyZNlJycLElKTk5W+/btFRoaau8TExOjrKws+9mh0uTm5iorK8vhAQAAzMnLmZXmzZunv/3tbxo+fLgaNmxYap+QkBAtWLDgstvauXOnbDabzp8/L39/f3300UeKiorSjh075OPjo+DgYIf+oaGhSk9PlySlp6c7BJ3i5cXLLmbatGmaPHnyZWsDAAA1n1Nh55dffrlsHx8fH8XGxl62X5s2bbRjxw5lZmbqgw8+UGxsrDZu3OhMWWU2btw4xcfH259nZWUpPDy8UvcJAADcw6mwk5iYKH9/f919990O7UuXLtXZs2fLFHKK+fj4qGXLlpKkTp06adu2bXrttdd07733Ki8vT6dPn3Y4u5ORkaGwsDBJUlhYWIlb3ovv1iruUxqr1Sqr1VrmGgEAQM3l1JydadOmqX79+iXaQ0JC9OKLL1aooKKiIuXm5qpTp07y9vbWunXr7Mv27t2r1NRU2Ww2SZLNZtPOnTt17Ngxe581a9YoMDBQUVFRFaoDAACYg1NndlJTU9WsWbMS7REREUpNTS3zdsaNG6fevXurSZMmys7O1uLFi7VhwwZ9/vnnCgoK0ogRIxQfH6+6desqMDBQjz76qGw2m2688UZJUq9evRQVFaWhQ4dqxowZSk9P1/jx4xUXF8eZGwAAIMnJsBMSEqIffvhBTZs2dWj//vvvVa9evTJv59ixY/bP4wkKClKHDh30+eef67bbbpMkzZo1Sx4eHho4cKByc3MVExOjuXPn2tf39PTUihUrNHLkSNlsNvn5+Sk2NlZTpkxx5rAAAIAJORV27r//fj322GMKCAhQt27dJEkbN27U448/rvvuu6/M27nc3Vq+vr5KSEhQQkLCRftERERo5cqVZd4nAAC4sjgVdqZOnaqDBw/q1ltvlZfXH5soKirSsGHDKjxnBwAAwJWcCjs+Pj567733NHXqVH3//feqVauW2rdvr4iICFfXBwAAUCFOhZ1irVu3VuvWrV1VCwAAgMs5FXYKCwuVlJSkdevW6dixYyoqKnJY/sUXX7ikOAAAgIpyKuw8/vjjSkpKUt++fdWuXTtZLBZX1wUAAOASToWdJUuW6P3331efPn1cXQ8AAIBLOfUJyn/+igcAAIDqzKmw88QTT+i1116TYRiurgcAAMClnLqM9fXXX2v9+vX673//q7Zt28rb29th+bJly1xSHAAAQEU5FXaCg4N11113uboWAAAAl3Mq7CQmJrq6DgAAgErh1JwdSSooKNDatWv15ptvKjs7W5J09OhR5eTkuKw4AACAinLqzM6hQ4d0++23KzU1Vbm5ubrtttsUEBCgl156Sbm5uZo/f76r6wQAAHCKU2d2Hn/8cV133XU6deqUatWqZW+/6667tG7dOpcVBwAAUFFOndn56quvtHnzZvn4+Di0N23aVL/99ptLCgMAAHAFp87sFBUVqbCwsET7kSNHFBAQUOGiAAAAXMWpsNOrVy/Nnj3b/txisSgnJ0cTJ07kKyQAAEC14tRlrFdffVUxMTGKiorS+fPnNWjQIP3yyy+qX7++/vOf/7i6RgAAAKc5FXYaN26s77//XkuWLNEPP/ygnJwcjRgxQoMHD3aYsAwAAOBuToUdSfLy8tKQIUNcWQsAAIDLORV2Fi1adMnlw4YNc6oYAAAAV3Mq7Dz++OMOz/Pz83X27Fn5+Piodu3ahB0AAFBtOHU31qlTpxweOTk52rt3r7p06cIEZQAAUK04/d1YF2rVqpWmT59e4qwPAACAO7ks7Eh/TFo+evSoKzcJAABQIU7N2fn0008dnhuGobS0NL3xxhu6+eabXVIYAACAKzgVdu68806H5xaLRQ0aNFDPnj316quvuqIuAAAAl3Aq7BQVFbm6DgAAgErh0jk7AAAA1Y1TZ3bi4+PL3HfmzJnO7AIAAMAlnAo727dv1/bt25Wfn682bdpIkn7++Wd5enrq2muvtfezWCyuqRIAAMBJToWdfv36KSAgQG+//bbq1Kkj6Y8PGnzggQfUtWtXPfHEEy4tEgAAwFlOzdl59dVXNW3aNHvQkaQ6dero+eef524sAABQrTgVdrKysvT777+XaP/999+VnZ1d4aIAAABcxamwc9ddd+mBBx7QsmXLdOTIER05ckQffvihRowYoQEDBri6RgAAAKc5NWdn/vz5evLJJzVo0CDl5+f/sSEvL40YMUIvv/yySwsEAACoCKfCTu3atTV37ly9/PLL+vXXXyVJLVq0kJ+fn0uLAwAAqKgKfahgWlqa0tLS1KpVK/n5+ckwDFfVBQAA4BJOhZ0TJ07o1ltvVevWrdWnTx+lpaVJkkaMGMFt5wAAoFpxKuyMHTtW3t7eSk1NVe3ate3t9957r1atWuWy4gAAACrKqTk7q1ev1ueff67GjRs7tLdq1UqHDh1ySWEAAACu4NSZnTNnzjic0Sl28uRJWa3WChcFAADgKk6Fna5du2rRokX25xaLRUVFRZoxY4ZuueUWlxUHAABQUU5dxpoxY4ZuvfVWffvtt8rLy9M//vEP7dq1SydPntSmTZtcXSMAAIDTnDqz065dO/3888/q0qWL+vfvrzNnzmjAgAHavn27WrRo4eoaAQAAnFbuMzv5+fm6/fbbNX/+fD333HOVURMAAIDLlPvMjre3t3744YfKqAUAAMDlnLqMNWTIEC1YsMDVtQAAALicUxOUCwoKtHDhQq1du1adOnUq8Z1YM2fOdElxAAAAFVWusLN//341bdpUP/74o6699lpJ0s8//+zQx2KxuK46AACACipX2GnVqpXS0tK0fv16SX98PcTrr7+u0NDQSikOAACgoso1Z+fCbzX/73//qzNnzri0IAAAAFdyaoJysQvDDwAAQHVTrrBjsVhKzMlhjg4AAKjOyjVnxzAMDR8+3P5ln+fPn9cjjzxS4m6sZcuWua5CAACACihX2ImNjXV4PmTIEJcWAwAA4GrlCjuJiYmVVQcAAEClqNAEZQAAgOqOsAMAAEzNrWFn2rRpuv766xUQEKCQkBDdeeed2rt3r0Of8+fPKy4uTvXq1ZO/v78GDhyojIwMhz6pqanq27evateurZCQED311FMqKCioykMBAADVlFvDzsaNGxUXF6ctW7ZozZo1ys/PV69evRw+qHDs2LFavny5li5dqo0bN+ro0aMaMGCAfXlhYaH69u2rvLw8bd68WW+//baSkpI0YcIEdxwSAACoZpz6IlBXWbVqlcPzpKQkhYSEKCUlRd26dVNmZqYWLFigxYsXq2fPnpL+mCR99dVXa8uWLbrxxhu1evVq7d69W2vXrlVoaKg6duyoqVOn6umnn9akSZPk4+PjjkMDAADVRLWas5OZmSlJqlu3riQpJSVF+fn5io6OtveJjIxUkyZNlJycLElKTk5W+/btHb6fKyYmRllZWdq1a1ep+8nNzVVWVpbDAwAAmFO1CTtFRUUaM2aMbr75ZrVr106SlJ6eLh8fHwUHBzv0DQ0NVXp6ur3PhV9EWvy8uM+Fpk2bpqCgIPsjPDzcxUcDAACqi2oTduLi4vTjjz9qyZIllb6vcePGKTMz0/44fPhwpe8TAAC4h1vn7BQbPXq0VqxYoS+//FKNGze2t4eFhSkvL0+nT592OLuTkZGhsLAwe5+tW7c6bK/4bq3iPheyWq32r7wAAADm5tYzO4ZhaPTo0froo4/0xRdfqFmzZg7LO3XqJG9vb61bt87etnfvXqWmpspms0mSbDabdu7cqWPHjtn7rFmzRoGBgYqKiqqaAwEAANWWW8/sxMXFafHixfrkk08UEBBgn2MTFBSkWrVqKSgoSCNGjFB8fLzq1q2rwMBAPfroo7LZbLrxxhslSb169VJUVJSGDh2qGTNmKD09XePHj1dcXBxnbwAAgHvDzrx58yRJPXr0cGhPTEzU8OHDJUmzZs2Sh4eHBg4cqNzcXMXExGju3Ln2vp6enlqxYoVGjhwpm80mPz8/xcbGasqUKVV1GAAAoBpza9gxDOOyfXx9fZWQkKCEhISL9omIiNDKlStdWRoAADCJanM3FgAAQGUg7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFNza9j58ssv1a9fPzVq1EgWi0Uff/yxw3LDMDRhwgQ1bNhQtWrVUnR0tH755ReHPidPntTgwYMVGBio4OBgjRgxQjk5OVV4FAAAoDpza9g5c+aMrrnmGiUkJJS6fMaMGXr99dc1f/58ffPNN/Lz81NMTIzOnz9v7zN48GDt2rVLa9as0YoVK/Tll1/qoYceqqpDAAAA1ZyXO3feu3dv9e7du9RlhmFo9uzZGj9+vPr37y9JWrRokUJDQ/Xxxx/rvvvu0549e7Rq1Spt27ZN1113nSRpzpw56tOnj1555RU1atSoyo4FAABUT9V2zs6BAweUnp6u6Ohoe1tQUJA6d+6s5ORkSVJycrKCg4PtQUeSoqOj5eHhoW+++eai287NzVVWVpbDAwAAmFO1DTvp6emSpNDQUIf20NBQ+7L09HSFhIQ4LPfy8lLdunXtfUozbdo0BQUF2R/h4eEurh4AAFQX1TbsVKZx48YpMzPT/jh8+LC7SwIAAJWk2oadsLAwSVJGRoZDe0ZGhn1ZWFiYjh075rC8oKBAJ0+etPcpjdVqVWBgoMMDAACYU7UNO82aNVNYWJjWrVtnb8vKytI333wjm80mSbLZbDp9+rRSUlLsfb744gsVFRWpc+fOVV4zAACoftx6N1ZOTo727dtnf37gwAHt2LFDdevWVZMmTTRmzBg9//zzatWqlZo1a6Z//vOfatSoke68805J0tVXX63bb79dDz74oObPn6/8/HyNHj1a9913H3diAQAASW4OO99++61uueUW+/P4+HhJUmxsrJKSkvSPf/xDZ86c0UMPPaTTp0+rS5cuWrVqlXx9fe3rvPvuuxo9erRuvfVWeXh4aODAgXr99der/FgAAED15Naw06NHDxmGcdHlFotFU6ZM0ZQpUy7ap27dulq8eHFllAcAAEyg2s7ZAQAAcAXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXThJ2EhAQ1bdpUvr6+6ty5s7Zu3erukgAAQDVgirDz3nvvKT4+XhMnTtR3332na665RjExMTp27Ji7SwMAAG5mirAzc+ZMPfjgg3rggQcUFRWl+fPnq3bt2lq4cKG7SwMAAG5W48NOXl6eUlJSFB0dbW/z8PBQdHS0kpOT3VgZAACoDrzcXUBFHT9+XIWFhQoNDXVoDw0N1U8//VTqOrm5ucrNzbU/z8zMlCRlZWW5tLacnJw/9pe+T0V55yVJ+SePSJJSUlLsyz08PFRUVOSw7oVt9KFPdd0/fehDH36+//x87969kv73u6/4915OTo7Lf88Wb88wjEv2q/FhxxnTpk3T5MmTS7SHh4dXyv5Off5GibaHHnqoUvYFAEB1cOHvvu7du1favrKzsxUUFHTR5TU+7NSvX1+enp7KyMhwaM/IyFBYWFip64wbN07x8fH250VFRTp58qTq1asni8Xi0vqysrIUHh6uw4cPKzAw0KXbxv8wzpWPMa4ajHPlY4wrX1WNsWEYys7OVqNGjS7Zr8aHHR8fH3Xq1Enr1q3TnXfeKemP8LJu3TqNHj261HWsVqusVqtDW3BwcKXWGRgYyA9VFWCcKx9jXDUY58rHGFe+qhjjS53RKVbjw44kxcfHKzY2Vtddd51uuOEGzZ49W2fOnNEDDzzg7tIAAICbmSLs3Hvvvfr99981YcIEpaenq2PHjlq1alWJScsAAODKY4qwI0mjR4++6GUrd7JarZo4cWKJy2ZwLca58jHGVYNxrnyMceWrbmNsMS53vxYAAEANVuM/VBAAAOBSCDsAAMDUCDsAAMDUCDsAAMDUCDsukJCQoKZNm8rX11edO3fW1q1bL9l/6dKlioyMlK+vr9q3b6+VK1dWUaU1V3nG+K233lLXrl1Vp04d1alTR9HR0Zd9TfCH8r6Xiy1ZskQWi8X+wZ64uPKO8enTpxUXF6eGDRvKarWqdevW/D+jDMo7zrNnz1abNm1Uq1YthYeHa+zYsTp//nwVVVvzfPnll+rXr58aNWoki8Wijz/++LLrbNiwQddee62sVqtatmyppKSkSq/TzkCFLFmyxPDx8TEWLlxo7Nq1y3jwwQeN4OBgIyMjo9T+mzZtMjw9PY0ZM2YYu3fvNsaPH294e3sbO3furOLKa47yjvGgQYOMhIQEY/v27caePXuM4cOHG0FBQcaRI0equPKapbzjXOzAgQPGVVddZXTt2tXo379/1RRbQ5V3jHNzc43rrrvO6NOnj/H1118bBw4cMDZs2GDs2LGjiiuvWco7zu+++65htVqNd9991zhw4IDx+eefGw0bNjTGjh1bxZXXHCtXrjSee+45Y9myZYYk46OPPrpk//379xu1a9c24uPjjd27dxtz5swxPD09jVWrVlVJvYSdCrrhhhuMuLg4+/PCwkKjUaNGxrRp00rtf8899xh9+/Z1aOvcubPx8MMPV2qdNVl5x/hCBQUFRkBAgPH2229XVomm4Mw4FxQUGDfddJPx73//24iNjSXsXEZ5x3jevHlG8+bNjby8vKoq0RTKO85xcXFGz549Hdri4+ONm2++uVLrNIuyhJ1//OMfRtu2bR3a7r33XiMmJqYSK/sfLmNVQF5enlJSUhQdHW1v8/DwUHR0tJKTk0tdJzk52aG/JMXExFy0/5XOmTG+0NmzZ5Wfn6+6detWVpk1nrPjPGXKFIWEhGjEiBFVUWaN5swYf/rpp7LZbIqLi1NoaKjatWunF198UYWFhVVVdo3jzDjfdNNNSklJsV/q2r9/v1auXKk+ffpUSc1XAnf/7jPNJyi7w/Hjx1VYWFjiaylCQ0P1008/lbpOenp6qf3T09Mrrc6azJkxvtDTTz+tRo0alfhBw/84M85ff/21FixYoB07dlRBhTWfM2O8f/9+ffHFFxo8eLBWrlypffv2adSoUcrPz9fEiROrouwax5lxHjRokI4fP64uXbrIMAwVFBTokUce0bPPPlsVJV8RLva7LysrS+fOnVOtWrUqdf+c2YGpTZ8+XUuWLNFHH30kX19fd5djGtnZ2Ro6dKjeeust1a9f393lmFZRUZFCQkL0r3/9S506ddK9996r5557TvPnz3d3aaayYcMGvfjii5o7d66+++47LVu2TJ999pmmTp3q7tLgIpzZqYD69evL09NTGRkZDu0ZGRkKCwsrdZ2wsLBy9b/SOTPGxV555RVNnz5da9euVYcOHSqzzBqvvOP866+/6uDBg+rXr5+9raioSJLk5eWlvXv3qkWLFpVbdA3jzHu5YcOG8vb2lqenp73t6quvVnp6uvLy8uTj41OpNddEzozzP//5Tw0dOlR///vfJUnt27fXmTNn9NBDD+m5556ThwfnBSrqYr/7AgMDK/2sjsSZnQrx8fFRp06dtG7dOntbUVGR1q1bJ5vNVuo6NpvNob8krVmz5qL9r3TOjLEkzZgxQ1OnTtWqVat03XXXVUWpNVp5xzkyMlI7d+7Ujh077I877rhDt9xyi3bs2KHw8PCqLL9GcOa9fPPNN2vfvn32IClJP//8sxo2bEjQuQhnxvns2bMlAk1xwDT4+kiXcPvvviqZBm1iS5YsMaxWq5GUlGTs3r3beOihh4zg4GAjPT3dMAzDGDp0qPHMM8/Y+2/atMnw8vIyXnnlFWPPnj3GxIkTufX8Mso7xtOnTzd8fHyMDz74wEhLS7M/srOz3XUINUJ5x/lC3I11eeUd49TUVCMgIMAYPXq0sXfvXmPFihVGSEiI8fzzz7vrEGqE8o7zxIkTjYCAAOM///mPsX//fmP16tVGixYtjHvuucddh1DtZWdnG9u3bze2b99uSDJmzpxpbN++3Th06JBhGIbxzDPPGEOHDrX3L771/KmnnjL27NljJCQkcOt5TTNnzhyjSZMmho+Pj3HDDTcYW7ZssS/r3r27ERsb69D//fffN1q3bm34+PgYbdu2NT777LMqrrjmKc8YR0REGJJKPCZOnFj1hdcw5X0v/xlhp2zKO8abN282OnfubFitVqN58+bGCy+8YBQUFFRx1TVPecY5Pz/fmDRpktGiRQvD19fXCA8PN0aNGmWcOnWq6guvIdavX1/q/2eLxzU2Ntbo3r17iXU6duxo+Pj4GM2bNzcSExOrrF6LYXCODgAAmBdzdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgBUe8OHD5fFYinxuP32291dGoAagG89B1Aj3H777UpMTHRos1qtpfbNz8+Xt7e3Q5uz3xLOt4sDNR9ndgDUCFarVWFhYQ6POnXqSJIsFovmzZunO+64Q35+fnrhhRc0adIkdezYUf/+97/VrFkz+fr6SpJSU1PVv39/+fv7KzAwUPfcc48yMjLs+7nYegBqLsIOAFOYNGmS7rrrLu3cuVN/+9vfJEn79u3Thx9+qGXLlmnHjh0qKipS//79dfLkSW3cuFFr1qzR/v37de+99zps68L1ANRsXMYCUCOsWLFC/v7+Dm3PPvusnn32WUnSoEGD9MADDzgsz8vL06JFi9SgQQNJ0po1a7Rz504dOHBA4eHhkqRFixapbdu22rZtm66//vpS1wNQsxF2ANQIt9xyi+bNm+fQVrduXfu/r7vuuhLrREREOASWPXv2KDw83B50JCkqKkrBwcHas2ePPexcuB6Amo2wA6BG8PPzU8uWLS+5vCxtZd0XAPNgzg6AK8bVV1+tw4cP6/Dhw/a23bt36/Tp04qKinJjZQAqE2d2ANQIubm5Sk9Pd2jz8vJS/fr1y7yN6OhotW/fXoMHD9bs2bNVUFCgUaNGqXv37qVeBgNgDpzZAVAjrFq1Sg0bNnR4dOnSpVzbsFgs+uSTT1SnTh1169ZN0dHRat68ud57771KqhpAdWAxDMNwdxEAAACVhTM7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1P4foCH8Jd3EeOoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean error: 0.5009568333625793\n",
      "Standard deviation : 0.5019811391830444\n"
     ]
    }
   ],
   "source": [
    "# Situation 2\n",
    "array = np.linspace(0, 2, 1000, dtype=np.float32)\n",
    "min_range = 0\n",
    "max_range = 1\n",
    "display_error_histogram(array, min_range, max_range)\n",
    "quantization_error_stats(array, min_range, max_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "id": "a5c3b1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHHCAYAAABZbpmkAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAPGFJREFUeJzt3XlclWX+//H3QVkEBEQFJBFxSXMfzRzKXJLEZUzTqdwSHEdLoTRbrSa1ppys1MkxbWYS81umWbboNJa7WaRmmqZmYSYuoLmBuIDC9fujn2c8sgiHA+d493o+Hvcjz3Vf931/Lm6OvrvPdd/HZowxAgAAsCgvdxcAAABQkQg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7gIV06dJFXbp0+c0c97fEZrNp0qRJ7i4DuCYRdoD/b+fOnRo6dKiuu+46+fr6KjIyUkOHDtWuXbvcXZqDXbt2adKkSfr5559/E8ctydq1a2Wz2YpdFi5c6O4SizRp0iTZbDYdO3asyPX169fXH/7wh3IfZ8GCBZoxY0a59wNc66q6uwDAEyxZskSDBg1SaGioRowYoZiYGP38889644039N5772nRokXq27evu8uU9GvomDx5srp06aL69es7rPvss88sd9zSePDBB9W+fftC7bGxsW6opmKcO3dOVauW7a/sBQsW6LvvvtO4ceMqpijgGkHYwW/e3r17de+996pBgwZav369ateubV83duxY3XrrrRo6dKi2b9+umJgYN1Z6dT4+Pr+p415y66236o9//GOZtikoKFBeXp78/PwKrTtz5owCAgLKVdPZs2fl7+9frn1crqg6PZ0rfo6AK/AxFn7zXnrpJZ09e1b//Oc/HYKOJNWqVUuvv/66cnJy9NJLL9nbExMTC13dkP738cTlUlJSdNtttyksLEy+vr5q1qyZZs+eXWjbSx9dbNiwQTfddJP8/PzUoEEDzZ8/395n3rx5uuuuuyRJXbt2tX9cs3btWkmF587Ur1+/2I94Lm2zf/9+jRkzRk2aNFG1atVUs2ZN3XXXXQ4fV5X1uJJ09OhRjRgxQuHh4fLz81Pr1q315ptvOvT5+eefZbPZ9PLLL+uf//ynGjZsKF9fX7Vv316bN28u9DMqD5vNpuTkZL399ttq3ry5fH19tXz5cs2bN082m03r1q3TmDFjFBYWprp169q3e+211+z9IyMjlZSUpFOnTjnsu0uXLmrRooW2bNmiTp06yd/fX08++aTL6798zs7p06c1btw41a9fX76+vgoLC9Ptt9+ub775xl7Tf/7zH+3fv99+vi7/nS3N+ZGk48eP695771VQUJBCQkKUkJCgb7/9VjabTfPmzbP3S0xMVGBgoPbu3atevXqpevXqGjJkiCTp888/11133aV69erJ19dXUVFReuihh3Tu3DmHY13aR3p6uv7whz8oMDBQ1113nWbNmiVJ2rFjh2677TYFBAQoOjpaCxYscNFPF1bHlR385i1dulT169fXrbfeWuT6Tp06qX79+lq6dKlee+21Mu9/9uzZat68ue644w5VrVpVS5cu1ZgxY1RQUKCkpCSHvmlpafrjH/+oESNGKCEhQXPnzlViYqLatWun5s2bq1OnTnrwwQf16quv6sknn9QNN9wgSfb/XmnGjBnKyclxaJs+fbq2bdummjVrSpI2b96sL7/8UgMHDlTdunX1888/a/bs2erSpYt27dolf3//Mh/33Llz6tKli9LS0pScnKyYmBgtXrxYiYmJOnXqlMaOHevQf8GCBTp9+rTuu+8+2Ww2TZ06Vf3799dPP/0kb2/vq/6MT58+XeT8l5o1azqEz9WrV+vdd99VcnKyatWqpfr162vbtm2SpDFjxqh27dp65plndObMGUm/htfJkycrLi5Oo0eP1p49ezR79mxt3rxZX3zxhUNtx48fV8+ePTVw4EANHTpU4eHhV637xIkTRbYXFBRcddv7779f7733npKTk9WsWTMdP35cGzZs0O7du9W2bVs99dRTysrK0sGDBzV9+nRJUmBgoKTSn5+CggL16dNHmzZt0ujRo9W0aVN99NFHSkhIKLKmixcvKj4+Xh07dtTLL79sv7K1ePFinT17VqNHj1bNmjW1adMmzZw5UwcPHtTixYsd9pGfn6+ePXuqU6dOmjp1qt5++20lJycrICBATz31lIYMGaL+/ftrzpw5GjZsmGJjYz3+iis8gAF+w06dOmUkmb59+5bY74477jCSTHZ2tjHGmISEBBMdHV2o38SJE82Vb6uzZ88W6hcfH28aNGjg0BYdHW0kmfXr19vbjh49anx9fc3DDz9sb1u8eLGRZNasWVNov507dzadO3cudhzvvvuukWSeffbZEutLTU01ksz8+fOdOu6MGTOMJPPWW2/Z2/Ly8kxsbKwJDAy0/xz37dtnJJmaNWuaEydO2Pt+9NFHRpJZunRpsWMxxpg1a9YYScUuGRkZ9r6SjJeXl9m5c6fDPlJSUowk07FjR3Px4kV7+9GjR42Pj4/p3r27yc/Pt7f/4x//MJLM3LlzHcYvycyZM6fEei+59HtS0tK7d2+HbSSZiRMn2l8HBwebpKSkEo/Tu3fvIn9PS3t+3n//fSPJzJgxw94vPz/f3HbbbUaSSUlJsbcnJCQYSeaJJ54odLyifsemTJlibDab2b9/f6F9vPDCC/a2kydPmmrVqhmbzWYWLlxob//+++8L/UyA4vAxFn7TTp8+LUmqXr16if0urb/UvyyqVatm/3NWVpaOHTumzp0766efflJWVpZD32bNmjlcYapdu7aaNGmin376qczHvdKuXbv0pz/9SX379tXTTz9dZH0XLlzQ8ePH1ahRI4WEhNg/EimrTz75RBERERo0aJC9zdvbWw8++KBycnK0bt06h/733HOPatSoYX996WdQ2nE/88wzWrFiRaElNDTUoV/nzp3VrFmzIvcxcuRIValSxf565cqVysvL07hx4+Tl5eXQLygoSP/5z38ctvf19dXw4cNLVe8l77//fpF1l+aqUEhIiDZu3KjDhw+X6ZhS6c/P8uXL5e3trZEjR9r7eXl5FboiebnRo0cXarv8d+zMmTM6duyYbr75ZhljtHXr1kL9//znP9v/HBISoiZNmiggIEB33323vb1JkyYKCQlxyXsD1sfHWPhNK22IOX36tGw2m2rVqlXmY3zxxReaOHGiUlNTdfbsWYd1WVlZCg4Otr+uV69eoe1r1KihkydPlvm4l8vOzlb//v113XXXaf78+Q4f7Zw7d05TpkxRSkqKDh06JGOMQ33O2L9/vxo3buwQEqT/fey1f/9+h/Yrx30p+JR23C1btlRcXNxV+5X0cceV6y7V2KRJE4d2Hx8fNWjQoNAYrrvuujJP1O7UqVORv1OlmYw8depUJSQkKCoqSu3atVOvXr00bNgwNWjQ4Krblvb87N+/X3Xq1Ck00bpRo0ZF7rdq1aoO850uSU9P1zPPPKOPP/640Dm98nfMz8+v0Ny54OBg1a1bt9B8uODg4HK/N/DbQNjBb1pwcLAiIyO1ffv2Evtt375ddevWtf9jduVfupfk5+c7vN67d6+6deumpk2batq0aYqKipKPj48++eQTTZ8+vdDcjMuvLFzu8gDijMTERB0+fFibNm1SUFCQw7oHHnhAKSkpGjdunGJjYxUcHCybzaaBAweWau6IK1TUuK90+RWGsqwr774rwt13361bb71VH3zwgT777DO99NJLevHFF7VkyRL17NmzUmu5xNfXt1CAys/P1+23364TJ07o8ccfV9OmTRUQEKBDhw4pMTGx1O+ByvodgTURdvCb16dPH73++uvasGGDOnbsWGj9559/rp9//lnjx4+3t9WoUaPQHTlS4SsWS5cuVW5urj7++GOHqxdr1qxxut7iglZx/va3v+nDDz/UkiVL1LRp00Lr33vvPSUkJOiVV16xt50/f77Q+Mpy3OjoaG3fvl0FBQUO//h9//339vWe7lKNe/bscbhakpeXp3379pXqSlJFq1OnjsaMGaMxY8bo6NGjatu2rZ5//nl72CnunJX2/ERHR2vNmjWFbqNPS0srdY07duzQDz/8oDfffFPDhg2zt69YsaL0AwXKiTk7+M175JFH5O/vr/vuu0/Hjx93WHfixAndf//9CgoKUnJysr29YcOGysrKcrgilJGRoQ8++MBh+0v/N3rlR0MpKSlO13vpuSVFha0rrVy5Uk8//bSeeuop9evXr8g+VapUKfR/xzNnzix0laosx+3Vq5cyMzO1aNEie9vFixc1c+ZMBQYGqnPnzlfdh7vFxcXJx8dHr776qsPP54033lBWVpZ69+7tttry8/MLffwTFhamyMhI5ebm2tsCAgKK/CiytOcnPj5eFy5c0L/+9S97v4KCAvut4KVR1HvAGKO///3vpd4HUF5c2cFvXqNGjTR//nwNGjRILVu2LPQE5ZMnT2rhwoUOczoGDhyoxx9/XHfeeacefPBBnT17VrNnz9b111/vMKm3e/fu8vHxUZ8+fXTfffcpJydH//rXvxQWFqaMjAyn6m3Tpo2qVKmiF198UVlZWfL19bU/x+dKgwYNUu3atdW4cWO99dZbDutuv/12hYeH6w9/+IP+7//+T8HBwWrWrJlSU1O1cuVK+63pzhx31KhRev3115WYmKgtW7aofv36eu+99/TFF19oxowZV50QXlaff/65zp8/X6i9VatWatWqlVP7rF27tiZMmKDJkyerR48euuOOO7Rnzx699tprat++vYYOHVresp12+vRp1a1bV3/84x/VunVrBQYGauXKldq8ebPDFbp27dpp0aJFGj9+vNq3b6/AwED16dOn1OenX79+uummm/Twww8rLS1NTZs21ccff2y/Zb40V/uaNm2qhg0b6pFHHtGhQ4cUFBSk999/n7k2qFzuug0M8DQ7duwwgwcPNhEREcbLy8tIMn5+foVuVb7ks88+My1atDA+Pj6mSZMm5q233iry1vOPP/7YtGrVyvj5+Zn69eubF1980cydO9dIMvv27bP3i46OLnS7sTFF307+r3/9yzRo0MBUqVLF4XbwK/uqhFubL21z8uRJM3z4cFOrVi0TGBho4uPjzffff2+io6NNQkKCU8c1xpgjR47Y9+vj42NatmzpcKuyMf+79fyll14qNG6V4rbiq916fvn2koq8VfvSreebN28u8hj/+Mc/TNOmTY23t7cJDw83o0ePNidPnnTo07lzZ9O8efMSa73cpd+TX375pcj1Rf0uXD6e3Nxc8+ijj5rWrVub6tWrm4CAANO6dWvz2muvOWyTk5NjBg8ebEJCQowkh9vQS3N+jDHml19+MYMHDzbVq1c3wcHBJjEx0XzxxRdGksOt4AkJCSYgIKDI8ezatcvExcWZwMBAU6tWLTNy5Ejz7bffFnn7elH7KO7nW9x7BriSzRhmdwFFmT9/vhITEzV06FCHpxgDv3Uffvih7rzzTm3YsEG33HKLu8sBroqPsYBiDBs2TBkZGXriiSdUt25dvfDCC+4uCah0586dc7jTLD8/XzNnzlRQUJDatm3rxsqA0uPKDgCgWH/+85917tw5xcbGKjc3V0uWLNGXX36pF154QRMmTHB3eUCpEHYAAMVasGCBXnnlFaWlpen8+fNq1KiRRo8e7XB3IuDpCDsAAMDSeM4OAACwNMIOAACwNO7G0q9PBD18+LCqV69e5kfxAwAA9zDG6PTp04qMjCz0vWyXI+xIOnz4sKKiotxdBgAAcMKBAwdUt27dYtcTdiT7o9EPHDhQ6BuhAQCAZ8rOzlZUVNRVv4KGsKP/fb9LUFAQYQcAgGvM1aagMEEZAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYWlV3FwAAAKwlPT1dx44ds7+uVauW6tWr57Z6CDsAAMBl0tPT1aTpDTp/7qy9za+av/Z8v9ttgYewAwAAXObYsWM6f+6sav7hYXnXjNKF4wd0fNkrOnbsGGEHAABYh3fNKPlGNHJ3GZKYoAwAACyOsAMAACyNsAMAACzNrWFnypQpat++vapXr66wsDD169dPe/bscejTpUsX2Ww2h+X+++936JOenq7evXvL399fYWFhevTRR3Xx4sXKHAoAAPBQbp2gvG7dOiUlJal9+/a6ePGinnzySXXv3l27du1SQECAvd/IkSP17LPP2l/7+/vb/5yfn6/evXsrIiJCX375pTIyMjRs2DB5e3vrhRdeqNTxAAAAz+PWsLN8+XKH1/PmzVNYWJi2bNmiTp062dv9/f0VERFR5D4+++wz7dq1SytXrlR4eLjatGmj5557To8//rgmTZokHx+fCh0DAADwbB41ZycrK0uSFBoa6tD+9ttvq1atWmrRooUmTJigs2f/96Ci1NRUtWzZUuHh4fa2+Ph4ZWdna+fOnZVTOAAA8Fge85ydgoICjRs3TrfccotatGhhbx88eLCio6MVGRmp7du36/HHH9eePXu0ZMkSSVJmZqZD0JFkf52ZmVnksXJzc5Wbm2t/nZ2d7erhAPAgnvboegCVy2PCTlJSkr777jtt2LDBoX3UqFH2P7ds2VJ16tRRt27dtHfvXjVs2NCpY02ZMkWTJ08uV70APNOVwSYjI0MD/niXcs+fs7e5+9H1ACqXR4Sd5ORkLVu2TOvXr1fdunVL7NuhQwdJUlpamho2bKiIiAht2rTJoc+RI0ckqdh5PhMmTND48ePtr7OzsxUVFVWeIQDwAEV9J88lnvToegCVy61hxxijBx54QB988IHWrl2rmJiYq26zbds2SVKdOnUkSbGxsXr++ed19OhRhYWFSZJWrFihoKAgNWvWrMh9+Pr6ytfX1zWDAOAxrvxOHkk699PXyvr8LY96dD2AyuXWsJOUlKQFCxboo48+UvXq1e1zbIKDg1WtWjXt3btXCxYsUK9evVSzZk1t375dDz30kDp16qRWrVpJkrp3765mzZrp3nvv1dSpU5WZmamnn35aSUlJBBrgN+ryYHPh+AE3VwPA3dx6N9bs2bOVlZWlLl26qE6dOvZl0aJFkiQfHx+tXLlS3bt3V9OmTfXwww9rwIABWrp0qX0fVapU0bJly1SlShXFxsZq6NChGjZsmMNzeQAAwG+X2z/GKklUVJTWrVt31f1ER0frk08+cVVZAADAQjzqOTsAAACuRtgBAACW5hG3nlvZlc/8kHigGQAAlYmwU4GKe+YHDzQDAKDyEHYqUFHP/OCBZgAAVC7CTiXgYWYAALgPE5QBAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAICluTXsTJkyRe3bt1f16tUVFhamfv36ac+ePQ59zp8/r6SkJNWsWVOBgYEaMGCAjhw54tAnPT1dvXv3lr+/v8LCwvToo4/q4sWLlTkUAADgodwadtatW6ekpCR99dVXWrFihS5cuKDu3bvrzJkz9j4PPfSQli5dqsWLF2vdunU6fPiw+vfvb1+fn5+v3r17Ky8vT19++aXefPNNzZs3T88884w7hgQAADxMVXcefPny5Q6v582bp7CwMG3ZskWdOnVSVlaW3njjDS1YsEC33XabJCklJUU33HCDvvrqK/3+97/XZ599pl27dmnlypUKDw9XmzZt9Nxzz+nxxx/XpEmT5OPj446hAQAAD+FRc3aysrIkSaGhoZKkLVu26MKFC4qLi7P3adq0qerVq6fU1FRJUmpqqlq2bKnw8HB7n/j4eGVnZ2vnzp1FHic3N1fZ2dkOCwAAsCaPCTsFBQUaN26cbrnlFrVo0UKSlJmZKR8fH4WEhDj0DQ8PV2Zmpr3P5UHn0vpL64oyZcoUBQcH25eoqCgXjwYAAHgKjwk7SUlJ+u6777Rw4cIKP9aECROUlZVlXw4cOFDhxwQAAO7h1jk7lyQnJ2vZsmVav3696tata2+PiIhQXl6eTp065XB158iRI4qIiLD32bRpk8P+Lt2tdanPlXx9feXr6+viUQAAAE/k1is7xhglJyfrgw8+0OrVqxUTE+Owvl27dvL29taqVavsbXv27FF6erpiY2MlSbGxsdqxY4eOHj1q77NixQoFBQWpWbNmlTMQAADgsdx6ZScpKUkLFizQRx99pOrVq9vn2AQHB6tatWoKDg7WiBEjNH78eIWGhiooKEgPPPCAYmNj9fvf/16S1L17dzVr1kz33nuvpk6dqszMTD399NNKSkri6g0AAHBv2Jk9e7YkqUuXLg7tKSkpSkxMlCRNnz5dXl5eGjBggHJzcxUfH6/XXnvN3rdKlSpatmyZRo8erdjYWAUEBCghIUHPPvtsZQ0DAAB4MLeGHWPMVfv4+flp1qxZmjVrVrF9oqOj9cknn7iyNAAAYBEeczcWAABARSDsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAAS3Mq7Pz000+urgMAAKBCOBV2GjVqpK5du+qtt97S+fPnXV0TAACAyzgVdr755hu1atVK48ePV0REhO677z5t2rTJ1bUBAACUm1Nhp02bNvr73/+uw4cPa+7cucrIyFDHjh3VokULTZs2Tb/88our6wQAAHBKuSYoV61aVf3799fixYv14osvKi0tTY888oiioqI0bNgwZWRkuKpOAAAAp5Qr7Hz99dcaM2aM6tSpo2nTpumRRx7R3r17tWLFCh0+fFh9+/Z1VZ0AAABOqerMRtOmTVNKSor27NmjXr16af78+erVq5e8vH7NTjExMZo3b57q16/vyloBAADKzKmwM3v2bP3pT39SYmKi6tSpU2SfsLAwvfHGG+UqDgAAoLycCjs//vjjVfv4+PgoISHBmd0DAAC4jFNzdlJSUrR48eJC7YsXL9abb75Z6v2sX79effr0UWRkpGw2mz788EOH9YmJibLZbA5Ljx49HPqcOHFCQ4YMUVBQkEJCQjRixAjl5OQ4MywAAGBBToWdKVOmqFatWoXaw8LC9MILL5R6P2fOnFHr1q01a9asYvv06NFDGRkZ9uWdd95xWD9kyBDt3LlTK1as0LJly7R+/XqNGjWq9IMBAACW5tTHWOnp6YqJiSnUHh0drfT09FLvp2fPnurZs2eJfXx9fRUREVHkut27d2v58uXavHmzbrzxRknSzJkz1atXL7388suKjIwsdS0AAMCanLqyExYWpu3btxdq//bbb1WzZs1yF3W5tWvXKiwsTE2aNNHo0aN1/Phx+7rU1FSFhITYg44kxcXFycvLSxs3bix2n7m5ucrOznZYAACANTkVdgYNGqQHH3xQa9asUX5+vvLz87V69WqNHTtWAwcOdFlxPXr00Pz587Vq1Sq9+OKLWrdunXr27Kn8/HxJUmZmpsLCwhy2qVq1qkJDQ5WZmVnsfqdMmaLg4GD7EhUV5bKaAQCAZ3HqY6znnntOP//8s7p166aqVX/dRUFBgYYNG1amOTtXc3lwatmypVq1aqWGDRtq7dq16tatm9P7nTBhgsaPH29/nZ2dTeABAMCinAo7Pj4+WrRokZ577jl9++23qlatmlq2bKno6GhX1+egQYMGqlWrltLS0tStWzdFRETo6NGjDn0uXryoEydOFDvPR/p1HpCvr2+F1goAADyDU2Hnkuuvv17XX3+9q2q5qoMHD+r48eP2BxnGxsbq1KlT2rJli9q1aydJWr16tQoKCtShQ4dKqwsAAHgup8JOfn6+5s2bp1WrVuno0aMqKChwWL969epS7ScnJ0dpaWn21/v27dO2bdsUGhqq0NBQTZ48WQMGDFBERIT27t2rxx57TI0aNVJ8fLwk6YYbblCPHj00cuRIzZkzRxcuXFBycrIGDhzInVgAAECSk2Fn7Nixmjdvnnr37q0WLVrIZrM5dfCvv/5aXbt2tb++NI8mISFBs2fP1vbt2/Xmm2/q1KlTioyMVPfu3fXcc885fAT19ttvKzk5Wd26dZOXl5cGDBigV1991al6AACA9TgVdhYuXKh3331XvXr1KtfBu3TpImNMses//fTTq+4jNDRUCxYsKFcdAADAupy69dzHx0eNGjVydS0AAAAu51TYefjhh/X3v/+9xKsyAAAAnsCpj7E2bNigNWvW6L///a+aN28ub29vh/VLlixxSXEAAADl5VTYCQkJ0Z133unqWgAAAFzOqbCTkpLi6joAAAAqhFNzdqRfn1S8cuVKvf766zp9+rQk6fDhw8rJyXFZcQAAAOXl1JWd/fv3q0ePHkpPT1dubq5uv/12Va9eXS+++KJyc3M1Z84cV9cJAADgFKeu7IwdO1Y33nijTp48qWrVqtnb77zzTq1atcplxQEAAJSXU1d2Pv/8c3355Zfy8fFxaK9fv74OHTrkksIAAABcwakrOwUFBcrPzy/UfvDgQVWvXr3cRQEAALiKU2Gne/fumjFjhv21zWZTTk6OJk6cWO6vkAAAAHAlpz7GeuWVVxQfH69mzZrp/PnzGjx4sH788UfVqlVL77zzjqtrBAAAcJpTYadu3br69ttvtXDhQm3fvl05OTkaMWKEhgwZ4jBhGQAAwN2cCjuSVLVqVQ0dOtSVtQAAALicU2Fn/vz5Ja4fNmyYU8UAAAC4mlNhZ+zYsQ6vL1y4oLNnz8rHx0f+/v6EHQAA4DGcuhvr5MmTDktOTo727Nmjjh07MkEZAAB4FKe/G+tKjRs31t/+9rdCV30AAADcyWVhR/p10vLhw4dduUsAAIBycWrOzscff+zw2hijjIwM/eMf/9Att9ziksIAAABcwamw069fP4fXNptNtWvX1m233aZXXnnFFXUBAAC4hFNhp6CgwNV1AAAAVAiXztkBAADwNE5d2Rk/fnyp+06bNs2ZQwAAALiEU2Fn69at2rp1qy5cuKAmTZpIkn744QdVqVJFbdu2tfez2WyuqRIAAMBJToWdPn36qHr16nrzzTdVo0YNSb8+aHD48OG69dZb9fDDD7u0SAAAAGc5NWfnlVde0ZQpU+xBR5Jq1Kihv/71r9yNBQAAPIpTYSc7O1u//PJLofZffvlFp0+fLndRAAAAruJU2Lnzzjs1fPhwLVmyRAcPHtTBgwf1/vvva8SIEerfv7+rawQAAHCaU3N25syZo0ceeUSDBw/WhQsXft1R1aoaMWKEXnrpJZcWCAAAUB5OhR1/f3+99tpreumll7R3715JUsOGDRUQEODS4gAAAMqrXA8VzMjIUEZGhho3bqyAgAAZY1xVFwAAgEs4FXaOHz+ubt266frrr1evXr2UkZEhSRoxYgS3nQMAAI/iVNh56KGH5O3trfT0dPn7+9vb77nnHi1fvtxlxQEAAJSXU3N2PvvsM3366aeqW7euQ3vjxo21f/9+lxQGAADgCk5d2Tlz5ozDFZ1LTpw4IV9f33IXBQAA4CpOhZ1bb71V8+fPt7+22WwqKCjQ1KlT1bVrV5cVBwAAUF5OfYw1depUdevWTV9//bXy8vL02GOPaefOnTpx4oS++OILV9cIAADgNKeu7LRo0UI//PCDOnbsqL59++rMmTPq37+/tm7dqoYNG7q6RgAAAKeV+crOhQsX1KNHD82ZM0dPPfVURdQEAADgMmW+suPt7a3t27dXRC0AAAAu59THWEOHDtUbb7zh6loAAABczqkJyhcvXtTcuXO1cuVKtWvXrtB3Yk2bNs0lxQEAAJRXmcLOTz/9pPr16+u7775T27ZtJUk//PCDQx+bzea66gAAAMqpTGGncePGysjI0Jo1ayT9+vUQr776qsLDwyukOAAAgPIq05ydK7/V/L///a/OnDnj0oIAAABcyakJypdcGX4AAAA8TZnCjs1mKzQnhzk6AADAk5Vpzo4xRomJifYv+zx//rzuv//+QndjLVmyxHUVAgAAlEOZwk5CQoLD66FDh7q0GAAAAFcrU9hJSUmpqDoAAAAqRLkmKAMAAHg6wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0t4ad9evXq0+fPoqMjJTNZtOHH37osN4Yo2eeeUZ16tRRtWrVFBcXpx9//NGhz4kTJzRkyBAFBQUpJCREI0aMUE5OTiWOAgAAeDK3hp0zZ86odevWmjVrVpHrp06dqldffVVz5szRxo0bFRAQoPj4eJ0/f97eZ8iQIdq5c6dWrFihZcuWaf369Ro1alRlDQEAAHi4Mj1U0NV69uypnj17FrnOGKMZM2bo6aefVt++fSVJ8+fPV3h4uD788EMNHDhQu3fv1vLly7V582bdeOONkqSZM2eqV69eevnllxUZGVlpYwEAAJ7JY+fs7Nu3T5mZmYqLi7O3BQcHq0OHDkpNTZUkpaamKiQkxB50JCkuLk5eXl7auHFjsfvOzc1Vdna2wwIAAKzJY8NOZmamJCk8PNyhPTw83L4uMzNTYWFhDuurVq2q0NBQe5+iTJkyRcHBwfYlKirKxdUDAABP4bFhpyJNmDBBWVlZ9uXAgQPuLgkAAFQQjw07ERERkqQjR444tB85csS+LiIiQkePHnVYf/HiRZ04ccLepyi+vr4KCgpyWAAAgDV5bNiJiYlRRESEVq1aZW/Lzs7Wxo0bFRsbK0mKjY3VqVOntGXLFnuf1atXq6CgQB06dKj0mgEAgOdx691YOTk5SktLs7/et2+ftm3bptDQUNWrV0/jxo3TX//6VzVu3FgxMTH6y1/+osjISPXr10+SdMMNN6hHjx4aOXKk5syZowsXLig5OVkDBw7kTiwAACDJzWHn66+/VteuXe2vx48fL0lKSEjQvHnz9Nhjj+nMmTMaNWqUTp06pY4dO2r58uXy8/Ozb/P2228rOTlZ3bp1k5eXlwYMGKBXX3210scCAAA8k1vDTpcuXWSMKXa9zWbTs88+q2effbbYPqGhoVqwYEFFlAcAACzAY+fsAAAAuAJhBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWJpHh51JkybJZrM5LE2bNrWvP3/+vJKSklSzZk0FBgZqwIABOnLkiBsrBgAAnsajw44kNW/eXBkZGfZlw4YN9nUPPfSQli5dqsWLF2vdunU6fPiw+vfv78ZqAQCAp6nq7gKupmrVqoqIiCjUnpWVpTfeeEMLFizQbbfdJklKSUnRDTfcoK+++kq///3vK7tUAADggTz+ys6PP/6oyMhINWjQQEOGDFF6erokacuWLbpw4YLi4uLsfZs2bap69eopNTXVXeUCAAAP49FXdjp06KB58+apSZMmysjI0OTJk3Xrrbfqu+++U2Zmpnx8fBQSEuKwTXh4uDIzM0vcb25urnJzc+2vs7OzK6J8AADgATw67PTs2dP+51atWqlDhw6Kjo7Wu+++q2rVqjm93ylTpmjy5MmuKBEAAHg4j/8Y63IhISG6/vrrlZaWpoiICOXl5enUqVMOfY4cOVLkHJ/LTZgwQVlZWfblwIEDFVg1AABwp2sq7OTk5Gjv3r2qU6eO2rVrJ29vb61atcq+fs+ePUpPT1dsbGyJ+/H19VVQUJDDAgAArMmjP8Z65JFH1KdPH0VHR+vw4cOaOHGiqlSpokGDBik4OFgjRozQ+PHjFRoaqqCgID3wwAOKjY3lTiwAAGDn0WHn4MGDGjRokI4fP67atWurY8eO+uqrr1S7dm1J0vTp0+Xl5aUBAwYoNzdX8fHxeu2119xcNQAA8CQeHXYWLlxY4no/Pz/NmjVLs2bNqqSKAADAteaamrMDAABQVoQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaZYJO7NmzVL9+vXl5+enDh06aNOmTe4uCQAAeABLhJ1FixZp/Pjxmjhxor755hu1bt1a8fHxOnr0qLtLAwAAbmaJsDNt2jSNHDlSw4cPV7NmzTRnzhz5+/tr7ty57i4NAAC42TUfdvLy8rRlyxbFxcXZ27y8vBQXF6fU1FQ3VgYAADxBVXcXUF7Hjh1Tfn6+wsPDHdrDw8P1/fffF7lNbm6ucnNz7a+zsrIkSdnZ2S6tLScn59fjZaapIO+8JOnCiYOSpC1bttjXe3l5qaCgwGHbK9voQx9PPb4n9dmzZ4+kK95zxw84tBX1HvT0cdHnt9vH3cd3ps+V78NL77mcnByX/zt7aX/GmJI7mmvcoUOHjCTz5ZdfOrQ/+uij5qabbipym4kTJxpJLCwsLCwsLBZYDhw4UGJWuOav7NSqVUtVqlTRkSNHHNqPHDmiiIiIIreZMGGCxo8fb39dUFCgEydOqGbNmrLZbC6vMTs7W1FRUTpw4ICCgoJcvn93Y3zXNsZ3bWN81zbGVz7GGJ0+fVqRkZEl9rvmw46Pj4/atWunVatWqV+/fpJ+DS+rVq1ScnJykdv4+vrK19fXoS0kJKSCK5WCgoIs+ct8CeO7tjG+axvju7YxPucFBwdftc81H3Ykafz48UpISNCNN96om266STNmzNCZM2c0fPhwd5cGAADczBJh55577tEvv/yiZ555RpmZmWrTpo2WL19eaNIyAAD47bFE2JGk5OTkYj+2cjdfX19NnDix0EdnVsH4rm2M79rG+K5tjK9y2Iy52v1aAAAA165r/qGCAAAAJSHsAAAASyPsAAAASyPsAAAASyPsuNjPP/+sESNGKCYmRtWqVVPDhg01ceJE5eXllbjd+fPnlZSUpJo1ayowMFADBgwo9FRoT/H888/r5ptvlr+/f6kfxpiYmCibzeaw9OjRo2ILdZIz4zPG6JlnnlGdOnVUrVo1xcXF6ccff6zYQp104sQJDRkyREFBQQoJCdGIESMcviOqKF26dCl0/u6///5KqvjqZs2apfr168vPz08dOnTQpk2bSuy/ePFiNW3aVH5+fmrZsqU++eSTSqrUOWUZ37x58wqdKz8/v0qstvTWr1+vPn36KDIyUjabTR9++OFVt1m7dq3atm0rX19fNWrUSPPmzavwOp1V1vGtXbu20Lmz2WzKzMysnILLaMqUKWrfvr2qV6+usLAw9evXz/69WCVxx/uPsONi33//vQoKCvT6669r586dmj59uubMmaMnn3yyxO0eeughLV26VIsXL9a6det0+PBh9e/fv5KqLpu8vDzdddddGj16dJm269GjhzIyMuzLO++8U0EVlo8z45s6dapeffVVzZkzRxs3blRAQIDi4+N1/vz5CqzUOUOGDNHOnTu1YsUKLVu2TOvXr9eoUaOuut3IkSMdzt/UqVMrodqrW7RokcaPH6+JEyfqm2++UevWrRUfH6+jR48W2f/LL7/UoEGDNGLECG3dulX9+vVTv3799N1331Vy5aVT1vFJvz6t9vJztX///kqsuPTOnDmj1q1ba9asWaXqv2/fPvXu3Vtdu3bVtm3bNG7cOP35z3/Wp59+WsGVOqes47tkz549DucvLCysgiosn3Xr1ikpKUlfffWVVqxYoQsXLqh79+46c+ZMsdu47f3nkm/jRImmTp1qYmJiil1/6tQp4+3tbRYvXmxv2717t5FkUlNTK6NEp6SkpJjg4OBS9U1ISDB9+/at0HpcrbTjKygoMBEREeall16yt506dcr4+vqad955pwIrLLtdu3YZSWbz5s32tv/+97/GZrOZQ4cOFbtd586dzdixYyuhwrK76aabTFJSkv11fn6+iYyMNFOmTCmy/91332169+7t0NahQwdz3333VWidzirr+MryvvQkkswHH3xQYp/HHnvMNG/e3KHtnnvuMfHx8RVYmWuUZnxr1qwxkszJkycrpSZXO3r0qJFk1q1bV2wfd73/uLJTCbKyshQaGlrs+i1btujChQuKi4uztzVt2lT16tVTampqZZRYKdauXauwsDA1adJEo0eP1vHjx91dkkvs27dPmZmZDucvODhYHTp08Ljzl5qaqpCQEN144432tri4OHl5eWnjxo0lbvv222+rVq1aatGihSZMmKCzZ89WdLlXlZeXpy1btjj87L28vBQXF1fszz41NdWhvyTFx8d73LmSnBufJOXk5Cg6OlpRUVHq27evdu7cWRnlVrhr6dyVR5s2bVSnTh3dfvvt+uKLL9xdTqllZWVJUon/3rnrHFrmCcqeKi0tTTNnztTLL79cbJ/MzEz5+PgUmh8SHh7usZ/VllWPHj3Uv39/xcTEaO/evXryySfVs2dPpaamqkqVKu4ur1wunaMrv57EE89fZmZmoUviVatWVWhoaIm1Dh48WNHR0YqMjNT27dv1+OOPa8+ePVqyZElFl1yiY8eOKT8/v8if/ffff1/kNpmZmdfEuZKcG1+TJk00d+5ctWrVSllZWXr55Zd18803a+fOnapbt25llF1hijt32dnZOnfunKpVq+amylyjTp06mjNnjm688Ubl5ubq3//+t7p06aKNGzeqbdu27i6vRAUFBRo3bpxuueUWtWjRoth+7nr/cWWnlJ544okiJ45dvlz5l8+hQ4fUo0cP3XXXXRo5cqSbKi8dZ8ZXFgMHDtQdd9yhli1bql+/flq2bJk2b96stWvXum4QJajo8blbRY9v1KhRio+PV8uWLTVkyBDNnz9fH3zwgfbu3evCUcAVYmNjNWzYMLVp00adO3fWkiVLVLt2bb3++uvuLg1X0aRJE913331q166dbr75Zs2dO1c333yzpk+f7u7SriopKUnfffedFi5c6O5SisSVnVJ6+OGHlZiYWGKfBg0a2P98+PBhde3aVTfffLP++c9/lrhdRESE8vLydOrUKYerO0eOHFFERER5yi61so6vvBo0aKBatWopLS1N3bp1c9l+i1OR47t0jo4cOaI6derY248cOaI2bdo4tc+yKu34IiIiCk1svXjxok6cOFGm37UOHTpI+vXKZcOGDctcr6vUqlVLVapUKXTnYknvnYiIiDL1dydnxnclb29v/e53v1NaWlpFlFipijt3QUFB1/xVneLcdNNN2rBhg7vLKFFycrL9ZoerXT101/uPsFNKtWvXVu3atUvV99ChQ+ratavatWunlJQUeXmVfAGtXbt28vb21qpVqzRgwABJv87GT09PV2xsbLlrL42yjM8VDh48qOPHjzuEg4pUkeOLiYlRRESEVq1aZQ832dnZ2rhxY5nvWHNWaccXGxurU6dOacuWLWrXrp0kafXq1SooKLAHmNLYtm2bJFXa+SuOj4+P2rVrp1WrVqlfv36Sfr2cvmrVqmK/GDg2NlarVq3SuHHj7G0rVqyotPdaWTgzvivl5+drx44d6tWrVwVWWjliY2ML3absqefOVbZt2+b291lxjDF64IEH9MEHH2jt2rWKiYm56jZue/9V6PTn36CDBw+aRo0amW7dupmDBw+ajIwM+3J5nyZNmpiNGzfa2+6//35Tr149s3r1avP111+b2NhYExsb644hXNX+/fvN1q1bzeTJk01gYKDZunWr2bp1qzl9+rS9T5MmTcySJUuMMcacPn3aPPLIIyY1NdXs27fPrFy50rRt29Y0btzYnD9/3l3DKFZZx2eMMX/7299MSEiI+eijj8z27dtN3759TUxMjDl37pw7hlCiHj16mN/97ndm48aNZsOGDaZx48Zm0KBB9vVX/n6mpaWZZ5991nz99ddm37595qOPPjINGjQwnTp1ctcQHCxcuND4+vqaefPmmV27dplRo0aZkJAQk5mZaYwx5t577zVPPPGEvf8XX3xhqlatal5++WWze/duM3HiROPt7W127NjhriGUqKzjmzx5svn000/N3r17zZYtW8zAgQONn5+f2blzp7uGUKzTp0/b31+SzLRp08zWrVvN/v37jTHGPPHEE+bee++19//pp5+Mv7+/efTRR83u3bvNrFmzTJUqVczy5cvdNYQSlXV806dPNx9++KH58ccfzY4dO8zYsWONl5eXWblypbuGUKLRo0eb4OBgs3btWod/686ePWvv4ynvP8KOi6WkpBhJRS6X7Nu3z0gya9assbedO3fOjBkzxtSoUcP4+/ubO++80yEgeZKEhIQix3f5eCSZlJQUY4wxZ8+eNd27dze1a9c23t7eJjo62owcOdL+l7WnKev4jPn19vO//OUvJjw83Pj6+ppu3bqZPXv2VH7xpXD8+HEzaNAgExgYaIKCgszw4cMdgtyVv5/p6emmU6dOJjQ01Pj6+ppGjRqZRx991GRlZblpBIXNnDnT1KtXz/j4+JibbrrJfPXVV/Z1nTt3NgkJCQ793333XXP99dcbHx8f07x5c/Of//ynkisum7KMb9y4cfa+4eHhplevXuabb75xQ9VXd+lW6yuXS+NJSEgwnTt3LrRNmzZtjI+Pj2nQoIHD+9DTlHV8L774omnYsKHx8/MzoaGhpkuXLmb16tXuKb4Uivu37vJz4invP9v/LxgAAMCSuBsLAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHgMdLTEws8pvce/To4e7SAFwD+CJQANeEHj16KCUlxaHN19e3yL4XLlyQt7e3Q1teXp58fHzKfFxntwPgObiyA+Ca4Ovrq4iICIelRo0akiSbzabZs2frjjvuUEBAgJ5//nlNmjRJbdq00b///W/FxMTIz89PkpSenq6+ffsqMDBQQUFBuvvuu3XkyBH7cYrbDsC1i7ADwBImTZqkO++8Uzt27NCf/vQnSVJaWpref/99LVmyRNu2bVNBQYH69u2rEydOaN26dVqxYoV++ukn3XPPPQ77unI7ANc2PsYCcE1YtmyZAgMDHdqefPJJPfnkk5KkwYMHa/jw4Q7r8/LyNH/+fNWuXVuStGLFCu3YsUP79u1TVFSUJGn+/Plq3ry5Nm/erPbt2xe5HYBrG2EHwDWha9eumj17tkNbaGio/c833nhjoW2io6MdAsvu3bsVFRVlDzqS1KxZM4WEhGj37t32sHPldgCubYQdANeEgIAANWrUqMT1pWkr7bEAWAdzdgD8Ztxwww06cOCADhw4YG/btWuXTp06pWbNmrmxMgAViSs7AK4Jubm5yszMdGirWrWqatWqVep9xMXFqWXLlhoyZIhmzJihixcvasyYMercuXORH4MBsAau7AC4Jixfvlx16tRxWDp27FimfdhsNn300UeqUaOGOnXqpLi4ODVo0ECLFi2qoKoBeAKbMca4uwgAAICKwpUdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaf8PWmSJz9RtvEMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean error: 0.030105333775281906\n",
      "Standard deviation : 1.4207834005355835\n"
     ]
    }
   ],
   "source": [
    "# Situation 3\n",
    "array = np.random.uniform(-2, 2, 1000).astype(np.float32)\n",
    "min_range = -1\n",
    "max_range = 1\n",
    "display_error_histogram(array, min_range, max_range)\n",
    "quantization_error_stats(array, min_range, max_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "id": "1d1ba903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHHCAYAAABZbpmkAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAPi1JREFUeJzt3Xt8z/X///H7e3Zis42xjcwcozl+qHiXHJc5JOJTkcP4+KiYIuVTqi/Sp5QK1cehTx8m3/JRSgcqOasYSURIkcxhm5w2ww625++Pfnt/vW3Y3t7be15u18vldcn7+Xq+Xq/Hc6+9ufd6PV/vt80YYwQAAGBRXp4uAAAAoCQRdgAAgKURdgAAgKURdgAAgKURdgAAgKURdgAAgKURdgAAgKURdgAAgKURdgAAgKURdgALad++vdq3b3/dHPd6YrPZNHHiRE+XAVyTCDvA/7dz504NGDBAN9xwg/z8/FS9enUNGDBAu3bt8nRpTnbt2qWJEyfq999/vy6Oezlr166VzWa75LJw4UJPl1ioiRMnymaz6dixY4Wur1Wrlu66666rPs6CBQs0ffr0q94PcK3z9nQBQFmwePFi9evXT5UrV9bQoUNVu3Zt/f7775ozZ44+/PBDvf/+++rZs6eny5T0Z+h47rnn1L59e9WqVctp3fLlyy133KJ49NFHdcsttxRot9vtHqimZJw7d07e3sX7K3vBggX66aefNHr06JIpCrhGEHZw3du3b58GDhyoOnXq6Ouvv1bVqlUd60aNGqU77rhDAwYM0Pbt21W7dm0PVnplvr6+19Vx891xxx3661//Wqxt8vLylJ2dLX9//wLrzpw5o4CAgKuq6ezZs6pQocJV7eNChdVZ1rnj5wi4A7excN175ZVXdPbsWf373/92CjqSVKVKFb311lvKyMjQK6+84mgfPHhwgasb0v/dnrhQQkKCOnbsqLCwMPn5+Sk6OlqzZs0qsG3+rYtvv/1Wt956q/z9/VWnTh3Nnz/f0WfevHm69957JUkdOnRw3K5Zu3atpIJzZ2rVqnXJWzz52xw4cEAjRoxQgwYNVL58eYWGhuree+91ul1V3ONK0tGjRzV06FCFh4fL399fzZo10zvvvOPU5/fff5fNZtOrr76qf//736pbt678/Px0yy23aPPmzQV+RlfDZrNp5MiReu+999SoUSP5+flp2bJlmjdvnmw2m9atW6cRI0YoLCxMNWrUcGw3c+ZMR//q1asrPj5ep06dctp3+/bt1bhxY23ZskVt27ZVhQoV9PTTT7u9/gvn7Jw+fVqjR49WrVq15Ofnp7CwMN1555364YcfHDV9/vnnOnDggON8Xfg7W5TzI0nHjx/XwIEDFRQUpJCQEMXFxenHH3+UzWbTvHnzHP0GDx6swMBA7du3T926dVPFihXVv39/SdI333yje++9VzVr1pSfn58iIyP12GOP6dy5c07Hyt9HUlKS7rrrLgUGBuqGG27QjBkzJEk7duxQx44dFRAQoKioKC1YsMBNP11YHVd2cN1bsmSJatWqpTvuuKPQ9W3btlWtWrW0ZMkSzZw5s9j7nzVrlho1aqS7775b3t7eWrJkiUaMGKG8vDzFx8c79d27d6/++te/aujQoYqLi9PcuXM1ePBgtWzZUo0aNVLbtm316KOP6o033tDTTz+tm266SZIc/73Y9OnTlZGR4dQ2bdo0bdu2TaGhoZKkzZs3a8OGDerbt69q1Kih33//XbNmzVL79u21a9cuVahQodjHPXfunNq3b6+9e/dq5MiRql27thYtWqTBgwfr1KlTGjVqlFP/BQsW6PTp03rooYdks9k0ZcoU9e7dW7/99pt8fHyu+DM+ffp0ofNfQkNDncLn6tWr9cEHH2jkyJGqUqWKatWqpW3btkmSRowYoapVq2r8+PE6c+aMpD/D63PPPaeYmBgNHz5ce/bs0axZs7R582atX7/eqbbjx4+ra9eu6tu3rwYMGKDw8PAr1n3ixIlC2/Py8q647cMPP6wPP/xQI0eOVHR0tI4fP65vv/1Wu3fvVosWLfTMM88oLS1Nhw4d0rRp0yRJgYGBkop+fvLy8tSjRw999913Gj58uBo2bKhPP/1UcXFxhdZ0/vx5xcbGqk2bNnr11VcdV7YWLVqks2fPavjw4QoNDdV3332nN998U4cOHdKiRYuc9pGbm6uuXbuqbdu2mjJlit577z2NHDlSAQEBeuaZZ9S/f3/17t1bs2fP1qBBg2S328v8FVeUAQa4jp06dcpIMj179rxsv7vvvttIMunp6cYYY+Li4kxUVFSBfhMmTDAXv63Onj1boF9sbKypU6eOU1tUVJSRZL7++mtH29GjR42fn595/PHHHW2LFi0yksyaNWsK7Lddu3amXbt2lxzHBx98YCSZSZMmXba+xMREI8nMnz/fpeNOnz7dSDLvvvuuoy07O9vY7XYTGBjo+Dnu37/fSDKhoaHmxIkTjr6ffvqpkWSWLFlyybEYY8yaNWuMpEsuycnJjr6SjJeXl9m5c6fTPhISEowk06ZNG3P+/HlH+9GjR42vr6/p3Lmzyc3NdbT/61//MpLM3LlzncYvycyePfuy9ebL/z253NK9e3enbSSZCRMmOF4HBweb+Pj4yx6ne/fuhf6eFvX8fPTRR0aSmT59uqNfbm6u6dixo5FkEhISHO1xcXFGknnqqacKHK+w37HJkycbm81mDhw4UGAfL774oqPt5MmTpnz58sZms5mFCxc62n/++ecCPxPgUriNheva6dOnJUkVK1a8bL/89fn9i6N8+fKOP6elpenYsWNq166dfvvtN6WlpTn1jY6OdrrCVLVqVTVo0EC//fZbsY97sV27dulvf/ubevbsqWeffbbQ+nJycnT8+HHVq1dPISEhjlsixfXFF18oIiJC/fr1c7T5+Pjo0UcfVUZGhtatW+fU//7771elSpUcr/N/BkUd9/jx47VixYoCS+XKlZ36tWvXTtHR0YXuY9iwYSpXrpzj9cqVK5Wdna3Ro0fLy8vLqV9QUJA+//xzp+39/Pw0ZMiQItWb76OPPiq07qJcFQoJCdGmTZt05MiRYh1TKvr5WbZsmXx8fDRs2DBHPy8vrwJXJC80fPjwAm0X/o6dOXNGx44d02233SZjjLZu3Vqg/9///nfHn0NCQtSgQQMFBATovvvuc7Q3aNBAISEhbnlvwPq4jYXrWlFDzOnTp2Wz2VSlSpViH2P9+vWaMGGCEhMTdfbsWad1aWlpCg4OdryuWbNmge0rVaqkkydPFvu4F0pPT1fv3r11ww03aP78+U63ds6dO6fJkycrISFBhw8fljHGqT5XHDhwQPXr13cKCdL/3fY6cOCAU/vF484PPkUdd5MmTRQTE3PFfpe73XHxuvwaGzRo4NTu6+urOnXqFBjDDTfcUOyJ2m3bti30d6ook5GnTJmiuLg4RUZGqmXLlurWrZsGDRqkOnXqXHHbop6fAwcOqFq1agUmWterV6/Q/Xp7ezvNd8qXlJSk8ePH67PPPitwTi/+HfP39y8wdy44OFg1atQoMB8uODj4qt8buD4QdnBdCw4OVvXq1bV9+/bL9tu+fbtq1Kjh+Mfs4r908+Xm5jq93rdvnzp16qSGDRtq6tSpioyMlK+vr7744gtNmzatwNyMC68sXOjCAOKKwYMH68iRI/ruu+8UFBTktO6RRx5RQkKCRo8eLbvdruDgYNlsNvXt27dIc0fcoaTGfbELrzAUZ93V7rsk3Hfffbrjjjv08ccfa/ny5XrllVf08ssva/HixeratWup1pLPz8+vQIDKzc3VnXfeqRMnTujJJ59Uw4YNFRAQoMOHD2vw4MFFfg+U1u8IrImwg+tejx499NZbb+nbb79VmzZtCqz/5ptv9Pvvv2vMmDGOtkqVKhV4IkcqeMViyZIlysrK0meffeZ09WLNmjUu13upoHUpL730kj755BMtXrxYDRs2LLD+ww8/VFxcnF577TVHW2ZmZoHxFee4UVFR2r59u/Ly8pz+8fv5558d68u6/Br37NnjdLUkOztb+/fvL9KVpJJWrVo1jRgxQiNGjNDRo0fVokULvfDCC46wc6lzVtTzExUVpTVr1hR4jH7v3r1FrnHHjh365Zdf9M4772jQoEGO9hUrVhR9oMBVYs4OrntPPPGEKlSooIceekjHjx93WnfixAk9/PDDCgoK0siRIx3tdevWVVpamtMVoeTkZH388cdO2+f/3+jFt4YSEhJcrjf/c0sKC1sXW7lypZ599lk988wz6tWrV6F9ypUrV+D/jt98880CV6mKc9xu3bopJSVF77//vqPt/PnzevPNNxUYGKh27dpdcR+eFhMTI19fX73xxhtOP585c+YoLS1N3bt391htubm5BW7/hIWFqXr16srKynK0BQQEFHorsqjnJzY2Vjk5OXr77bcd/fLy8hyPghdFYe8BY4xef/31Iu8DuFpc2cF1r169epo/f7769eunJk2aFPgE5ZMnT2rhwoVOczr69u2rJ598Uvfcc48effRRnT17VrNmzdKNN97oNKm3c+fO8vX1VY8ePfTQQw8pIyNDb7/9tsLCwpScnOxSvc2bN1e5cuX08ssvKy0tTX5+fo7P8blYv379VLVqVdWvX1/vvvuu07o777xT4eHhuuuuu/S///u/Cg4OVnR0tBITE7Vy5UrHo+muHPfBBx/UW2+9pcGDB2vLli2qVauWPvzwQ61fv17Tp0+/4oTw4vrmm2+UmZlZoL1p06Zq2rSpS/usWrWqxo0bp+eee05dunTR3XffrT179mjmzJm65ZZbNGDAgKst22WnT59WjRo19Ne//lXNmjVTYGCgVq5cqc2bNztdoWvZsqXef/99jRkzRrfccosCAwPVo0ePIp+fXr166dZbb9Xjjz+uvXv3qmHDhvrss88cj8wX5Wpfw4YNVbduXT3xxBM6fPiwgoKC9NFHHzHXBqXLU4+BAWXNjh07zAMPPGAiIiKMl5eXkWT8/f0LPKqcb/ny5aZx48bG19fXNGjQwLz77ruFPnr+2WefmaZNmxp/f39Tq1Yt8/LLL5u5c+caSWb//v2OflFRUQUeNzam8MfJ3377bVOnTh1Trlw5p8fBL+6ryzzanL/NyZMnzZAhQ0yVKlVMYGCgiY2NNT///LOJiooycXFxLh3XGGNSU1Md+/X19TVNmjRxelTZmP979PyVV14pMG4V4bHiKz16fuH2kgp9VDv/0fPNmzcXeox//etfpmHDhsbHx8eEh4eb4cOHm5MnTzr1adeunWnUqNFla71Q/u/JH3/8Uej6wn4XLhxPVlaWGTt2rGnWrJmpWLGiCQgIMM2aNTMzZ8502iYjI8M88MADJiQkxEhyegy9KOfHGGP++OMP88ADD5iKFSua4OBgM3jwYLN+/XojyelR8Li4OBMQEFDoeHbt2mViYmJMYGCgqVKlihk2bJj58ccfC318vbB9XOrne6n3DHAxmzHM7gIKM3/+fA0ePFgDBgxw+hRj4Hr3ySef6J577tG3336r22+/3dPlAFfEbSzgEgYNGqTk5GQ99dRTqlGjhl588UVPlwSUunPnzjk9aZabm6s333xTQUFBatGihQcrA4qOKzsAgEv6+9//rnPnzslutysrK0uLFy/Whg0b9OKLL2rcuHGeLg8oEsIOAOCSFixYoNdee0179+5VZmam6tWrp+HDhzs9nQiUdYQdAABgaXzODgAAsDTCDgAAsDSextKfnwh65MgRVaxYsdgfxQ8AADzDGKPTp0+revXqBb6X7UKEHUlHjhxRZGSkp8sAAAAuOHjwoGrUqHHJ9YQdyfHR6AcPHizwjdAAAKBsSk9PV2Rk5BW/goawo//7fpegoCDCDgAA15grTUFhgjIAALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0b08XAAAlLSkpSceOHXO8rlKlimrWrOnBigCUJsIOAEtLSkpSg4Y3KfPcWUebf/kK2vPzbgIPcJ0g7ACwtGPHjinz3FmF3vW4fEIjlXP8oI4vfU3Hjh0j7ADXCcIOgOuCT2ik/CLqeboMAB7ABGUAAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBpHg07EydOlM1mc1oaNmzoWJ+Zman4+HiFhoYqMDBQffr0UWpqqtM+kpKS1L17d1WoUEFhYWEaO3aszp8/X9pDAQAAZZTHv/W8UaNGWrlypeO1t/f/lfTYY4/p888/16JFixQcHKyRI0eqd+/eWr9+vSQpNzdX3bt3V0REhDZs2KDk5GQNGjRIPj4+evHFF0t9LAAAoOzxeNjx9vZWREREgfa0tDTNmTNHCxYsUMeOHSVJCQkJuummm7Rx40a1bt1ay5cv165du7Ry5UqFh4erefPmev755/Xkk09q4sSJ8vX1Le3hAACAMsbjc3Z+/fVXVa9eXXXq1FH//v2VlJQkSdqyZYtycnIUExPj6NuwYUPVrFlTiYmJkqTExEQ1adJE4eHhjj6xsbFKT0/Xzp07L3nMrKwspaenOy0AAMCaPBp2WrVqpXnz5mnZsmWaNWuW9u/frzvuuEOnT59WSkqKfH19FRIS4rRNeHi4UlJSJEkpKSlOQSd/ff66S5k8ebKCg4MdS2RkpHsHBgAAygyP3sbq2rWr489NmzZVq1atFBUVpQ8++EDly5cvseOOGzdOY8aMcbxOT08n8AAAYFEev411oZCQEN14443au3evIiIilJ2drVOnTjn1SU1NdczxiYiIKPB0Vv7rwuYB5fPz81NQUJDTAgAArKlMhZ2MjAzt27dP1apVU8uWLeXj46NVq1Y51u/Zs0dJSUmy2+2SJLvdrh07dujo0aOOPitWrFBQUJCio6NLvX4AAFD2ePQ21hNPPKEePXooKipKR44c0YQJE1SuXDn169dPwcHBGjp0qMaMGaPKlSsrKChIjzzyiOx2u1q3bi1J6ty5s6KjozVw4EBNmTJFKSkpevbZZxUfHy8/Pz9PDg0AAJQRHg07hw4dUr9+/XT8+HFVrVpVbdq00caNG1W1alVJ0rRp0+Tl5aU+ffooKytLsbGxmjlzpmP7cuXKaenSpRo+fLjsdrsCAgIUFxenSZMmeWpIAACgjPFo2Fm4cOFl1/v7+2vGjBmaMWPGJftERUXpiy++cHdpAADAIsrUnB0AAAB3I+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABL8/Z0AQDgTklJSTp27Jjj9e7duz1YDYCygLADwDKSkpLUoOFNyjx31tOlAChDCDsALOPYsWPKPHdWoXc9Lp/QSEnSud++V9o373q4MgCeRNgBYDk+oZHyi6gnSco5ftDD1QDwNCYoAwAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyszYeell16SzWbT6NGjHW2ZmZmKj49XaGioAgMD1adPH6Wmpjptl5SUpO7du6tChQoKCwvT2LFjdf78+VKuHgAAlFVlIuxs3rxZb731lpo2berU/thjj2nJkiVatGiR1q1bpyNHjqh3796O9bm5uerevbuys7O1YcMGvfPOO5o3b57Gjx9f2kMAAABllMfDTkZGhvr376+3335blSpVcrSnpaVpzpw5mjp1qjp27KiWLVsqISFBGzZs0MaNGyVJy5cv165du/Tuu++qefPm6tq1q55//nnNmDFD2dnZnhoSAAAoQzweduLj49W9e3fFxMQ4tW/ZskU5OTlO7Q0bNlTNmjWVmJgoSUpMTFSTJk0UHh7u6BMbG6v09HTt3LmzdAYAAADKNI9+EejChQv1ww8/aPPmzQXWpaSkyNfXVyEhIU7t4eHhSklJcfS5MOjkr89fdylZWVnKyspyvE5PT3d1CAAAoIzz2JWdgwcPatSoUXrvvffk7+9fqseePHmygoODHUtkZGSpHh8AAJQej4WdLVu26OjRo2rRooW8vb3l7e2tdevW6Y033pC3t7fCw8OVnZ2tU6dOOW2XmpqqiIgISVJERESBp7PyX+f3Kcy4ceOUlpbmWA4ePOjewQEAgDLDY2GnU6dO2rFjh7Zt2+ZYbr75ZvXv39/xZx8fH61atcqxzZ49e5SUlCS73S5Jstvt2rFjh44ePeros2LFCgUFBSk6OvqSx/bz81NQUJDTAgAArMljc3YqVqyoxo0bO7UFBAQoNDTU0T506FCNGTNGlStXVlBQkB555BHZ7Xa1bt1aktS5c2dFR0dr4MCBmjJlilJSUvTss88qPj5efn5+pT4mAABQ9nh0gvKVTJs2TV5eXurTp4+ysrIUGxurmTNnOtaXK1dOS5cu1fDhw2W32xUQEKC4uDhNmjTJg1UDAICypEyFnbVr1zq99vf314wZMzRjxoxLbhMVFaUvvviihCsDAADXKo9/zg4AAEBJIuwAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLcyns/Pbbb+6uAwAAoES4FHbq1aunDh066N1331VmZqa7awIAAHAbl8LODz/8oKZNm2rMmDGKiIjQQw89pO+++87dtQEAAFw1l8JO8+bN9frrr+vIkSOaO3eukpOT1aZNGzVu3FhTp07VH3/84e46AQAAXHJVE5S9vb3Vu3dvLVq0SC+//LL27t2rJ554QpGRkRo0aJCSk5PdVScAAIBLrirsfP/99xoxYoSqVaumqVOn6oknntC+ffu0YsUKHTlyRD179nRXnQAAAC7xdmWjqVOnKiEhQXv27FG3bt00f/58devWTV5ef2an2rVra968eapVq5Y7awUAACg2l8LOrFmz9Le//U2DBw9WtWrVCu0TFhamOXPmXFVxAAAAV8ulsPPrr79esY+vr6/i4uJc2T0AAIDbuDRnJyEhQYsWLSrQvmjRIr3zzjtXXRQAAIC7uBR2Jk+erCpVqhRoDwsL04svvnjVRQEAALiLS2EnKSlJtWvXLtAeFRWlpKSkqy4KAADAXVwKO2FhYdq+fXuB9h9//FGhoaFXXRQAAIC7uBR2+vXrp0cffVRr1qxRbm6ucnNztXr1ao0aNUp9+/Z1d40AAAAucynsPP/882rVqpU6deqk8uXLq3z58urcubM6duxYrDk7s2bNUtOmTRUUFKSgoCDZ7XZ9+eWXjvWZmZmKj49XaGioAgMD1adPH6WmpjrtIykpSd27d1eFChUUFhamsWPH6vz5864MCwAAWJBLj577+vrq/fff1/PPP68ff/xR5cuXV5MmTRQVFVWs/dSoUUMvvfSS6tevL2OM3nnnHfXs2VNbt25Vo0aN9Nhjj+nzzz/XokWLFBwcrJEjR6p3795av369JCk3N1fdu3dXRESENmzYoOTkZA0aNEg+Pj5MlAYAAJJcDDv5brzxRt14440ub9+jRw+n1y+88IJmzZqljRs3qkaNGpozZ44WLFigjh07SvrzkfebbrpJGzduVOvWrbV8+XLt2rVLK1euVHh4uJo3b67nn39eTz75pCZOnChfX9+rGR4AALAAl8JObm6u5s2bp1WrVuno0aPKy8tzWr969WqX9rlo0SKdOXNGdrtdW7ZsUU5OjmJiYhx9GjZsqJo1ayoxMVGtW7dWYmKimjRpovDwcEef2NhYDR8+XDt37tRf/vKXQo+VlZWlrKwsx+v09PRi1wsAAK4NLoWdUaNGad68eerevbsaN24sm83mcgE7duyQ3W5XZmamAgMD9fHHHys6Olrbtm2Tr6+vQkJCnPqHh4crJSVFkpSSkuIUdPLX56+7lMmTJ+u5555zuWYAAHDtcCnsLFy4UB988IG6det21QU0aNBA27ZtU1pamj788EPFxcVp3bp1V73fyxk3bpzGjBnjeJ2enq7IyMgSPSYAAPAMlyco16tXzy0FXLivli1bavPmzXr99dd1//33Kzs7W6dOnXK6upOamqqIiAhJUkREhL777jun/eU/rZXfpzB+fn7y8/NzS/0AAKBsc+nR88cff1yvv/66jDHurkd5eXnKyspSy5Yt5ePjo1WrVjnW7dmzR0lJSbLb7ZIku92uHTt26OjRo44+K1asUFBQkKKjo91eGwAAuPa4dGXn22+/1Zo1a/Tll1+qUaNG8vHxcVq/ePHiIu1n3Lhx6tq1q2rWrKnTp09rwYIFWrt2rb766isFBwdr6NChGjNmjCpXrqygoCA98sgjstvtat26tSSpc+fOio6O1sCBAzVlyhSlpKTo2WefVXx8PFduAACAJBfDTkhIiO65556rPvjRo0c1aNAgJScnKzg4WE2bNtVXX32lO++8U5I0bdo0eXl5qU+fPsrKylJsbKxmzpzp2L5cuXJaunSphg8fLrvdroCAAMXFxWnSpElXXRsAALAGl8JOQkKCWw4+Z86cy6739/fXjBkzNGPGjEv2iYqK0hdffOGWegAAgPW4NGdHks6fP6+VK1fqrbfe0unTpyVJR44cUUZGhtuKAwAAuFouXdk5cOCAunTpoqSkJGVlZenOO+9UxYoV9fLLLysrK0uzZ892d50AAAAucenKzqhRo3TzzTfr5MmTKl++vKP9nnvucXp6CgAAwNNcurLzzTffaMOGDQW+e6pWrVo6fPiwWwoDAABwB5eu7OTl5Sk3N7dA+6FDh1SxYsWrLgoAAMBdXAo7nTt31vTp0x2vbTabMjIyNGHCBLd8hQQAAIC7uHQb67XXXlNsbKyio6OVmZmpBx54QL/++quqVKmi//73v+6uEQAAwGUuhZ0aNWroxx9/1MKFC7V9+3ZlZGRo6NCh6t+/v9OEZQAAAE9zKexIkre3twYMGODOWgAAANzOpbAzf/78y64fNGiQS8UAAAC4m0thZ9SoUU6vc3JydPbsWfn6+qpChQqEHQAAUGa49DTWyZMnnZaMjAzt2bNHbdq0YYIyAAAoU1z+bqyL1a9fXy+99FKBqz4AAACe5LawI/05afnIkSPu3CUAAMBVcWnOzmeffeb02hij5ORk/etf/9Ltt9/ulsIAAADcwaWw06tXL6fXNptNVatWVceOHfXaa6+5oy4AAAC3cCns5OXlubsOAACAEuHWOTsAAABljUtXdsaMGVPkvlOnTnXlEAAAAG7hUtjZunWrtm7dqpycHDVo0ECS9Msvv6hcuXJq0aKFo5/NZnNPlQAAAC5yKez06NFDFStW1DvvvKNKlSpJ+vODBocMGaI77rhDjz/+uFuLBAAAcJVLc3Zee+01TZ482RF0JKlSpUr65z//ydNYAACgTHEp7KSnp+uPP/4o0P7HH3/o9OnTV10UAACAu7gUdu655x4NGTJEixcv1qFDh3To0CF99NFHGjp0qHr37u3uGgEAAFzm0pyd2bNn64knntADDzygnJycP3fk7a2hQ4fqlVdecWuBAAAAV8OlsFOhQgXNnDlTr7zyivbt2ydJqlu3rgICAtxaHAAAwNW6qg8VTE5OVnJysurXr6+AgAAZY9xVFwAAgFu4FHaOHz+uTp066cYbb1S3bt2UnJwsSRo6dCiPnQMAgDLFpbDz2GOPycfHR0lJSapQoYKj/f7779eyZcvcVhwAAMDVcmnOzvLly/XVV1+pRo0aTu3169fXgQMH3FIYAACAO7h0ZefMmTNOV3TynThxQn5+flddFAAAgLu4FHbuuOMOzZ8/3/HaZrMpLy9PU6ZMUYcOHdxWHAAAwNVy6TbWlClT1KlTJ33//ffKzs7WP/7xD+3cuVMnTpzQ+vXr3V0jAACAy1y6stO4cWP98ssvatOmjXr27KkzZ86od+/e2rp1q+rWrevuGgEAAFxW7Cs7OTk56tKli2bPnq1nnnmmJGoCAABwm2Jf2fHx8dH27dtLohYAAAC3c+k21oABAzRnzhx31wIAAOB2Lk1QPn/+vObOnauVK1eqZcuWBb4Ta+rUqW4pDgAA4GoVK+z89ttvqlWrln766Se1aNFCkvTLL7849bHZbO6rDgAA4CoVK+zUr19fycnJWrNmjaQ/vx7ijTfeUHh4eIkUBwAAcLWKNWfn4m81//LLL3XmzBm3FgQAAOBOLk1Qzndx+AEAAChrihV2bDZbgTk5zNEBAABlWbHm7BhjNHjwYMeXfWZmZurhhx8u8DTW4sWL3VchAADAVShW2ImLi3N6PWDAALcWAwAA4G7FCjsJCQklVQcAAECJuKoJygAAAGUdYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFiaR8PO5MmTdcstt6hixYoKCwtTr169tGfPHqc+mZmZio+PV2hoqAIDA9WnTx+lpqY69UlKSlL37t1VoUIFhYWFaezYsTp//nxpDgUAAJRRHg0769atU3x8vDZu3KgVK1YoJydHnTt31pkzZxx9HnvsMS1ZskSLFi3SunXrdOTIEfXu3duxPjc3V927d1d2drY2bNigd955R/PmzdP48eM9MSQAAFDGFOu7sdxt2bJlTq/nzZunsLAwbdmyRW3btlVaWprmzJmjBQsWqGPHjpL+/H6um266SRs3blTr1q21fPly7dq1SytXrlR4eLiaN2+u559/Xk8++aQmTpwoX19fTwwNAACUEWVqzk5aWpokqXLlypKkLVu2KCcnRzExMY4+DRs2VM2aNZWYmChJSkxMVJMmTRQeHu7oExsbq/T0dO3cubMUqwcAAGWRR6/sXCgvL0+jR4/W7bffrsaNG0uSUlJS5Ovrq5CQEKe+4eHhSklJcfS5MOjkr89fV5isrCxlZWU5Xqenp7trGAAAoIwpM1d24uPj9dNPP2nhwoUlfqzJkycrODjYsURGRpb4MQEAgGeUibAzcuRILV26VGvWrFGNGjUc7REREcrOztapU6ec+qempioiIsLR5+Kns/Jf5/e52Lhx45SWluZYDh486MbRAACAssSjYccYo5EjR+rjjz/W6tWrVbt2baf1LVu2lI+Pj1atWuVo27Nnj5KSkmS32yVJdrtdO3bs0NGjRx19VqxYoaCgIEVHRxd6XD8/PwUFBTktAADAmjw6Zyc+Pl4LFizQp59+qooVKzrm2AQHB6t8+fIKDg7W0KFDNWbMGFWuXFlBQUF65JFHZLfb1bp1a0lS586dFR0drYEDB2rKlClKSUnRs88+q/j4ePn5+XlyeAAAoAzwaNiZNWuWJKl9+/ZO7QkJCRo8eLAkadq0afLy8lKfPn2UlZWl2NhYzZw509G3XLlyWrp0qYYPHy673a6AgADFxcVp0qRJpTUMAABQhnk07BhjrtjH399fM2bM0IwZMy7ZJyoqSl988YU7SwMAABZRJiYoAwAAlBTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDSPhp2vv/5aPXr0UPXq1WWz2fTJJ584rTfGaPz48apWrZrKly+vmJgY/frrr059Tpw4of79+ysoKEghISEaOnSoMjIySnEUAACgLPNo2Dlz5oyaNWumGTNmFLp+ypQpeuONNzR79mxt2rRJAQEBio2NVWZmpqNP//79tXPnTq1YsUJLly7V119/rQcffLC0hgAAAMo4b08evGvXruratWuh64wxmj59up599ln17NlTkjR//nyFh4frk08+Ud++fbV7924tW7ZMmzdv1s033yxJevPNN9WtWze9+uqrql69eqmNBQAAlE1lds7O/v37lZKSopiYGEdbcHCwWrVqpcTERElSYmKiQkJCHEFHkmJiYuTl5aVNmzZdct9ZWVlKT093WgAAgDWV2bCTkpIiSQoPD3dqDw8Pd6xLSUlRWFiY03pvb29VrlzZ0acwkydPVnBwsGOJjIx0c/UAAKCsKLNhpySNGzdOaWlpjuXgwYOeLgkAAJSQMht2IiIiJEmpqalO7ampqY51EREROnr0qNP68+fP68SJE44+hfHz81NQUJDTAgAArKnMhp3atWsrIiJCq1atcrSlp6dr06ZNstvtkiS73a5Tp05py5Ytjj6rV69WXl6eWrVqVeo1AwCAssejT2NlZGRo7969jtf79+/Xtm3bVLlyZdWsWVOjR4/WP//5T9WvX1+1a9fW//zP/6h69erq1auXJOmmm25Sly5dNGzYMM2ePVs5OTkaOXKk+vbty5NYAABAkofDzvfff68OHTo4Xo8ZM0aSFBcXp3nz5ukf//iHzpw5owcffFCnTp1SmzZttGzZMvn7+zu2ee+99zRy5Eh16tRJXl5e6tOnj954441SHwsAACibPBp22rdvL2PMJdfbbDZNmjRJkyZNumSfypUra8GCBSVRHgAAsIAyO2cHAADAHQg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0rw9XQAAALCWpKQkHTt2zPG6SpUqqlmzpsfqIewAAAC3SUpKUoOGNynz3FlHm3/5Ctrz826PBR7CDgAAcJtjx44p89xZhd71uHxCI5Vz/KCOL31Nx44dI+wAAADr8AmNlF9EPU+XIYmwU+Iuvm8pef7eJQAA1xPCTgkq7L6l5Pl7lwAAXE8IOyXo4vuWksrEvUsAAK4nhJ1SUJbuWwIAcL3hQwUBAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClWSbszJgxQ7Vq1ZK/v79atWql7777ztMlAQCAMsASYef999/XmDFjNGHCBP3www9q1qyZYmNjdfToUU+XBgAAPMwSYWfq1KkaNmyYhgwZoujoaM2ePVsVKlTQ3LlzPV0aAADwsGs+7GRnZ2vLli2KiYlxtHl5eSkmJkaJiYkerAwAAJQF1/zXRRw7dky5ubkKDw93ag8PD9fPP/9c6DZZWVnKyspyvE5LS5Mkpaenu7W2jIyMP4+Xsld52ZmSpJwThyRJW7Zscaz38vJSXl6e07YXt9GHPmX1+GWpz549eyRd9J47ftCprbD3YFkfF32u3z6ePr4rfS5+H+a/5zIyMtz+72z+/owxl+9ornGHDx82ksyGDRuc2seOHWtuvfXWQreZMGGCkcTCwsLCwsJigeXgwYOXzQrX/JWdKlWqqFy5ckpNTXVqT01NVURERKHbjBs3TmPGjHG8zsvL04kTJxQaGiqbzeb2GtPT0xUZGamDBw8qKCjI7fv3NMZ3bWN81zbGd21jfFfHGKPTp0+revXql+13zYcdX19ftWzZUqtWrVKvXr0k/RleVq1apZEjRxa6jZ+fn/z8/JzaQkJCSrhSKSgoyJK/zPkY37WN8V3bGN+1jfG5Ljg4+Ip9rvmwI0ljxoxRXFycbr75Zt16662aPn26zpw5oyFDhni6NAAA4GGWCDv333+//vjjD40fP14pKSlq3ry5li1bVmDSMgAAuP5YIuxI0siRIy9528rT/Pz8NGHChAK3zqyC8V3bGN+1jfFd2xhf6bAZc6XntQAAAK5d1/yHCgIAAFwOYQcAAFgaYQcAAFgaYQcAAFgaYcfNfv/9dw0dOlS1a9dW+fLlVbduXU2YMEHZ2dmX3S4zM1Px8fEKDQ1VYGCg+vTpU+BTocuKF154QbfddpsqVKhQ5A9jHDx4sGw2m9PSpUuXki3URa6Mzxij8ePHq1q1aipfvrxiYmL066+/lmyhLjpx4oT69++voKAghYSEaOjQoU7fEVWY9u3bFzh/Dz/8cClVfGUzZsxQrVq15O/vr1atWum77767bP9FixapYcOG8vf3V5MmTfTFF1+UUqWuKc745s2bV+Bc+fv7l2K1Rff111+rR48eql69umw2mz755JMrbrN27Vq1aNFCfn5+qlevnubNm1fidbqquONbu3ZtgXNns9mUkpJSOgUX0+TJk3XLLbeoYsWKCgsLU69evRzfi3U5nnj/EXbc7Oeff1ZeXp7eeust7dy5U9OmTdPs2bP19NNPX3a7xx57TEuWLNGiRYu0bt06HTlyRL179y6lqosnOztb9957r4YPH16s7bp06aLk5GTH8t///reEKrw6roxvypQpeuONNzR79mxt2rRJAQEBio2NVWZmZglW6pr+/ftr586dWrFihZYuXaqvv/5aDz744BW3GzZsmNP5mzJlSilUe2Xvv/++xowZowkTJuiHH35Qs2bNFBsbq6NHjxbaf8OGDerXr5+GDh2qrVu3qlevXurVq5d++umnUq68aIo7PunPT6u98FwdOHCgFCsuujNnzqhZs2aaMWNGkfrv379f3bt3V4cOHbRt2zaNHj1af//73/XVV1+VcKWuKe748u3Zs8fp/IWFhZVQhVdn3bp1io+P18aNG7VixQrl5OSoc+fOOnPmzCW38dj7zy3fxonLmjJliqldu/Yl1586dcr4+PiYRYsWOdp2795tJJnExMTSKNElCQkJJjg4uEh94+LiTM+ePUu0Hncr6vjy8vJMRESEeeWVVxxtp06dMn5+fua///1vCVZYfLt27TKSzObNmx1tX375pbHZbObw4cOX3K5du3Zm1KhRpVBh8d16660mPj7e8To3N9dUr17dTJ48udD+9913n+nevbtTW6tWrcxDDz1UonW6qrjjK877siyRZD7++OPL9vnHP/5hGjVq5NR2//33m9jY2BKszD2KMr41a9YYSebkyZOlUpO7HT161Egy69atu2QfT73/uLJTCtLS0lS5cuVLrt+yZYtycnIUExPjaGvYsKFq1qypxMTE0iixVKxdu1ZhYWFq0KCBhg8fruPHj3u6JLfYv3+/UlJSnM5fcHCwWrVqVebOX2JiokJCQnTzzTc72mJiYuTl5aVNmzZddtv33ntPVapUUePGjTVu3DidPXu2pMu9ouzsbG3ZssXpZ+/l5aWYmJhL/uwTExOd+ktSbGxsmTtXkmvjk6SMjAxFRUUpMjJSPXv21M6dO0uj3BJ3LZ27q9G8eXNVq1ZNd955p9avX+/pcoosLS1Nki77752nzqFlPkG5rNq7d6/efPNNvfrqq5fsk5KSIl9f3wLzQ8LDw8vsvdri6tKli3r37q3atWtr3759evrpp9W1a1clJiaqXLlyni7vquSfo4u/nqQsnr+UlJQCl8S9vb1VuXLly9b6wAMPKCoqStWrV9f27dv15JNPas+ePVq8eHFJl3xZx44dU25ubqE/+59//rnQbVJSUq6JcyW5Nr4GDRpo7ty5atq0qdLS0vTqq6/qtttu086dO1WjRo3SKLvEXOrcpaen69y5cypfvryHKnOPatWqafbs2br55puVlZWl//znP2rfvr02bdqkFi1aeLq8y8rLy9Po0aN1++23q3Hjxpfs56n3H1d2iuipp54qdOLYhcvFf/kcPnxYXbp00b333qthw4Z5qPKicWV8xdG3b1/dfffdatKkiXr16qWlS5dq8+bNWrt2rfsGcRklPT5PK+nxPfjgg4qNjVWTJk3Uv39/zZ8/Xx9//LH27dvnxlHAHex2uwYNGqTmzZurXbt2Wrx4sapWraq33nrL06XhCho0aKCHHnpILVu21G233aa5c+fqtttu07Rp0zxd2hXFx8frp59+0sKFCz1dSqG4slNEjz/+uAYPHnzZPnXq1HH8+ciRI+rQoYNuu+02/fvf/77sdhEREcrOztapU6ecru6kpqYqIiLiasousuKO72rVqVNHVapU0d69e9WpUye37fdSSnJ8+ecoNTVV1apVc7SnpqaqefPmLu2zuIo6voiIiAITW8+fP68TJ04U63etVatWkv68clm3bt1i1+suVapUUbly5Qo8uXi5905ERESx+nuSK+O7mI+Pj/7yl79o7969JVFiqbrUuQsKCrrmr+pcyq233qpvv/3W02Vc1siRIx0PO1zp6qGn3n+EnSKqWrWqqlatWqS+hw8fVocOHdSyZUslJCTIy+vyF9BatmwpHx8frVq1Sn369JH052z8pKQk2e32q669KIozPnc4dOiQjh8/7hQOSlJJjq927dqKiIjQqlWrHOEmPT1dmzZtKvYTa64q6vjsdrtOnTqlLVu2qGXLlpKk1atXKy8vzxFgimLbtm2SVGrn71J8fX3VsmVLrVq1Sr169ZL05+X0VatWXfKLge12u1atWqXRo0c72lasWFFq77XicGV8F8vNzdWOHTvUrVu3Eqy0dNjt9gKPKZfVc+cu27Zt8/j77FKMMXrkkUf08ccfa+3atapdu/YVt/HY+69Epz9fhw4dOmTq1atnOnXqZA4dOmSSk5Mdy4V9GjRoYDZt2uRoe/jhh03NmjXN6tWrzffff2/sdrux2+2eGMIVHThwwGzdutU899xzJjAw0GzdutVs3brVnD592tGnQYMGZvHixcYYY06fPm2eeOIJk5iYaPbv329WrlxpWrRoYerXr28yMzM9NYxLKu74jDHmpZdeMiEhIebTTz8127dvNz179jS1a9c2586d88QQLqtLly7mL3/5i9m0aZP59ttvTf369U2/fv0c6y/+/dy7d6+ZNGmS+f77783+/fvNp59+aurUqWPatm3rqSE4WbhwofHz8zPz5s0zu3btMg8++KAJCQkxKSkpxhhjBg4caJ566ilH//Xr1xtvb2/z6quvmt27d5sJEyYYHx8fs2PHDk8N4bKKO77nnnvOfPXVV2bfvn1my5Ytpm/fvsbf39/s3LnTU0O4pNOnTzveX5LM1KlTzdatW82BAweMMcY89dRTZuDAgY7+v/32m6lQoYIZO3as2b17t5kxY4YpV66cWbZsmaeGcFnFHd+0adPMJ598Yn799VezY8cOM2rUKOPl5WVWrlzpqSFc1vDhw01wcLBZu3at0791Z8+edfQpK+8/wo6bJSQkGEmFLvn2799vJJk1a9Y42s6dO2dGjBhhKlWqZCpUqGDuuecep4BUlsTFxRU6vgvHI8kkJCQYY4w5e/as6dy5s6latarx8fExUVFRZtiwYY6/rMua4o7PmD8fP/+f//kfEx4ebvz8/EynTp3Mnj17Sr/4Ijh+/Ljp16+fCQwMNEFBQWbIkCFOQe7i38+kpCTTtm1bU7lyZePn52fq1atnxo4da9LS0jw0goLefPNNU7NmTePr62tuvfVWs3HjRse6du3ambi4OKf+H3zwgbnxxhuNr6+vadSokfn8889LueLiKc74Ro8e7egbHh5uunXrZn744QcPVH1l+Y9aX7zkjycuLs60a9euwDbNmzc3vr6+pk6dOk7vw7KmuON7+eWXTd26dY2/v7+pXLmyad++vVm9erVnii+CS/1bd+E5KSvvP9v/LxgAAMCSeBoLAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHQJk3ePDgQr/JvUuXLp4uDcA1gC8CBXBN6NKlixISEpza/Pz8Cu2bk5MjHx8fp7bs7Gz5+voW+7iubgeg7ODKDoBrgp+fnyIiIpyWSpUqSZJsNptmzZqlu+++WwEBAXrhhRc0ceJENW/eXP/5z39Uu3Zt+fv7S5KSkpLUs2dPBQYGKigoSPfdd59SU1Mdx7nUdgCuXYQdAJYwceJE3XPPPdqxY4f+9re/SZL27t2rjz76SIsXL9a2bduUl5ennj176sSJE1q3bp1WrFih3377Tffff7/Tvi7eDsC1jdtYAK4JS5cuVWBgoFPb008/raefflqS9MADD2jIkCFO67OzszV//nxVrVpVkrRixQrt2LFD+/fvV2RkpCRp/vz5atSokTZv3qxbbrml0O0AXNsIOwCuCR06dNCsWbOc2ipXruz4880331xgm6ioKKfAsnv3bkVGRjqCjiRFR0crJCREu3fvdoSdi7cDcG0j7AC4JgQEBKhevXqXXV+UtqIeC4B1MGcHwHXjpptu0sGDB3Xw4EFH265du3Tq1ClFR0d7sDIAJYkrOwCuCVlZWUpJSXFq8/b2VpUqVYq8j5iYGDVp0kT9+/fX9OnTdf78eY0YMULt2rUr9DYYAGvgyg6Aa8KyZctUrVo1p6VNmzbF2ofNZtOnn36qSpUqqW3btoqJiVGdOnX0/vvvl1DVAMoCmzHGeLoIAACAksKVHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGn/D6eJHw/YyJX4AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean error: 0.012168971821665764\n",
      "Standard deviation : 0.43982189893722534\n"
     ]
    }
   ],
   "source": [
    "# Situation 4 :\n",
    "array = np.random.normal(0, 0.5, 1000).astype(np.float32)\n",
    "min_range = -1\n",
    "max_range = 1\n",
    "display_error_histogram(array, min_range, max_range)\n",
    "quantization_error_stats(array, min_range, max_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7895769f",
   "metadata": {},
   "source": [
    "## Post training quantization from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "id": "45e1aa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def quantize_model_naive(model):\n",
    "    model_q = copy.deepcopy(model)\n",
    "    # find minumum value \n",
    "    for param in model_q.parameters():\n",
    "        param.data = torch.round(param.data).to(torch.int8).to(torch.float32)\n",
    "\n",
    "    return model_q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "id": "a67aea59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original accuracy: 0.9764\n",
      "Quantized naive accuracy: 0.098\n"
     ]
    }
   ],
   "source": [
    "model_q = quantize_model_naive(model)\n",
    "print(\"Original accuracy:\", model.evaluate(test_loader))\n",
    "print(\"Quantized naive accuracy:\", model_q.evaluate(test_loader))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a015ae6e",
   "metadata": {},
   "source": [
    "Cela ne fonctionne pas du tout, on a complementement casse le modele. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "172085df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original accuracy: 0.9764\n",
      "Quantized static accuracy: 0.9762\n"
     ]
    }
   ],
   "source": [
    "def quantize_model_static(model, train_loader):\n",
    "    model_q = copy.deepcopy(model)\n",
    "    min = float('inf')\n",
    "    max = float('-inf')\n",
    "\n",
    "    for name, param in model_q.named_parameters():\n",
    "        min_elem = torch.min(param.data).item()\n",
    "        max_elem = torch.max(param.data).item()\n",
    "        min = min_elem if min_elem < min else min\n",
    "        max = max_elem if max_elem > max else max\n",
    "\n",
    "    for param in model_q.parameters():\n",
    "        value = param.data.cpu().numpy()\n",
    "        quantized_param = quantize(value, min, max, zero = 0)\n",
    "        dequantized_param = to_float(quantized_param, min, max)\n",
    "        param.data = torch.from_numpy(dequantized_param).to(torch.float32)\n",
    "\n",
    "    return model_q\n",
    "\n",
    "model_q_static = quantize_model_static(model, train_loader)\n",
    "print(\"Original accuracy:\", model.evaluate(test_loader))\n",
    "print(\"Quantized static accuracy:\", model_q_static.evaluate(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "5808ea88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original accuracy: 0.9764\n",
      "Quantized each layer accuracy: 0.9762\n"
     ]
    }
   ],
   "source": [
    "def quantize_model_each_layer(model, train_loader):\n",
    "    model_q = copy.deepcopy(model)\n",
    "\n",
    "    for name, param in model_q.named_parameters():\n",
    "        min_elem = torch.min(param.data).item()\n",
    "        max_elem = torch.max(param.data).item()\n",
    "\n",
    "        value = param.data.cpu().numpy()\n",
    "        quantized_param = quantize(value, min_elem, max_elem, zero = 0)\n",
    "        dequantized_param = to_float(quantized_param, min_elem, max_elem)\n",
    "        param.data = torch.from_numpy(dequantized_param).to(torch.float32)\n",
    "\n",
    "    return model_q\n",
    "model_q_each_layer = quantize_model_each_layer(model, train_loader)\n",
    "print(\"Original accuracy:\", model.evaluate(test_loader))\n",
    "print(\"Quantized each layer accuracy:\", model_q_each_layer.evaluate(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80e7869",
   "metadata": {},
   "source": [
    "Cela marche -t-il ? Sinon que suggerez vous pour resoudre le probleme ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da7f4cb",
   "metadata": {},
   "source": [
    "On n'est pas sur une mega reussite, mais c'est deja mieux que le modele quantifie naiveement.\n",
    "Pour ameliorer les choses, on pourrait essayer d'utiliser une quantification symetrique (centrer autour de 0).Malgré la quantization par couche, la précision reste inférieure au modèle original. Cela s’explique par la perte d’information due à la réduction de précision. Pour améliorer les résultats, il serait nécessaire d’introduire la quantization des activations ou d’utiliser la Quantization Aware Training (QAT) afin que le réseau apprenne à compenser les effets de la quantization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce484723",
   "metadata": {},
   "source": [
    "Que faudrait-il ajouter à l'approche précédente pour quantifier aussi les activations des couches ? \n",
    "\n",
    "Comment obtenir les bonnes plages de quantization à utiliser ? \n",
    "\n",
    "faire en sorte de  faire une quantization des weights et des activations de votre modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "328a4461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.3452\n",
      "Epoch 2/5, Loss: 0.1391\n",
      "Epoch 3/5, Loss: 0.0951\n",
      "Epoch 4/5, Loss: 0.0722\n",
      "Epoch 5/5, Loss: 0.0563\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "def quantize_tensor(x: torch.Tensor, min_val: float, S: float, qmin: float) -> torch.Tensor:\n",
    "    return torch.round((x - min_val) / S + qmin)\n",
    "\n",
    "def dequantize_tensor(Q: torch.Tensor, min_val: float, S: float, qmin: float) -> torch.Tensor:\n",
    "    return (Q - qmin) * S + min_val\n",
    "\n",
    "\n",
    "class QuantizeSTE(MLP):\n",
    "    def __init__(self, pretrained_state_dict=None, bits=8):\n",
    "        super().__init__()\n",
    "        if pretrained_state_dict is not None:\n",
    "            try:\n",
    "                self.load_state_dict(pretrained_state_dict)\n",
    "            except Exception as e:\n",
    "                print(\"Couldn't load pretrained_state_dict:\", e)\n",
    "\n",
    "        self.bits = bits\n",
    "        self.qmin = -(1 << (bits - 1))\n",
    "        self.qmax = (1 << (bits - 1)) - 1\n",
    "\n",
    "    \n",
    "    def quantize_activation(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        min_val = x.min()\n",
    "        max_val = x.max() \n",
    "\n",
    "        S = (max_val - min_val) / (self.qmax - self.qmin)\n",
    "\n",
    "        # Quantization\n",
    "        Q = quantize_tensor(x, min_val, S, self.qmin)\n",
    "        # Dequantization\n",
    "        x_dequant = dequantize_tensor(Q, min_val, S, self.qmin)\n",
    "        # Straight-Through Estimator\n",
    "        x_q = (x_dequant - x).detach() + x # d/dx = 1 / and return value = x_dequant !!!!\n",
    "\n",
    "        return x_q\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.quantize_activation(x)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.quantize_activation(x)\n",
    "        x = self.relu2(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        x = self.quantize_activation(x)\n",
    "        return x\n",
    "    \n",
    "    def quantize_state_dict(self):\n",
    "        q_state_dict = {}\n",
    "        qparams = {}\n",
    "\n",
    "        for name, param in self.state_dict().items():\n",
    "            min_val = param.min().item()\n",
    "            max_val = param.max().item()\n",
    "            S = (max_val - min_val) / (self.qmax - self.qmin + 1e-8)\n",
    "\n",
    "            q = torch.round((param - min_val) / S + self.qmin).to(torch.int8)\n",
    "\n",
    "            q_state_dict[name] = q\n",
    "            qparams[name] = (S, min_val)\n",
    "\n",
    "        return q_state_dict, qparams\n",
    "\n",
    "\n",
    "    def quantize_model_STE(self):\n",
    "        model_q = copy.deepcopy(self)\n",
    "        model_q.qparams = {} \n",
    "\n",
    "        for name, param in model_q.named_parameters():\n",
    "            min_elem = torch.min(param.data).item()\n",
    "            max_elem = torch.max(param.data).item()\n",
    "            S = (max_elem - min_elem) / (model_q.qmax - model_q.qmin + 1e-8)\n",
    "\n",
    "            value = quantize_tensor(param.data, min_elem, S, model_q.qmin)\n",
    "            param.data = value\n",
    "\n",
    "            model_q.qparams[name] = (min_elem, S)\n",
    "\n",
    "        return model_q\n",
    "    \n",
    "    def dequantize_model_STE(self):\n",
    "        model_deq = copy.deepcopy(self)\n",
    "\n",
    "        for name, param in model_deq.named_parameters():\n",
    "            min_elem, S = model_deq.qparams[name]\n",
    "            value = dequantize_tensor(param.data, min_elem, S, self.qmin)\n",
    "            param.data = value\n",
    "\n",
    "        return model_deq\n",
    "    \n",
    "    def save_quantized_model(self, filename):\n",
    "        q_state_dict, qparams = self.quantize_state_dict()\n",
    "        torch.save({'q_state_dict': q_state_dict, 'qparams': qparams, 'bits': self.bits}, filename)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_quantized_model(filename):\n",
    "        file = torch.load(filename)\n",
    "        q_state_dict = file['q_state_dict']\n",
    "        qparams = file['qparams']\n",
    "\n",
    "        model = QuantizeSTE(bits=file['bits'])\n",
    "        model.load_state_dict(q_state_dict)\n",
    "\n",
    "        model.qparams = qparams\n",
    "\n",
    "        return model\n",
    "\n",
    "model_ste = QuantizeSTE(pretrained_state_dict=None)\n",
    "optimizer_ste = optim.Adam(model_ste.parameters(), lr=1e-3)\n",
    "criterion_ste = nn.CrossEntropyLoss()\n",
    "model_ste.compile(optimizer_ste, criterion_ste)\n",
    "\n",
    "model_ste.fit(train_loader, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "b88aeb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9732\n"
     ]
    }
   ],
   "source": [
    "acc = model_ste.evaluate(test_loader)\n",
    "print(f\"Test accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "121ea5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original STE accuracy: 0.9732\n",
      "Quantized STE accuracy: 0.973\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_quantize = model_ste.quantize_model_STE()\n",
    "\n",
    "model_dequantize = dequantize_model_STE(model_quantize)\n",
    "print(\"Original STE accuracy:\", model_ste.evaluate(test_loader))\n",
    "print(\"Quantized STE accuracy:\", model_dequantize.evaluate(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17da0ecd",
   "metadata": {},
   "source": [
    "Et la ca fonctionne on a bien un model qui lorsqu'il est quantifier puis dequantifier retrouve des performances proches de l'original !!!\n",
    "\n",
    "On peut tenter de les sauvegarder pour voir la place que l'on gagne en theorie x4. Attention pour des raisons de tensorflow on a encore des float32 dans les fichiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "55e7c12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_state_dict, qparams = model_ste.quantize_state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "faf0e785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of quantized model: 109.97 KB\n",
      "Size of dequantized model: 430.37 KB\n"
     ]
    }
   ],
   "source": [
    "save_quantized_model(model_ste, \"quantized_model_ste.pth\")\n",
    "torch.save({'state_dict': model_ste.state_dict()}, \"dequantized_model_ste.pth\")\n",
    "\n",
    "import os\n",
    "size_quantized = os.path.getsize(\"quantized_model_ste.pth\")\n",
    "size_dequantized = os.path.getsize(\"dequantized_model_ste.pth\")\n",
    "print(f\"Size of quantized model: {size_quantized / 1024:.2f} KB\")\n",
    "print(f\"Size of dequantized model: {size_dequantized / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "81700af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded quantized model accuracy: 0.973\n"
     ]
    }
   ],
   "source": [
    "model_loaded = load_quantized_model(\"quantized_model_ste.pth\", bits=8)\n",
    "dequantized_model = dequantize_model_STE(model_loaded) # not perfect \n",
    "print(\"Loaded quantized model accuracy:\", dequantized_model.evaluate(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a944581a",
   "metadata": {},
   "source": [
    "Normal que les performances ne soient pas mieux qu'avec le modele de base car le model fonctionne avec des float32 qui peuvent etre convertis en "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "id": "5ba51ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12252/1188474859.py:26: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
      "For migrations of users: \n",
      "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
      "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
      "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
      "see https://github.com/pytorch/ao/issues/2259 for more details\n",
      "  prepare_qat(qat_model, inplace=True)  # insère fake-quant / observers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Loss: 1.0723\n",
      "Epoch 1/1, Loss: 0.3569\n",
      "Epoch 1/1, Loss: 0.2871\n",
      "Epoch 1/1, Loss: 0.2532\n",
      "Epoch 1/1, Loss: 0.2282\n",
      "Epoch 1/1, Loss: 0.2078\n",
      "Epoch 1/1, Loss: 0.1903\n",
      "Epoch 1/1, Loss: 0.1754\n",
      "Epoch 1/1, Loss: 0.1630\n",
      "Epoch 1/1, Loss: 0.1519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12252/1188474859.py:41: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
      "For migrations of users: \n",
      "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
      "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
      "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
      "see https://github.com/pytorch/ao/issues/2259 for more details\n",
      "  quantized_model = convert(qat_model, inplace=False)  # retourne une copie quantized\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Could not run 'quantized::linear_relu' with arguments from the 'CPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'quantized::linear_relu' is only available for these backends: [Meta, QuantizedCPU, QuantizedCUDA, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMTIA, AutogradMAIA, AutogradMeta, Tracer, AutocastCPU, AutocastMTIA, AutocastMAIA, AutocastXPU, AutocastMPS, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nMeta: registered at /pytorch/aten/src/ATen/core/MetaFallbackKernel.cpp:23 [backend fallback]\nQuantizedCPU: registered at /pytorch/aten/src/ATen/native/quantized/cpu/qlinear.cpp:1603 [kernel]\nQuantizedCUDA: registered at /pytorch/aten/src/ATen/native/quantized/cudnn/Linear.cpp:359 [kernel]\nBackendSelect: fallthrough registered at /pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:194 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:479 [backend fallback]\nFunctionalize: registered at /pytorch/aten/src/ATen/FunctionalizeFallbackKernel.cpp:387 [backend fallback]\nNamed: registered at /pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /pytorch/aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at /pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at /pytorch/aten/src/ATen/ZeroTensorFallback.cpp:115 [backend fallback]\nADInplaceOrView: fallthrough registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:104 [backend fallback]\nAutogradOther: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:63 [backend fallback]\nAutogradCPU: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:67 [backend fallback]\nAutogradCUDA: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:75 [backend fallback]\nAutogradXLA: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:87 [backend fallback]\nAutogradMPS: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:95 [backend fallback]\nAutogradXPU: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:71 [backend fallback]\nAutogradHPU: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:108 [backend fallback]\nAutogradLazy: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:91 [backend fallback]\nAutogradMTIA: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:79 [backend fallback]\nAutogradMAIA: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:83 [backend fallback]\nAutogradMeta: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:99 [backend fallback]\nTracer: registered at /pytorch/torch/csrc/autograd/TraceTypeManual.cpp:294 [backend fallback]\nAutocastCPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\nAutocastMTIA: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:468 [backend fallback]\nAutocastMAIA: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:506 [backend fallback]\nAutocastXPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:544 [backend fallback]\nAutocastMPS: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:209 [backend fallback]\nAutocastCUDA: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:165 [backend fallback]\nFuncTorchBatched: registered at /pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:731 [backend fallback]\nBatchedNestedTensor: registered at /pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:758 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:27 [backend fallback]\nBatched: registered at /pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at /pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:210 [backend fallback]\nPythonTLSSnapshot: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:202 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:475 [backend fallback]\nPreDispatch: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:206 [backend fallback]\nPythonDispatcher: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:198 [backend fallback]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[667]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     44\u001b[39m quantized_model.eval()\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     acc_q = \u001b[43mquantized_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mQuantized model accuracy:\u001b[39m\u001b[33m\"\u001b[39m, acc_q)\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# Tu peux aussi mesurer la différence logits / outputs float vs quant pour debug\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# --- Export: TorchScript + optimize for mobile ---\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[663]\u001b[39m\u001b[32m, line 41\u001b[39m, in \u001b[36mSimpleMLP.evaluate\u001b[39m\u001b[34m(self, test_loader)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m data, target \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m         output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m         _, predicted = torch.max(output.data, \u001b[32m1\u001b[39m)\n\u001b[32m     43\u001b[39m         correct += (predicted == target).sum().item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[663]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mSimpleMLP.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     11\u001b[39m     x = x.view(-\u001b[32m1\u001b[39m, \u001b[32m28\u001b[39m*\u001b[32m28\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.relu1(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     13\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.relu2(\u001b[38;5;28mself\u001b[39m.fc2(x))\n\u001b[32m     14\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.fc3(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/ao/nn/intrinsic/quantized/modules/linear_relu.py:40\u001b[39m, in \u001b[36mLinearReLU.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch.Tensor) -> torch.Tensor:\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquantized\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear_relu\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_packed_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_packed_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mzero_point\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/mlops/introduction_a_la_quantization/.venv/lib/python3.12/site-packages/torch/_ops.py:1255\u001b[39m, in \u001b[36mOpOverloadPacket.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1253\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_torchbind_op_overload \u001b[38;5;129;01mand\u001b[39;00m _must_dispatch_in_python(args, kwargs):\n\u001b[32m   1254\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _call_overload_packet_from_python(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1255\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mNotImplementedError\u001b[39m: Could not run 'quantized::linear_relu' with arguments from the 'CPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'quantized::linear_relu' is only available for these backends: [Meta, QuantizedCPU, QuantizedCUDA, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMTIA, AutogradMAIA, AutogradMeta, Tracer, AutocastCPU, AutocastMTIA, AutocastMAIA, AutocastXPU, AutocastMPS, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nMeta: registered at /pytorch/aten/src/ATen/core/MetaFallbackKernel.cpp:23 [backend fallback]\nQuantizedCPU: registered at /pytorch/aten/src/ATen/native/quantized/cpu/qlinear.cpp:1603 [kernel]\nQuantizedCUDA: registered at /pytorch/aten/src/ATen/native/quantized/cudnn/Linear.cpp:359 [kernel]\nBackendSelect: fallthrough registered at /pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:194 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:479 [backend fallback]\nFunctionalize: registered at /pytorch/aten/src/ATen/FunctionalizeFallbackKernel.cpp:387 [backend fallback]\nNamed: registered at /pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /pytorch/aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at /pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at /pytorch/aten/src/ATen/ZeroTensorFallback.cpp:115 [backend fallback]\nADInplaceOrView: fallthrough registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:104 [backend fallback]\nAutogradOther: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:63 [backend fallback]\nAutogradCPU: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:67 [backend fallback]\nAutogradCUDA: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:75 [backend fallback]\nAutogradXLA: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:87 [backend fallback]\nAutogradMPS: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:95 [backend fallback]\nAutogradXPU: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:71 [backend fallback]\nAutogradHPU: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:108 [backend fallback]\nAutogradLazy: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:91 [backend fallback]\nAutogradMTIA: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:79 [backend fallback]\nAutogradMAIA: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:83 [backend fallback]\nAutogradMeta: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:99 [backend fallback]\nTracer: registered at /pytorch/torch/csrc/autograd/TraceTypeManual.cpp:294 [backend fallback]\nAutocastCPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\nAutocastMTIA: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:468 [backend fallback]\nAutocastMAIA: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:506 [backend fallback]\nAutocastXPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:544 [backend fallback]\nAutocastMPS: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:209 [backend fallback]\nAutocastCUDA: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:165 [backend fallback]\nFuncTorchBatched: registered at /pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:731 [backend fallback]\nBatchedNestedTensor: registered at /pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:758 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:27 [backend fallback]\nBatched: registered at /pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at /pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:210 [backend fallback]\nPythonTLSSnapshot: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:202 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:475 [backend fallback]\nPreDispatch: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:206 [backend fallback]\nPythonDispatcher: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:198 [backend fallback]\n"
     ]
    }
   ],
   "source": [
    "from torch.ao.quantization import (get_default_qat_qconfig,\n",
    "                                  prepare_qat,\n",
    "                                  convert,\n",
    "                                  fuse_modules)\n",
    "\n",
    "\n",
    "# --- Setup ---\n",
    "device = torch.device(\"cpu\")  # QAT training done on CPU/GPU as usual; conversion for backend qnnpack is CPU runtime\n",
    "torch.backends.quantized.engine = \"qnnpack\"  # pour ARM; sur x86 => \"fbgemm\"\n",
    "\n",
    "model = MLP()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)  # lr plus petit pour QAT fine-tuning\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model.compile(optimizer, criterion)\n",
    "\n",
    "# --- Fusion (facultatif mais recommandé) ---\n",
    "# On fuse Linear + ReLU si possible (nommes comme ci-dessus)\n",
    "# pour un MLP on fuse ['fc1','relu1'] et ['fc2','relu2'] si nécessaire\n",
    "# attention: fuse_modules attend que les modules existent au même niveau.\n",
    "fused_model = copy.deepcopy(model)\n",
    "fuse_modules(fused_model, [['fc1', 'relu1'], ['fc2', 'relu2']], inplace=True)\n",
    "\n",
    "# --- QAT preparation ---\n",
    "qat_model = fused_model\n",
    "qat_model.qconfig = get_default_qat_qconfig(\"qnnpack\")\n",
    "prepare_qat(qat_model, inplace=True)  # insère fake-quant / observers\n",
    "\n",
    "# --- QAT training / fine-tune ---\n",
    "# Important: pour QAT, lr réduit, momentum/weight decay adaptés. 5-20 epochs typiquement.\n",
    "n_epochs_qat = 10\n",
    "for epoch in range(n_epochs_qat):\n",
    "    avg_loss = qat_model.fit(train_loader)  # utilise la méthode fit_epoch définie\n",
    "    acc = qat_model.evaluate(test_loader)\n",
    "\n",
    "# Optionnel : \"freeze\" observers avant conversion (réduit variance)\n",
    "# torch.ao.quantization.disable_observer(qat_model)\n",
    "# torch.ao.quantization.freeze_bn_stats(qat_model)  # si batchnorm present\n",
    "\n",
    "# --- Convert to quantized model (int8 modules) ---\n",
    "qat_model.eval()\n",
    "quantized_model = convert(qat_model, inplace=False)  # retourne une copie quantized\n",
    "\n",
    "# --- Test / comparer performances (accuracy) ---\n",
    "quantized_model.eval()\n",
    "with torch.no_grad():\n",
    "    acc_q = quantized_model.evaluate(test_loader)\n",
    "    print(\"Quantized model accuracy:\", acc_q)\n",
    "\n",
    "# Tu peux aussi mesurer la différence logits / outputs float vs quant pour debug\n",
    "# --- Export: TorchScript + optimize for mobile ---\n",
    "scripted = torch.jit.script(quantized_model)\n",
    "# Optionnel: optimiser pour mobile\n",
    "try:\n",
    "    from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "    scripted_optimized = optimize_for_mobile(scripted)\n",
    "    scripted_optimized.save(\"mlp_qat_int8_mobile.pt\")\n",
    "    print(\"Saved optimized mobile scripted quantized model -> mlp_qat_int8_mobile.pt\")\n",
    "except Exception as e:\n",
    "    # si mobile optimizer non disponible, sauvegarde le scripted normal\n",
    "    scripted.save(\"mlp_qat_int8.pt\")\n",
    "    print(\"Saved scripted quantized model -> mlp_qat_int8.pt (optimize_for_mobile failed):\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d721b059",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
